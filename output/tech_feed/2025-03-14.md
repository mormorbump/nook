
# Organization Listing / Internal Marketplace を使ってみる | ちゅらデータ株式会社のフィード

[View on Company Blog](https://zenn.dev/churadata/articles/de18794e30740c)

この記事は、Snowflakeの組織内リスティングとインターナルマーケットプレイスの検証結果をまとめたものです。

**背景**

Snowflakeにはデータ共有の仕組みとして、Direct Sharing、Listing、Native Appsがあります。今回検証するのは、2024年11月にGAとなったOrganization Listing / Internal Marketplaceです。これは、同一組織内でのデータ共有を安全に行うための仕組みです。

**Organization Listing / Internal Marketplaceとは**

*   **Organization Listing:** 提供元（プロバイダー）が組織内でデータを安全に共有する手段
*   **Internal Marketplace:** 組織内の消費者（コンシューマ）が、Organization Listingで共有されたデータを見つけやすい場所

**検証内容**

1.  **Organization Listingの作成と公開**
    *   ORGADMINロールを使用して、別リージョンへの公開を許可
    *   データ提供を行うアカウントにGLOBAL\_DATA\_SHARINGを許可
2.  **Internal Marketplaceでのデータ利用**
    *   コンシューマ側でInternal Marketplaceにアクセスし、共有されたデータを選択
    *   共有されたリストからデータベースを作成
3.  **カスタムロールでの権限設定**
    *   カスタムロールに、LISTINGからデータベースを作成するための権限を付与
    *   `IMPORT ORGANIZATION LISTING`権限が必要（ドキュメントには記載なし）
    *   別のカスタムロールでデータベースを閲覧するために、`IMPORTED PRIVILEGES`権限を付与

**まとめ**

組織リスティングとインターナルマーケットプレイスは、組織内での安全なデータ共有に非常に有効です。特に、別リージョン間でのデータ共有が可能な点がメリットです。カスタムロールでの権限設定には注意が必要で、`IMPORT ORGANIZATION LISTING`権限が必要となることがわかりました。

---

# モジュラモノリスにおける Prisma を利用した DB アクセスの秩序を保つ | Ubie テックブログのフィード

[View on Company Blog](https://zenn.dev/ubie_dev/articles/nestjs-prisma-db-access-management)

この記事は、モジュラモノリスアーキテクチャにおいて Prisma を利用した DB アクセスを行う際の課題と、その解決のために作成した lint ルールについて解説しています。

**課題:**

*   **Prisma Client を利用したモジュール間を跨いでのテーブルアクセス:** 本来アクセスできないはずの他のモジュールのテーブルに直接アクセスできてしまう。
*   **Prisma スキーマにおけるモジュール間での `@relation` の利用:** モジュールを跨いだテーブルの JOIN が可能になってしまう。

**解決策:**

これらの課題に対し、以下の 2 つの lint ルールを実装しました。

1.  **Prisma Client を利用した他モジュールのテーブルへのアクセスを禁止する ESLint カスタムルール:**

    *   各モジュールが所有するデータベースのテーブル名を収集する関数を作成。
    *   lint 対象のファイルが所属するモジュールでアクセスできるテーブルと全てのテーブルを取得。
    *   `client.xxx` という形式でのテーブルアクセスについて、`xxx` がアクセス可能なテーブル名に含まれていない場合にエラーを報告。
2.  **モジュール間での `@relation` の利用を禁止する Node.js スクリプト:**

    *   各モジュールの Prisma スキーマを解析し、`@relation` を含む行を検出。
    *   関連するテーブル名を抽出し、アクセス可能なテーブルに含まれていない場合にエラーメッセージを報告。
    *   `// schema-lint-disable-next-line:` のコメントによる lint 抑制を可能にする。

**その他:**

*   Prisma スキーマの解析には、正規表現を使用。
*   パフォーマンスやメンテナンスの観点から、非公式なスキーマ解析ツールは採用しなかった。
*   例外的にモジュール間での `@relation` を許容する場合に備え、lint 抑制の仕組みを導入。

これらの lint ルールを導入することで、モジュラモノリスにおける DB アクセスの秩序を保ち、モジュール間の独立性を高めることを目指しています。

---

# 「AIエージェントキャッチアップ #24 - Giskard」を開催しました | Generative Agents Tech Blog

[View on Company Blog](https://blog.generative-agents.co.jp/entry/2025/03/13/191150)

ジェネラティブエージェンツの大嶋氏が「AIエージェントキャッチアップ #24 - Giskard」という勉強会を開催した。

今回のテーマは、LLMアプリケーションのパフォーマンス、バイアス、セキュリティなどを評価するフレームワーク「Giskard」について。Giskardは従来の機械学習からLLMアプリケーションまで対応しており、RAGに特化した「RAG Evaluation Toolkit（RAGET）」という機能も含まれている。

Giskardのチュートリアルでは、LangChainで実装したRAGのChainに対し、Giskardでハルシネーションの評価を実行し、レポートが出力される。Giskardではハルシネーションのチェックとして、「ごますり検出器」が実装されており、LLMが質問に対して矛盾した回答をしないかチェックする。

RAGETのチュートリアルでは、GiskardによりRAGの検索対象のドキュメントからQAデータセットを自動生成し、評価まで実行することができる。評価レポートでは、スコアだけでなく、改善点も提示される。

次回の「AIエージェントキャッチアップ #25」では、Agentic AI WorkflowのPythonフレームワーク「ControlFlow」がテーマとなる。

---

# JAWS DAYS 参加日記 ～version 松澤～ | Technology - NRIネットコムBlog

[View on Company Blog](https://tech.nri-net.com/entry/jawsdays-diary)

NRIネットコムの松澤氏が、JAWS DAYS 2025に参加した体験をレポート。JAWS DAYSはJAWS-UG主催のAWSに関するカンファレンス型イベントで、セッションや企業ブースを通じてAWSの知見を得られる。

松澤氏は、Next-Generation Software Development、IAMのマニアックな話、地方版CCoE「re:light local」の取り組み、Sonnet de ソネット。、LLM-as-a-Judgeを使ったRAG環境の回答精度向上、AI導入のヒント、DevelopersIO流！アマゾンの奥地で技術の限界に挑戦、生成AI×財務経理、ABWG2024採択者が語るエンジニアとしての自分自身の見つけ方、IoTとメディア処理の未経験者が語る1000台規模システムへの挑戦、恒例！AWSエンジニアたちの怒涛のLTといったセッションを聴講。特に生成AIに関するセッションに興味を持ち、多くの知見を得た。

常設参加型コンテンツとして、生成AI絵画展、お悩み解決ボード、開発Tipsガチャガチャ、メッセージチェキボード、Book Swapコーナーが設けられていた。企業ブースでは、様々な企業がAWS関連事業を宣伝しており、多くの景品を獲得。また、JAWS DAYSお茶会テーブル「純喫茶 鮫」では、参加者同士の交流が行われた。

後悔したこととして、生成AI絵画展に応募しなかったこと、大きめのバッグを持参しなかったことを挙げている。

全体として、AWSに関する知識だけでなく、様々な企業や登壇者の存在を知り、見識が広がった有意義な一日だったとまとめている。特に、地方での取り組みや、アウトプットに対するマインドなど、日々の業務では得られない気づきや刺激があった。アプリケーションエンジニアにも参加を勧め、1500円のチケット料金以上の価値があると述べている。最後に、JAWS FESTA 2025が金沢で開催されることを告知している。

---

# 「初任給が高い会社＝お得？」生涯年収という視点で企業を選ぼう | SHIFT Group 技術ブログ

[View on Company Blog](https://note.shiftinc.jp/n/n77271e89fb99)

新卒就活生に向けて、初任給だけでなく生涯年収を考慮した企業選びの重要性を解説。

*   **初任給の高さだけで判断しない**: 初任給が高くても、昇給率が低いと長期的に損をする可能性がある。
*   **昇給率に注目**: 昇給率の高い企業は、長期的に年収が伸びやすい。企業説明会で昇給率について質問することも有効。
*   **仕事の成長性が鍵**: 昇給しやすい企業は、仕事を通して自身の価値を高めやすい環境がある。業務範囲が広がる、上流工程に関われるなど、仕事がアップデートされる仕組みがあるかを確認。
*   **労働集約型から知識集約型へ**: キャリアの中で知識集約型へシフトできる企業を選ぶ。
*   **企業の見分け方**:
    *   昇給実績が公開されているか
    *   キャリアパスが明確か (5年後、10年後にどんな仕事ができるのか)
    *   知識集約型へシフトできる環境があるか (上流工程に携われるか、教育・マネジメントの機会があるか)
*   **長期的な視点**: 10年後、20年後の自身の市場価値を意識し、生涯年収の観点で企業を選ぶことが大切。

就職活動では、目先の初任給に捉われず、長期的なキャリアを見据えた企業選びをすることが重要であると述べている。

---

# 【多様性シリーズ総集編】個の選択を支える組織へ～定年前に大企業から思い切って転身。ブレインパッドが持つ魅力と未来 | Platinum Data Blog by BrainPad ブレインパッド

[View on Company Blog](https://blog.brainpad.co.jp/entry/2025/03/13/181429)

この記事は、ブレインパッドの「多様性シリーズ」の総集編として、グローバル企業からブレインパッドへ転職した加藤氏へのインタビューを通して、個の選択を支える組織のあり方や、ブレインパッドの魅力と未来について考察する内容です。

加藤氏は、ソニーで長年、生産管理、経営企画、CFO、総務部門のトップなどを経験し、危機管理やコーポレートガバナンスにも携わりました。57歳でソニーを退職する決断をしたのは、自身の存在が後進の育成を妨げるという危機感から、次世代に道を譲るためでした。

転職の軸として、社会貢献、国際性、経験の活用を掲げ、ブレインパッドに入社。経営陣の謙虚さや社員の風通しの良さに感銘を受けた一方、平均勤続年数の短さに課題を感じました。その背景には、「日本一の人材輩出企業を目指す」という目標があるものの、社員が企業に対する「内発的なブランド価値」を育むための仕組みがまだ発展途上であることが挙げられました。

加藤氏は、人材のサステナビリティが今後の課題であると指摘し、「会社が人を育てる」ことの重要性を強調。ソニーでの経験を踏まえ、「自分がいなくなっても機能する組織」を作ること、失敗から学ぶ姿勢を持つことの重要性を語りました。

ブレインパッドが多様な人材を受け入れる環境が整ってきたからこそ、個を大切にし、成長をサポートする仕組みを強化することで、組織全体の力を高め、企業理念である「データ活用の促進を通じて持続可能な未来をつくる」を実現できると結論づけています。

---

# DEIM2025 参加レポート | MicroAd Developers Blog

[View on Company Blog](https://developers.microad.co.jp/entry/2025/03/13/180000)

マイクロアドはDEIM2025にゴールドスポンサーとして協賛し、技術登壇とスポンサーブース出展を行った。技術登壇では「マイクロアドのデータ基盤とその構成について」と題し、オンプレミスからSpark/Icebergベースへのデータ基盤移行の背景とメリットを紹介。スポンサーブースでも同様のテーマでポスター展示を実施し、多くの来場者と交流した。

ポスター発表の聴講では、広告会社の視点から興味深い研究として、大規模言語モデル(LLM)によるユーザー特性を考慮したクリック予測と、推薦システムにおけるレビュー数と評価値に基づく人気バイアスの影響調査の2つを取り上げた。

*   **大規模言語モデルによるユーザー特性を考慮したクリック予測:** LLMにユーザー特性を入力することで、クリック行動のシミュレーション精度が向上することが示唆された。インプレッションに到達しなかった広告に対する擬似ラベル作成への応用が考えられる。
*   **推薦システムにおけるレビュー数と評価値に基づく人気バイアスの影響調査:** アイテムの人気度を質と同調性（レビュー数）に分解し、さらに評価値による人気も切り分けてインタラクションを推定することで、推薦システムの精度が向上することが示された。マイクロアド内のバイアス除去への応用に期待。

マイクロアドは機械学習エンジニアを募集している。

---

# Rails 8.0.2がリリースされました | TechRacho

[View on Company Blog](https://techracho.bpsinc.jp/hachi8833/2025_03_13/149490)

Rails 8.0.2がリリースされ、バグ修正が行われた。

主な更新内容は以下の通り。

*   **Action Pack**: `with_routing`ヘルパーがミドルウェアスタックをリビルドしないよう改善。`#resource`や`#resources`に無効な`:only`や`:except`オプションを渡すと発生する`ArgumentError`にリソース名を表示するように改善。`:path_params`経由でハッシュでないパラメータが渡された場合にクラッシュしないよう修正。`ActionDispatch::Executor`が他のエラー報告ミドルウェアと同様に例外をアンラップするよう修正。
*   **Action View**: `collection_checkboxes`で非表示のinput要素に`html_options[:form]`が反映されるよう修正。`render`に渡されたlocalsにレイアウトファイルからアクセスできるよう修正。テンプレート内の引数エラーのうち、strict localsに関連するものは`ActionView::StrictLocalsError`をraiseし、その他の引数エラーはそのまま再度raiseされるように修正。依存関係トラッカーが循環依存を処理するときにスタックオーバーフローになるのを修正。
*   **Active Record**: マイグレーションの`rename_enum_value`で`:from`と`:to`を指定してロールバックできない問題を修正。無効なレコードが永続化されるのを防止。マイグレーションの`drop_table`にオプションなしでブロックを渡した場合にロールバックできなかった問題を修正。修飾名を渡した`.group`と`.count`に続けてリレーションを`.reload`すると`.count`できない問題を修正。読み込まれたリレーションで`sum`に修飾名を渡すとエラーになる問題を修正。SQLite3アダプタが有限でないNumeric値を引用符で囲むよう修正。PostgreSQLAdapterでlibpqがdbバージョンを0で返したらコネクション失敗として処理するよう修正。コネクション構成中のエラー処理を修正。リトライ不可のクエリがリトライ可能とマーキングされていたケースを修正。関連付けの自動保存時のバリデーションで循環参照がクラッシュしないよう修正。PoolConfigがコネクションクラスへの参照を維持しないように修正。非同期クエリでSQLのActive Support Instrumentation通知が送信されない場合があったのを修正。PostgreSQLのenum型でカンマを含む名前もサポートするよう修正。MySQL環境における自動増分値取得処理で複数の自動生成カラムを持つテーブルに対応。スコープ付き関連付けで文字列とバインドパラメータを使うjoinsを修正。システムテストでトランザクショナルなフィクスチャを使う場合の潜在的な競合状態を修正。関連付けの自動保存で、関連付けられるレコードが変更されていない場合にバリデーションを行わないよう修正。1件のリクエスト中にバリデーションが繰り返し再実行されるのを避けるため、直近のバリデーションをデータベースコネクションで記憶するようになった。
*   **Active Storage**: 関連付けられた添付ファイルをBlobが自動保存しないように修正。
*   **Active Support**: `new_framework_defaults_8_0.rb`の`to_time_preserves_timezone`設定方法を修正。ローカルストアが有効な場合のActive Support Cache `fetch_multi`を修正。Exceptionも含めてすべての例外を報告するよう実行ラッピングを修正。RedisCacheStoreとMemCacheStoreがコネクションプール関連のエラーも処理できるよう修正。ローカルキャッシュを使う場合にバージョンの有効期限が反映されるよう`ActiveSupport::Cache#read_multi`を修正。`ActiveSupport::MessageVerifier`と `ActiveSupport::MessageEncryptor`でon\_rotationコールバックの設定方法を修正。`ActiveSupport::MessageVerifier`でURL安全なペイロードとURL安全でないペイロードを常に両方とも検証できるよう修正。`:race_condition_ttl`オプションを指定した場合にも指定の有効期限が反映されるよう`cache.fetch`を修正。`set_callback`にprocを`&:引数`で渡すとエラーになっていたのを修正。`String#mb_chars`がレシーバを改変しないように修正。ErrorSubscriberがエラーの原因(rror.cause)をreportedとマーキングするよう改善。モジュールに名前を付けた後にModule#module\_parent\_nameが正しい名前を返すよう修正。
*   **Railties**: Railsコンソールでルーティングを読み込むよう修正。`rails new --minimal`オプションを更新。ローカル環境に存在する場合は、ENVやcredentialにある`secret_key_base`を使うよう修正。

アップグレード方法についてはRailsガイドを参照。
Rails 8.0.xと7.2.xがバグ修正とセキュリティ修正のサポート対象。


---

# マイクロインシュアランスとは？デジタル革新が切り開く保険の未来 | 株式会社モンスターラボ

[View on Company Blog](https://monstar-lab.com/dx/about/about-microinsurance/)

この記事は、マイクロインシュアランスという、これまで保険サービスを受けにくかった低所得者層などを対象とした少額保険について解説しています。

**マイクロインシュアランスとは**

*   低所得者層や保険にアクセスできない人々を対象とした少額でシンプルな保険。
*   農業従事者向けに干ばつを補償する保険や、畜産農家向けに家畜の死亡を補償する保険など、特定のニーズに合わせた商品がある。
*   従来の大量の契約者を集める保険とは異なり、顧客一人ひとりの状況やニーズに合わせた適切な保険商品を設計する。
*   デジタル技術の進展により、若年層やデジタルネイティブ層といった幅広い層にも価値を提供するようになっている。
*   イベント当日の悪天候など、従来は保険の対象となりにくかったリスクにも対応。
*   世界のマイクロインシュアランス市場は成長を続けており、特にアジア太平洋地域で顕著。

**マイクロファイナンス、少額短期保険、組込型保険との違い**

*   マイクロファイナンスは小口融資であり、マイクロインシュアランスは融資を受けた人の経済的安定性を高めるために提供される。
*   少額短期保険は国内のニッチ市場をターゲットとするが、マイクロインシュアランスはより幅広い層へのアクセス提供を目指す。
*   組込型保険は商品やサービスに付随する保険だが、マイクロインシュアランスは独立した保険商品として提供されることが多い。

**デジタル革新がもたらす変革**

*   スマートフォンの普及により、保険の申込みから請求までのプロセスが簡素化。
*   デジタルプラットフォームを通じた保険提供により、コスト削減と効率化が実現。
*   AIやビッグデータを活用し、リスク評価の精度向上やパーソナライズされた商品設計が可能に。

**導入時の課題と解決策**

*   保険の必要性や仕組みについて理解促進のため、デジタルコンテンツを活用した教育プログラムを提供する。
*   効率的なシステムを構築するため、クラウドサービスの活用や段階的なシステムの導入を行う。
*   各国の保険規制に適合するため、規制当局との対話を通じた法規制に適応したシステム設計を行う。
*   保険会社、通信事業者、地域社会、テクノロジープロバイダーなどとの連携によって、持続可能なビジネスモデルを形成する。

**モンスターラボの事例**

*   シンガポールのIncome Insuranceが提供するSNACKは、日常的な行動に連動して少額の保険料を積み立てる仕組みで、若年層を中心に支持を得ている。

**今後の展望**

*   IoTデバイスとの連携やブロックチェーン技術の活用により、保険料の最適化や保険金支払いプロセスの効率化が期待される。
*   気候変動リスクへの対応や、ギグエコノミーの発展に伴う短期保障ニーズへの対応も進んでいる。
*   マイクロインシュアランスは国内保険業界の課題解決にもつながると期待されている。

---

# 相手のプライベートにどこまで踏み込んでいいの？ | SHIFT Group 技術ブログ

[View on Company Blog](https://note.shiftinc.jp/n/nbaf2a664d0c6)

株式会社SHIFTの岡田洋輔氏による記事の要約です。
相手との適切な距離感を保ちながら、より良い人間関係を築くためのヒントが提供されています。

重要なのは、「どこまで踏み込むか」ではなく「相手が求める関係性をどう築くか」という視点を持つことです。

具体的なアプローチとして、以下の5つのポイントが挙げられています。

1.  **段階的に関係を深める:** 軽い雑談から始め、相手の反応を見ながら徐々に会話の幅を広げる。
2.  **相手のサインを見逃さない:** 表情やリアクションに注意を払い、会話のトーンを調整する。
3.  **「踏み込むこと＝信頼」ではない:** 相手にとって心地よい距離感を尊重し、業務上の関係だけでも信頼を築けることを理解する。
4.  **相手にとっての価値を意識する:** 会話が相手にとって有益かどうかを考え、負担にならないよう配慮する。
5.  **相手が話したいことを優先する:** 自分が知りたいことよりも、相手が話したいことを中心に会話を進める。

相手のニーズを尊重し、共感的な姿勢で接することで、より深く豊かな人間関係を築くことができると結論付けています。


---

# JSONとYAMLどっちがいい？APIフォーマット選びで悩んでいる開発者必見！

[View on Qiita Trend](https://qiita.com/takuya77088/items/935ca090323049280e64?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

この記事は、API開発におけるデータフォーマットとしてJSONとYAMLのどちらを選ぶべきかについて解説しています。著者は、上司からAPIドキュメントをJSONからYAMLに書き換えるように指示された経験から、YAMLの利点に気づき、その魅力を伝えています。

記事では、JSONとYAMLの主な違いとして以下の4点を挙げています。

1.  **構造表現:** JSONは中括弧と角括弧を使用するのに対し、YAMLはインデントと改行で階層を表現するため、YAMLの方が構造が一目瞭然である。
2.  **冗長性:** JSONはすべての文字列にダブルクォートが必要だが、YAMLは必要に応じて省略できるため、YAMLの方がコード量が少なくスッキリしている。
3.  **コメント:** JSONはコメントを記述できないが、YAMLはコメントを記述できるため、コードの意図を説明できる。
4.  **人間親和性:** JSONは機械処理向けだが、YAMLは人間の読みやすさを重視しているため、YAMLの方が理解しやすい。

YAMLを選ぶ理由として、読みやすさ、コメント機能、コード量削減、OpenAPI/Swaggerとの相性、チーム連携の向上、メンテナンスの容易さを挙げています。

JSONからYAMLへの変換方法として、AIツール、オンライン変換ツール、コマンドラインツールの3つを紹介しています。

最後に、API管理ツールApidogを紹介し、ApidogがJSONとYAMLの両方をサポートし、API定義のインポート、APIドキュメントの自動生成、APIテストなどを一つのツールで完結できることを強調しています。

結論として、JSONはデータ交換の標準であり続けるものの、API定義や設定ファイルではYAMLの方が優位性があり、特にApidogのようなツールを使えば作業が格段に楽になると述べています。

---

# 「AIがあるんだからもっと安く早く作れるでしょ？」と非エンジニアに言われた時に読む（読んでもらう）記事

[View on Qiita Trend](https://qiita.com/ku_suke/items/577bdb839b411fe75e44?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

この記事は、非エンジニアから「AIがあるんだから、もっと安く早く開発できるでしょ？」と言われた際に、エンジニアがどのように答えるべきか、あるいは非エンジニアに読んでもらうべきかを解説しています。

**主なポイント:**

*   **AIが得意なことと苦手なこと:** AIは、ゼロから新しいものを作るのは得意ですが、既存の複雑なシステムに修正や機能追加をするのは苦手です。なぜなら、AIは公開されたデータで学習しているため、企業の内部コードのような非公開情報については知識がないからです。
*   **AIによる生産性向上:** AIは、開発プロセス全体の一部を支援することで生産性を向上させることができます。例えば、要件定義、画面設計、テスト、ドキュメント作成などのタスクです。特に、指示を細分化することで、AIはより効果的に機能します。
*   **AIツールの導入と活用:** Github CopilotのようなAIツールを導入し、エンジニアが使いこなせるようにすることが重要です。ただし、ツールは常に進化しているため、定期的な見直しが必要です。
*   **人手不足の解消:** AIは、進捗報告書作成のような、本来エンジニアがやるべきではないタスクを代行できます。また、企画者がAIを使ってモックアップを作成することで、エンジニアへの指示をより具体的にすることができます。
*   **部門間のコミュニケーション:** AIの翻訳機能を活用することで、技術職、営業職、企画職など、異なる視点を持つ人々の間のコミュニケーションを円滑にすることができます。
*   **重要な考え方:**

    *   既存システムへの追加は人間もAIも難しい
    *   PoCや設計書作成でのAI活用は有効
    *   開発プロセス全体でAI活用できるポイントは多い
    *   まずはAIツールを導入し使いこなす
    *   プログラミングは開発工程の一部に過ぎない
    *   AIを活用して抽象度の高い業務を可能にする

要するに、AIは万能ではなく、得意なことと苦手なことがあります。AIを効果的に活用するためには、適切なツールを導入し、開発プロセス全体を見直す必要があります。また、AIはエンジニアの仕事を奪うのではなく、より高度な仕事に集中できるようにするための支援ツールとして捉えるべきです。

---

# 15分でわかる！AIエージェント開発の最新フレームワーク OpenAI Agents SDK

[View on Qiita Trend](https://qiita.com/Kumacchiino/items/51a8ffee98eeb4f8d0c6?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

この記事は、OpenAIが新たに公開したAIエージェント開発フレームワーク「OpenAI Agents SDK」について、その概要とPythonでの実装例を解説するものです。このSDKを使うことで、複数のAIエージェントを連携させ、複雑なタスクを処理できるようになります。

記事では、SDKの主要な4つの概念である、Agents（エージェント）、Handoffs（ハンドオフ）、Guardrails（ガードレール）、Tracing（トレーシング）について解説しています。

*   **Agents（エージェント）**: フレームワークの中核となるコンポーネントで、名前、役割、使用モデル、ツールなどを設定して定義します。記事では旅費計算エージェントを例に、エージェントの定義方法と、エージェントが使用するツールの関数定義について説明しています。
*   **Handoffs（ハンドオフ）**: エージェントが他のエージェントにタスクを委譲する機能です。記事では、マネージャーエージェントがユーザーの質問を評価・分類し、住宅ローン計算エージェントや旅費計算エージェントにタスクを振り分ける例を紹介しています。
*   **Guardrails（ガードレール）**: ユーザー入力をチェックし、エージェントが意図しないタスクを実行しないようにする機能です。記事では、旅費計算や住宅ローン計算以外のタスクが依頼された場合に、その実行を拒否するガードレールの実装方法を解説しています。
*   **Tracing（トレーシング）**: エージェントの実行中に発生するLLMの生成、ツール呼び出し、ハンドオフなどのイベントを記録・可視化する機能です。これにより、エージェントシステムのデバッグ、可視化、監視が容易になります。

記事では、これらの概念を組み合わせたPythonプログラムの全体像を示し、住宅ローン計算、旅費計算、およびガードレールが作動する例を通して、実際の動作を解説しています。

まとめとして、OpenAI Agents SDKはAIエージェント開発を容易にする強力なフレームワークであり、今後のアップデートにも期待できると述べています。

---

# 【マルチモーダル】Phi-4-multimodalで音声ファイルからテキスト生成させる

[View on Qiita Trend](https://qiita.com/zawatti/items/599e2214ecdbab40edb2?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

この記事は、マルチモーダルモデルPhi-4-multimodalを用いて、音声ファイルからテキストを生成する実験結果をまとめたものです。

**背景:**

*   Phi-4-multimodalがSpeechToTextに対応しているため、その精度と速度に興味を持った。
*   音声入力からテキスト生成が可能なマルチモーダルAIの珍しさ。

**Phi-4-multimodalについて:**

*   Microsoftが発表したオープンソースLLM「Phi」ファミリーの最新モデル。
*   音声・画像・テキストに対応した小規模言語モデル（SLM）。
*   5.6Bのパラメータを持つマルチモーダル変換モデル。
*   バックボーンはPhi-4-Mini-Instruct。
*   事後学習で音声・視覚情報を処理するために「Mixture of LoRA」を実装。

**実行手順:**

1.  **実行環境の構築:** Google Colabで必要なライブラリをインストール。
2.  **モデル読み込み:** HuggingFaceからPhi-4-multimodalを読み込む。
3.  **推論:** サンプルコードのプロンプトを変更して実行。

**実行結果:**

*   音声ファイルからテキストを生成できた。
*   生成されたテキストは、音声の内容の要約と論点を記述。
*   推論に10秒から11秒かかる。

**今後の課題:**

*   録音した音声をアップロードして対話できるインターフェースの構築。
*   推論速度の向上。

**解決策:**

*   ngrokを使用して、Google Colabで簡易的な推論サーバを構築。
*   React/CSSで音声入力インターフェースを構築。
*   `torch.compile`でモデルをコンパイルし、モデルのウォームアップを行うことで推論を最適化。

**結論:**

Phi-4-multimodalは高いポテンシャルを持つ。音声入力による対話形式を想定した学習が行われていると感じた。今後は、音声出力にも対応させたい。


---

# CLIPをFine-Tuneして病理画像分類に挑戦してみた

[View on Qiita Trend](https://qiita.com/syun88/items/501b846646ad5e924598?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

この記事は、KaggleのNCT-CRC-HE-100Kデータセットを用いて、OpenAIのCLIPモデルをファインチューニングし、病理画像分類に挑戦した実験についてまとめたものです。データセットは、HE染色されたヒト癌組織スライドから抽出された10万枚の画像パッチで構成され、9つの組織クラスに分類されています。

実験では、まずCLIPモデルに線形分類器を追加し、病理画像分類用にファインチューニングを行いました。学習の進捗はtqdmで可視化し、クロスエントロピー損失とAdamオプティマイザを用いて学習を実施しました。

次に、学習済みファインチューニングモデルと元のCLIPモデルの推論結果を比較しました。元のCLIPモデルでは正解クラスの確率が低かったのに対し、ファインチューニング後のモデルでは正解クラスの確率が大幅に向上しました。

さらに、streamlitを用いてWebアプリケーションを作成し、アップロードされた画像に対して、オリジナルCLIPとファインチューニング済みモデルの分類結果を比較できるようにしました。

著者は、個人的な経験から人を助ける技術に触れたいという思いがあり、このプロジェクトを気分転換と自己成長のために取り組んでいます。今後は、得られた知見を活かし、日本で社会に貢献できる技術を開発していきたいと考えています。


---

# スライド版フリマサービスのPMを務めて学んだこと

[View on Qiita Trend](https://qiita.com/takahashi-yoji/items/05d3eb34803ef2c07085?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

スライド版フリマサービス「DocTok」のPMとして、要件定義からリリースまでのプロジェクトを通して学んだことについての記事です。

プロジェクトはウォーターフォール型で進められましたが、デザインや開発段階でも、プロダクトに良い影響を与える機能は追加されました。

**要件定義**

*   類似・競合サービスを実際に触って必要な要件を洗い出すことが重要。
*   プロダクトリリース後のマーケティングを考慮して要件定義を行うべき。
    *   ターゲット層に合わせたマーケティング施策によって必要な要件は変わる。
    *   SNSでの拡散を考慮したOGP設定やマイページ機能などが重要。
*   リリース後の分析・検証・改善サイクルで使用するツールも要件定義段階で検討すべき。
    *   売れ筋商品やユーザー単価を把握するための分析基盤（BigQueryなど）の導入を検討。
*   キャッシュフローの整理は最優先事項。
    *   Stripeなどの決済サービスの手数料体系を詳細に把握し、利用料や最低販売金額を決定。
    *   外部サービスの仕様はサポートセンターに確認し、認識齟齬がないようにする。

**WF/デザイン**

*   要件定義とWF（ワイヤーフレーム）は並行して進めるのが良い。
    *   WFを作成することで、要件定義の漏れやUX上の問題点を発見できる。
*   WFで動線や機能を詳細に詰めることで、デザインや開発がスムーズに進む。

**開発**

*   どんな小さな修正依頼でもBacklogに起票し、進捗を管理する。

**QA**

*   シナリオテストを実施し、UI面だけでなくバックエンドのロジック面もテストする。
    *   特に決済処理がある場合は、プラットフォーム手数料や振込手数料などを考慮して最終決済額が正しいかチェック。
*   QAで出た不具合に対し、POと相談して優先度を決め、期限内に修正箇所を精査する。

**まとめ**

*   仕様通りの開発だけでなく、リリース後のことを考えて要件定義することが重要。
*   限られたリソースの中で、機能開発や不具合修正の優先順位をチームで検討することで、プロダクトの品質を高められる。

---

# ゲーム開発環境だってオブザーバビリティを実現したい！

[View on Qiita Trend](https://qiita.com/ume67026265/items/bef6117fe211695c8011?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

この記事では、ゲーム開発環境におけるオブザーバビリティの実現方法について、New Relic を用いた具体的な例を挙げて解説しています。

まず、ゲーム開発環境は、バージョン管理、ジョブ管理、ビルド、ファイルサーバなどの要素で構成されており、それぞれのサーバやプロセスを監視することが重要であると述べています。

具体的な監視方法として、以下の内容を説明しています。

*   **バージョン管理システムサーバ (Perforce Helix Core, GitHub)**: Infrastructure Agent をインストールして CPU、メモリ、プロセスの稼働状況、ログを収集し、リアルタイムに状況を把握する。Helix Core のパフォーマンスを確認するコマンドの結果を New Relic に送信し、ダッシュボード化する。GitHub との連携による可視化。
*   **ジョブ管理サーバ (Jenkins)**: Jenkins と連携してジョブとパイプラインの実行を分散トレースとして視覚化する。APM や Browser の機能でパフォーマンスを計測する。Change Tracking を活用してデプロイ前後の変化を確認する。
*   **ビルドサーバ**: ビルドサーバのパフォーマンスを監視し、リソースの効率的な活用を図る。Incredibuild の Helper サーバの利用状況をリアルタイムで確認する。AWS の Billing データを取り込み、リソースとコストの相関を分析する。Unity のビルドで MacOS を活用する場合も、Infrastructure Agent で状況を把握する。Mobile Agent を使ってクライアントのパフォーマンス改善を行う。
*   **ファイルサーバ**: ディスクの使用率を Infrastructure Agent やクラウド連携による Metrics で確認する。Flex を使って容量を圧迫しているファイルを特定する。
*   **(Appendix)AIの活用**: AIを使ったアプリケーションの効率化として、レスポンスタイムやエラーの監視・改善を行う。

最後に、New Relic を活用して開発状況を可視化し、問題の早期発見・対応を行うことが、効率的な開発環境運用に繋がると結論付けています。

---

# Azureにおける通信制御の実現方法について

[View on Qiita Trend](https://qiita.com/bluesea_nishi/items/ca34cd3f6088f2a47762?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

Azureで通信制御を実現する方法について、インバウンドとアウトバウンドのアクセス制御に焦点を当て、具体的な設定方法と注意点を紹介しています。

**1. はじめに**

Azure環境でWAFやAzure Firewallなどを利用して通信制御を行う方法について、検証を通じて得られたノウハウを紹介。

**2. 前提**

*   Azure Front DoorでPrivate Linkを使用して配信元(BLOB)を保護
*   WAF導入済み
*   アクセス元のIPを制限（変動するIPアドレスにも対応）
*   コスト優先度は高くない

**3. アクセス制御の実現方法 (インバウンド)**

*   **静的コンテンツに対するIP制限:** WAFのカスタムルールを使用。特定のIPアドレスからのBLOBへの直接アクセスを制限。IPv6アドレスからのアクセスも考慮し、IPv6拒否ルールも設定する必要がある。
*   **IPが変動する場合のアクセス制御:** WAFのカスタムルールで、HTTPリクエスト情報に基づいた制限を行う。HTTPリクエストヘッダーに含まれる特定の文字列を基にアクセスを拒否するルールを設定。アクセスログを解析し、HTTPリクエスト情報を追跡してWAFルールを調整する方法も有効。NSGやAzure Firewallの仮想ネットワークサービスタグはMicrosoft管理サービスに限定される。

**4. アクセス制御の実現方法 (アウトバウンド)**

*   **Azure Firewallによるアクセス制御:** Azure Firewallを使用してアウトバウンド通信をフィルタリング。Webカテゴリによるフィルタリングを利用し、有害サイトへのアクセスを制御。セキュリティ要件を満たせるか検討が必要。Webカテゴリ機能はAzure Firewall Standard以上でのみ利用可能。

**5. まとめ**

システム構成や制約に応じて最適な通信制御方法を選択することが重要。


---

# Google News の RSS から元記事の URL を得る AWS Lambda 関数と応用例の紹介

[View on Qiita Trend](https://qiita.com/nasuvitz/items/609ad4bcacd56b154acc?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

この文章は、Google NewsのRSSフィードから提供されるエンコードされたURLをデコードし、元のニュース記事のURLを取得するためのAWS Lambda関数の実装について解説しています。

**背景と目的:**

Google NewsのRSSフィードに含まれるURLは、直接的なニュースソースのURLではなく、Google独自のエンコード形式が用いられています。この記事では、このエンコードされたURLを解析し、元のURLを復元する技術的アプローチを紹介します。AWS Lambdaと組み合わせることで、この処理をサーバレスでスケーラブルに運用し、他のサービスと組み合わせて応用することを目指しています。

**コードの解説:**

記事では、GoogleDecoderクラスを中心に、以下のメソッドについて解説しています。

*   **`__init__`**: クラスの初期化処理で、プロキシの設定やデバッグモードの管理を行います。
*   **`_build_opener`**: プロキシ設定がある場合に、ProxyHandlerを用いてopenerを構築します。
*   **`get_base64_str`**: Google NewsのURLからBase64文字列を抽出します。URLの形式が想定と異なる場合はエラーを返します。
*   **`get_decoding_params`**: 抽出したBase64文字列から、署名（signature）とタイムスタンプ（timestamp）を取得します。最初に`https://news.google.com/articles/{base64_str}`を試し、エラーが発生した場合は`https://news.google.com/rss/articles/{base64_str}`を試すフォールバック処理を実装しています。
*   **`decode_url`**: 署名、タイムスタンプ、Base64文字列を組み合わせて、Google Newsの内部APIにPOSTリクエストを送信し、元のURLを取得します。
*   **`decode_google_news_url`**: 上記の各メソッドを統合し、一連のデコード処理を実行します。必要に応じて、APIへのアクセス頻度を制御するための遅延（interval）を挿入します。
*   **`lambda_handler`**: AWS Lambdaのエントリーポイントとして、イベントからパラメータを取得し、GoogleDecoderを構築して`decode_google_news_url`を呼び出し、結果を返します。

**エラーハンドリングとログ出力:**

コード全体を通して、HTTPエラー、URLエラー、JSONパースエラーなど、想定されるエラーに対して、詳細なエラーハンドリングを実装しています。エラーが発生した箇所を特定しやすいように、メソッド名とエラー要因をログに記録します。

**応用例:**

このLambda関数とAWSの生成AIサービス（Amazon Bedrockなど）を組み合わせることで、以下のような応用例が考えられます。

*   リアルタイムな情報分析・要約
*   キーポイントの抽出
*   AIエージェントによる最新情報を参考にした資料作成

**まとめ:**

この記事では、AWS Lambda関数を使用してGoogle NewsのエンコードされたURLをデコードし、元のニュース記事のURLを取得する方法を解説しました。この技術は、トレンド記事のデータベース化や、生成AIを活用した記事分析など、様々な場面で役立つ可能性があります。

**特記事項:**

*   この記事で紹介されているコードは、オープンソースのSSujitX/google-news-url-decoderをベースに、AWS Lambdaで動作するように一部改変されたものです。
*   オリジナルのコードではrequestsライブラリが使用されていますが、Lambda関数で実行するためにurllib.requestに置き換えられています。
*   Web上の記事やファイルを取得する際は、著作権や利用規約に注意が必要です。


---

# エレコム、世界初のナトリウムイオンモバイルバッテリ。従来より長寿命で安全

[View on Hatena Trend](https://pc.watch.impress.co.jp/docs/news/1669565.html)

エレコムは、世界初となるナトリウムイオン電池を採用したモバイルバッテリー「DE-C55L-9000BK」「DE-C55L-9000LGY」を発表した。このバッテリーは、従来のリチウムイオンバッテリーに比べて長寿命で安全性が高く、低温環境下でも使用できるという特徴を持つ。

この製品は、9,000mAhの容量を持ち、USB Type-CとType-Aポートをそれぞれ1つ搭載している。Type-Cポートは45W出力と30W入力に対応し、USB PDとPPSをサポートする。Type-Aポートは18W出力に対応する。

エレコムは、モバイルバッテリーのリーディング企業として、発火事故の増加やリチウムイオン電池による環境汚染などの課題を解決するために、このナトリウムイオンモバイルバッテリーを開発した。ナトリウムイオン電池は、コバルトやリチウムなどのレアメタルを使用せず、-35℃から50℃までの幅広い温度環境で使用でき、5,000回の充放電サイクルを実現する長寿命である点が特徴。

現状ではナトリウムイオン電池はPSEの対象外だが、エレコムは同等のテストを実施し、安全性に配慮した設計を行っている。廃棄方法については、地方自治体に問い合わせるか、エレコムのサポートセンターに連絡する必要がある。

環境負荷低減のため、筐体には再生プラスチックを使用し、パッケージも紙製にするなど、環境に配慮した設計となっている。エレコムは今後、ナトリウムイオン電池をはじめとする次世代電池の採用を拡大し、全固体電池を搭載したモバイルバッテリーの実用化を目指すとしている。

---

# 勢いでつくったSQLツールと歩んだ28年。フリーソフト「A5:SQL Mk-2」開発秘話【フォーカス】 レバテックラボ（レバテックLAB）

[View on Hatena Trend](https://levtech.jp/media/article/focus/detail_633/)

「A5:SQL Mk-2」は、開発者の松原正和氏が1997年から個人で開発を続けているフリーのSQLクライアントツールです。MySQLをはじめとする主要なデータベースに対応し、SQLの実行・編集、ER図作成など、データベース開発に関わる「全て」をカバーすることを目指しています。近年では、ChatGPTなどのLLMと連携したAIアシスタント機能も実装されました。

開発のきっかけは、社内で使用されていたSQL実行ソフトに対抗意識を燃やしたことでした。当初は社内向けツールとして開発されましたが、その後多くの人に使ってもらいたいと考え、2003年にフリーソフトとして公開されました。

公開当初はなかなか広まらず、業務で使用許可が下りないこともありましたが、松原氏は派遣先で積極的にプレゼンを行い、実際に使用しながら改善を重ねました。特に、SIerの現場で頻繁に行われるExcelへのデータ貼り付け作業を効率化する機能など、現場のニーズに応える実用的な改善を重ねた結果、徐々に知名度が向上していきました。

開発費用の負担から、有料化も検討されましたが、「無料だからこそ多くの人に使ってもらえる」という考えから、フリーソフトとしての提供を続けています。2022年には、ODBCドライバーを販売するCData Softwareからのスポンサーシップを受け、開発収支が黒字化しました。

今後の目標は、「A5:SQL Mk-2」のオープンソース化です。しかし、長年の開発でコードが属人化しており、ソフトウェアライセンスが不明瞭なライブラリも存在するため、リファクタリングやライブラリの置き換えが必要となります。定年退職後、本腰を入れてオープンソース化に取り組む予定です。

松原氏は、「A5:SQL Mk-2」の開発を「自分の葬式の前日まで」続けるつもりだと語ります。このツールが少しでも多くのエンジニアの役に立ち、開発現場の課題解決に貢献することを願っています。


---

# Web制作者はダウンロードしておきたい！ CSS関連の最新版チートシートのまとめ

[View on Hatena Trend](https://coliss.com/articles/build-websites/operation/css/css-cheatsheets-2025.html)

この記事は、Web制作者向けにCSS関連の最新チートシートをまとめたものです。CSS Grid、Flexboxのプロパティや値、セレクタ、nth-child()、display、positionなど、CSSに関する様々なチートシートが紹介されています。

これらのチートシートは無料でダウンロード可能で、高解像度版も用意されています。モニターの壁紙にしたり、印刷して手元に置いておくことで、コーディング時の「あれは何だっけ？」という疑問をすぐに解決できます。

記事では、それぞれのチートシートの内容についても簡単に解説しています。例えば、FlexboxやGridのチートシートでは、各プロパティと値がどのようにレイアウトに影響するかを視覚的に確認できます。セレクタのチートシートでは、基本的なセレクタから疑似クラス、疑似要素まで、CSSで利用できる様々なセレクタがまとめられています。

その他にも、CSSアニメーション、フォント関連、CSSで使用できる単位、VS Codeのショートカット、Gitのコマンドなど、Web制作に役立つ様々なチートシートが紹介されています。

---

# みんなパスキーに期待しすぎている。MIXI伊東氏に聞く「認証のゴール地点」の考え方 | レバテックラボ（レバテックLAB）

[View on Hatena Trend](https://levtech.jp/media/article/interview/detail_632/)

この記事は、パスワードレス認証として注目されるパスキーについて、MIXIの伊東諒氏にインタビューした内容をまとめたものです。

**パスキーの革新性と課題:**

*   パスキーの最大の革新性は、フィッシング攻撃への耐性です。これは、認証情報を「人間に生成させない」「人間に記憶させない」「人間に入力させない」ことで、ヒューマンエラーのリスクを排除しているためです。
*   しかし、「パスキーを実装するならパスワードを廃止すべき」というプレッシャーが開発者には存在します。パスキーの恩恵を最大限に得るためには、パスキー以外の認証方法を廃止することが理想ですが、ユーザーの反発や非対応環境への対応など現実的な課題があります。

**MIXIのパスキー導入事例:**

*   MIXIでは、キャッシュレス決済サービス「MIXI M」で最初にパスキーを導入しました。MIXI Mでは、以前からSMS認証のみのフルパスワードレスを採用していましたが、SMS認証の課題を解決するためにパスキーを導入しました。
*   パスキー導入にあたっては、UXへの懸念から1年以上の検討期間を要しました。ブラウザの「Passkey Autofill」機能の登場により、ユーザー体験を大きく損なわずにパスキー認証を提供できると判断し、実装に至りました。

**認証のゴール地点:**

*   パスキーが普及するためには、段階的な移行が必要であり、パスワードマネージャーの普及が鍵となります。パスワードマネージャーによって、ユーザーは認証情報の生成・記憶・入力をシステムに委ねることに慣れてもらう必要があります。
*   認証に絶対的な正解はなく、サービスごとに最適な認証方式は異なります。目標とするセキュリティレベルを設定し、その実現のために最適な技術を選択・実装できる環境を維持することが重要です。
*   パスキーの普及後も攻撃者とのいたちごっこは続くため、認証に関わる開発者は常に新たな脅威に対応していく必要があります。

---

# OpenSearchで日本語全文検索をするためのドメイン知識を整理する - ドワンゴ教育サービス開発者ブログ

[View on Hatena Trend](https://blog.nnn.dev/entry/2025/03/13/110000)

ドワンゴ教育サービスのZEN Studyにおける新しい教材基盤（Kotlin）で、AWS OpenSearch Serviceを利用したコンテンツ管理のための全文検索機能を導入するにあたり、OpenSearchの各種概念モデルの概要をまとめた記事。

対象外：日本語全文検索と直接関係しない検索機能、クラスタリングやシャーディングなどの物理設計、エンドポイント仕様など具体的な利用方法、AWS OpenSearch Service の独自部分。

**ドキュメントとインデックス**
- ドキュメント：OpenSearchに登録されるJSON形式の文書データ。RDBのレコードに相当。各ドキュメントは一意の`_id`と更新回数を記録する`_version`を持つ。
- インデックス：ドキュメントの論理的な格納場所。RDBのテーブルに相当。アナライザとマッピングの設定を持つ。設定には動的な設定と、作成時に設定したら変更できない静的な設定がある。

**アナライザ**
- 全文検索で転置インデックスを作成する方法を指定する部品。
- 1つのTokenizerと、0個以上のCharacter Filter/Token Filterで構成される。
    - Tokenizer：文字列をトークン（見出し語）に分割する方法を指定。日本語ではn-gramや形態素解析が用いられる。
        - n-gram：文章を機械的にn文字単位で分割。シンプルだが、不要な単語でヒットする問題やデータ量の増加がある。
        - 形態素解析：文章を単語単位で分割。単語の揺れに対応できない場合がある。kuromojiとSudachiという2種類の形態素解析エンジンがプラグインとして用意されている。
    - Character Filter：Tokenizerによる分割の前処理。全角半角の正規化やHTMLタグの除去などを行う。
    - Token Filter：Tokenizerによる分割の後処理。同義語の追加、表記揺れの統一、ストップワードの除去などを行う。

**マッピング**
- ドキュメントに含まれる属性（フィールド）とその型を定義する部品。RDBのテーブルスキーマ定義に相当。
- 動的マッピングと明示的マッピングの2種類がある。
    - フィールド型：文字列、数値、ブール値、日時など。
        - 文字列型：text型（全文検索用、アナライザによる分析あり）とkeyword型（完全一致検索用、分析なし）がある。
        - 配列型：明示的な配列型は存在しないが、全てのフィールドに複数の値を含めることができる。
        - null：デフォルトでは属性名ごと存在しない扱いになる。null_valueを指定することで、nullとして扱う値を設定できる。
        - Multifields：同じフィールドを複数の型で扱いたい場合に、フィールドをネストさせることが可能。

**検索クエリ**
- JSONで表現される独自のDSLを使用。
- 検索結果には、ヒットしたドキュメント一覧、総件数、クエリへの一致度を示す`_score`が含まれる。
- ソート、ページネーション、ハイライト表示などが可能。
- クエリはleaf queryとcompound queryに大別される。
    - Leaf Query：単一フィールドを検索対象とする。
        - term-level query：text型以外のフィールドを対象。条件に一致するか否かで判断される。
        - full-text query：text型を対象とした全文検索用のクエリ。_scoreを使って関連度順にソート可能。match, match_bool_prefix, match_phrase, multi_match, query_stringなどがある。
    - Compound Query：複数のクエリを組み合わせる。Boolean Queryについて説明。
        - Boolean Query：複数のクエリをANDやORで組み合わせる。must（AND条件）、should（OR条件）などの属性が含まれる。

**まとめ**
OpenSearchで日本語全文検索を行うためのドメイン知識として、ドキュメントとインデックス、アナライザ（Tokenizer、Character Filter、Token Filter）、マッピング（フィールド型、Multifields）、検索クエリ（Leaf Query、Compound Query）について、それぞれの概念と設定方法を説明。

---

# 「AIがあるんだからもっと安く早く作れるでしょ？」と非エンジニアに言われた時に読む（読んでもらう）記事 - Qiita

[View on Hatena Trend](https://qiita.com/ku_suke/items/577bdb839b411fe75e44)

この記事は、非エンジニアから「AIがあるんだから、もっと安く早く作れるでしょ？」と言われた際に、エンジニアが抱える課題やAIの活用方法について解説するものです。

AIは、ゼロから新しいものを作るのは得意ですが、既存の複雑なシステムに機能を追加したり、修正したりするのは苦手です。なぜなら、AIは学習データに基づいてコードを生成しますが、企業の内部システムや独自のコードに関する知識を持っていないため、部分的な情報だけでは適切なコードを生成できないからです。

しかし、AIを全く活用できないわけではありません。AIは、タスクを細分化し、特定の工程に特化させることで、開発の生産性を向上させることができます。例えば、Github CopilotのようなAIツールを導入し、エンジニアが使いこなすことで、コードの自動生成やテスト、ドキュメント作成などの作業を効率化できます。

また、プログラミング以外の工程、例えば要件定義、画面設計、進捗報告書の作成などにもAIを活用することで、全体的な開発効率を向上させることができます。特に、部署間のコミュニケーションにおいて、AIによる翻訳や情報整理は有効です。

重要なのは、AIができることとできないことを見極め、適切なツールを導入し、エンジニアがAIを使いこなせるようにサポートすることです。そして、AIを活用した経験を共有し、どの工程でAIが有効なのかを見つけ出すことが、生産性向上につながります。

まとめると、

*   既存システムへのAIの適用は難しい
*   PoCや設計書作成など、新規開発におけるAI活用は有効
*   タスクを細分化し、AIが得意な工程に適用することで生産性を向上
*   AIツールを導入し、エンジニアが使いこなせるようにサポート
*   AI活用経験を共有し、有効な活用方法を見つける
*   プログラミング以外の工程にもAIを活用
*   部署間のコミュニケーションにAIを活用

人手不足が深刻な現代において、AIの支援を受けながら、抽象度の高い仕事ができるようにすることが重要です。

---

# 土星の衛星、一気に128個も増える　現在274個

[View on Hatena Trend](https://www.itmedia.co.jp/news/articles/2503/13/news147.html)

土星の衛星が新たに128個発見され、合計274個となり、木星の95個を大きく上回り、太陽系で最も多くの衛星を持つ惑星となった。

カナダ・フランス・ハワイ望遠鏡（CFHT）を用いて、2019年から2021年にかけて土星周辺を広範囲に観測した。複数の画像を組み合わせて分析し、軌道を特定することで、小さな衛星を発見した。

これらの衛星の大きさは約5kmで、すべて不規則衛星と呼ばれるもので、惑星の形成時に残った破片や、大きな天体が衝突してできたものと考えられている。研究チームは、これらの衛星が過去に別の衛星と衝突してできた可能性があると考えている。


---

# 安全性は高いのに……モバイルバッテリーに「PSEマーク」表示できないエレコムのジレンマ、それでも販売できる理由

[View on Hatena Trend](https://www.itmedia.co.jp/news/articles/2503/13/news192.html)

エレコムが、安全性の高い新しいリチウムイオンポリマー電池を採用したモバイルバッテリー「DE-C55L-9000シリーズ」を発売したが、製品にPSEマークが表示されていない。

PSEマークは、電気用品安全法に基づき、製品が安全基準を満たしていることを示すもの。モバイルバッテリーは2019年2月からPSEマークの表示が義務付けられ、表示のない製品は販売できない。PSEマークを表示するには、登録検査機関による適合性検査を受け、その証明書を提出する必要がある。検査では、短絡試験や過充電試験など、様々な安全性を確認するための試験が行われる。

エレコムによると、今回のモバイルバッテリーは、従来の一般的なリチウムイオン電池よりも安全性の高い電池を採用しているため、本来はより安全な製品。PSEマークを表示しない理由は、モバイルバッテリーには、リチウムイオン蓄電池の技術基準が適用されるため、新しいリチウムイオンポリマー電池は「規制対象外」となり、PSEマークがなくても販売できる。

ただし、PSEマークがない場合、販売時に注意が必要となる。販売店によってはPSEマークがない製品の販売を控える場合があるからだ。エレコムは、販売店に対し、今回の製品が法律に違反していないことを説明し、理解を求めている。

---

# 私のよく使うソフトウェアアーキテクチャの雛型

[View on Hatena Trend](https://zenn.dev/m10maeda/articles/my-favorite-architecture-blueprint)

この記事は、イベント駆動とCQRSを意識したレイヤードアーキテクチャに基づいた、ヘキサゴナルアーキテクチャのソフトウェアアーキテクチャの雛形を紹介しています。

**構成要素:**

*   **レイヤードアーキテクチャ:** プレゼンテーション層、アプリケーション層、ドメイン層、インフラストラクチャー層の4層構造。
*   **ディレクトリ構成:** 各層の役割に対応したディレクトリ構造。
*   **ドメイン層:**
    *   `Event`: ドメインで発生した出来事を表すオブジェクト。
    *   `IEventSubscriber`: Eventを受け取った後の処理を行うインターフェース。
    *   `IEventPublisher`: IEventSubscriberにEventを通知するインターフェース（インフラストラクチャー層でEventBusとして実装）。
    *   `Aggregate`: 整合性を保つために同時に変更する必要があるデータの集まりを表すオブジェクト。状態を変更する振る舞いはEventを返す。
    *   `IRepository`: Aggregateの取得を永続化メカニズムから隠蔽するインターフェース。
    *   `IFactory`: Aggregateの生成処理を隠蔽するインターフェース。
*   **アプリケーション層:**
    *   `IUseCaseInputPort`: ビジネスユースケースを実現するインターフェース。コマンド(操作)用とクエリ(参照)用に分け、InteractorとQueryServiceとして実装。
    *   `Interactor`: 副作用を持つコマンドのユースケース実装クラス。ドメイン層のオブジェクトを使用し、IEventPublisherにEventを発行。
*   **インフラストラクチャー層:**
    *   `EventBus`: IEventPublisherを実装し、購読しているIEventSubscriberにイベントを渡す。
    *   `EventStore`: IEventSubscriberを実装し、受け取ったEventを永続化する。
    *   `Repository`: IRepositoryの実装クラスで、蓄積されたEventからAggregateを復元して返す。
    *   `Factory`: IFactoryの実装クラス。
    *   `Messenger`: IEventSubscriberを実装。検知したEventを外部サービスへ通知。
*   **プレゼンテーション層:**
    *   `Controller`: ソフトウェアの入出力を担当。IUseCaseInputPortを呼び出し、レスポンスを整形して出力。

**処理の流れ:**

*   **コマンド:** Controller -> IUseCaseInputPort -> Interactor -> Aggregate -> Event -> IEventPublisher -> Controller
*   **クエリ:** Controller -> IUseCaseInputPort -> QueryService -> Controller

**データの永続化:**

*   イベントソーシングを使用し、Eventを蓄積してAggregateの最新状態を復元。Aggregateの状態を保存する必要はない。

**フロントエンド:**

*   モダンフロントエンドでは、フレームワークのプラクティスに従い、ビジネスロジックを隔離するためのアーキテクチャは不要なケースが多い。

サンプルプロジェクトへのリンクも提供されています。


---

# 花粉を出さないスギ「春凪」、静岡大が開発　研究期間15年の成果　「花粉症に苦しんだ時期に静かに暮らせるように」

[View on Hatena Trend](https://www.itmedia.co.jp/news/articles/2503/13/news195.html)

静岡大学などの研究グループは、花粉を出さないスギ「春凪（はるなぎ）」を開発したと発表しました。これは15年にわたる研究の成果で、花粉症に苦しむ人々が静かに暮らせるようにという願いが込められています。

このスギは、雄花で花粉を作れない性質を持つ突然変異体を活用し、育種や栽培などにも問題がない品種です。研究グループは、2010年にこの突然変異体を持つスギを開発し、2023年には成長や性質、花粉の少なさなどを確認し、一つの品種として確立しました。この品種は、品種登録を出願しており、「品種登録出願中」と表示されます。

開発者は、「春（花粉）の時期に静かに暮らせるように」という思いを込めてこの名前を付けました。今後は、大学などでの植栽や、種苗の生産と新たな花粉症対策としての普及を目指しています。

---

# メシウス、WebアプリケーションでExcelライクなUIや機能を実現する「SpreadJS V18J」をリリース

[View on CodeZine Trend](http://codezine.jp/article/detail/21166)

メシウスは、WebアプリケーションにExcelライクなUIと機能を提供するJavaScriptライブラリ「SpreadJS V18J」を3月26日にリリースする。価格は1開発ライセンスが220,000円、1配布ライセンス（1ドメイン）が660,000円で、1年定額制のサブスクリプション方式。

新機能として、データ管理機能「データマネージャー」のデータを基にしたチャート生成を可能にする「データチャート」が追加された。これにより、データベースから取得したデータを用いてチャートを作成し、シートに表示できる。従来のチャートよりもグラフ要素のカスタマイズ性が向上している。複数のテーブルを組み合わせたリレーショナルテーブルもデータソースとして利用可能。

データマネージャーをデータソースとするデータチャートは、同じくデータマネージャーをデータソースとするレポートシートでのチャート表示に適しており、ダッシュボードや報告書などでグラフィカルな表現が可能になる。

---

# フリーランスの4割近くが正社員への転向を検討。転向者の約6割はマネジメント職種の経験あり

[View on CodeZine Trend](http://codezine.jp/article/detail/21167)

ファインディが実施した調査によると、IT/Webフリーランスエンジニアの37%が正社員への転向を検討したことがあり、実際に転向した人の40%は当初正社員の意向はなかった。転向理由は「働く人の魅力」「会社の将来性」「年収などの条件」が重要視され、転向者の約6割はマネジメント職経験者（プロジェクトマネージャー、エンジニアマネージャー、プロダクトマネージャーなど）。正社員を検討して転向しなかった理由は「年収やリモートなどの条件で合意できない」が多い。フリーランスの働き方には年収やリモート可否が影響し、フルリモート希望は74.3%。テレワーク導入減少傾向から、今後もテレワーク導入率・フルリモート可否が企業選択に影響すると予想される。フルリモート希望理由としては「通勤時間の削減・遠方在住・家庭の事情」が挙げられている。

---

# BizTech、「最新生成AIツール・モデル調査レポート（2025.2.25 - 3.11）」を無料公開

[View on CodeZine Trend](http://codezine.jp/article/detail/21168)

BizTechが、2025年2月25日から3月11日までの生成AI技術トレンドをまとめた「最新生成AIツール・モデル調査レポート（2025.2.25 - 3.11）」を3月12日に無料公開した。このレポートは、XやGitHub、Product Huntなどで話題のエンジニアリング寄りの技術やツール・モデル（LLM、画像生成、動画生成など）、技術系スタートアップ情報などを収集・掲載している。主な掲載情報として、Alexa＋（AmazonのAlexa大幅アップデート）、Manus（中国発自律型汎用AIエージェント）、exa.ai webset（高性能web research agent）、Mercury Coder（拡散モデルのチャットサービス）、Scribe（elevenLabの音声認識モデル）が挙げられている。このレポートは、最新の生成AI情報についていけていない人、最新モデルや機能を押さえたい人、AIのプロがまとめた情報をチェックしたい人に適している。

---

# macOS上のアプリケーションからChatGPTが呼び出せるように。各種IDEやターミナル、メモなどが対応

[View on CodeZine Trend](http://codezine.jp/article/detail/21169)

OpenAIがChatGPTのバージョン1.2025.057以降で、macOS上の各種IDE、ターミナル、メモなどのコーディングツールからChatGPTを呼び出せるようにした。Option + Spaceキーを押すか、メニューバーのアイコンをクリックしてチャットバーを開き、ChatGPTのメインウィンドウから手動で呼び出すことも可能。現在は特定のコーディングツールとテキストエディタのみ対応しており、今後対応アプリを追加予定。
対応アプリケーションは、メモ、Notion、テキストエディット、Quip、Xcode、Visual Studio Code、Jetbrains (Android Studio, IntelliJ, PyCharm, WebStorm, PHPStorm, CLion, Rider, RubyMine, AppCode, GoLand, DataGripを含む)、ターミナル、iTerm、Warp、Prompt。

---

# 世界6000万ユーザーの「TimeTree」、サービスの未来を見据えて挑んだデータベース移行の舞台裏

[View on CodeZine Trend](http://codezine.jp/article/detail/21038)

TimeTreeは、全世界で6000万人のユーザーを抱えるカレンダーシェアアプリ。
以前はAmazon RDSを使用していたが、データ量の増加に伴いAuroraへ移行。
しかし、Auroraでもデータ量の増加やスキーマ変更時のダウンタイム発生といった課題が生じ、サービスの進化を妨げる要因となっていた。
そこで、Google Cloud Spannerへの移行プロジェクトが立ち上がった。

移行先としてSpannerを選定した理由は、大規模なデータを持つスキーマの変更が容易であること。
移行は3つのステップで実施され、プロジェクトを円滑に進めるための工夫も行われた。
TimeTreeのSREチームのマネージャーである金井栄喜氏と、SREチームのバックエンドエンジニアであるGreg氏へのインタビューを通して、Spanner移行の背景や成功の秘訣が語られている。

---

# JavaScriptのMath.sumPrecise()の静的メソッドをサポート、「Firefox 137」ベータ版が提供開始

[View on CodeZine Trend](http://codezine.jp/article/detail/21171)

MozillaがWebブラウザ「Firefox 137」のベータ版を公開した。このベータ版では、JavaScriptのMath.sumPrecise()静的メソッドのサポート、<discard> SVG要素と対応するJavaScriptインターフェースのサポート、SVGパスデータ操作APIのサポートが追加された。また、AndroidではHEVC（H.265）動画のハードウェア再生、Linuxではハードウェア・ソフトウェア両方の再生に対応した。正式リリースは4月1日を予定している。

---

# 「ExpressVPN」のLinux向けアプリが大幅アップデート、GUIの追加など

[View on CodeZine Trend](http://codezine.jp/article/detail/21172)

VPNサービス「ExpressVPN」が、Linux向けアプリの大幅アップデートをベータテスト版として公開した。
これまではコマンドライン操作が必要だったVPN制御や設定変更が、GUIの導入によりクリック操作で可能になる。
ライト/ダークモード、17言語対応、自動接続機能、チャットサポートなども追加。
既存アプリのアンインストール後、新アプリをインストールする必要がある。
今後数か月で更なる機能追加が予定されており、ベータプログラムへの参加が呼びかけられている。

---

# Google、Google Cloud Trace Explorerを刷新

[View on CodeZine Trend](http://codezine.jp/article/detail/21173)

Googleは、監視ツール「Google Cloud Observability」の一部である「Google Cloud Trace Explorer」をアップデートした。UIに多数の改善が加えられ、トレーススコープ、スパン、カスタム属性のフィルターを備えたフィルターバーや、該当するスパンをヒートマップやグラフで視覚化する機能などが追加されている。新しいTrace Explorerを使用することで、トレースデータの高度なクエリとビジュアライゼーションによって、開発者やSREは本番環境のインシデントを効率的に発見し対処できる。新しいTrace Explorerはすでにすべてのユーザーに一般公開されている。

---

# お絵描きアプリをグレードアップさせよう！Tauri 2.0でアンドゥとリドゥを実装

[View on CodeZine Trend](http://codezine.jp/article/detail/20894)

この記事は、Tauri 2.0とRustを使ってお絵描きアプリを開発する連載の第5回で、アプリの機能を向上させる方法を解説する。

主な内容は以下の通り。

1. **描画矩形のリサイズ**:
   - `<canvas>`タグの描画領域を画面幅いっぱいに広げる。
   - ウィンドウのリサイズに合わせて`<canvas>`タグもリサイズされるようにする。
   - スクロールバーが表示されないように`<canvas>`の高さを調整し、代わりに説明文を追加する。

2. **アンドゥとリドゥの実装**:
   - マウスホイールを使ってアンドゥとリドゥができるようにする。

3. **サンプルデータの表示**:
   - サンプルのトイプードルの画像を表示できるようにする。

4. **アプリアイコンの変更**

その他、ESモジュールに関する注意点や、Tauri 2.0向けのWebページをWebブラウザでテストする方法について解説する。

---

# オープンソースのWebアプリケーション／Webサイトフレームワーク「Nuxt 3.16」がリリース

[View on CodeZine Trend](http://codezine.jp/article/detail/21165)

オープンソースのWebアプリケーション/Webサイトフレームワーク「Nuxt」の開発チームは、「Nuxt 3.16」をリリースした。
Nuxt 3.16では、Nuxtプロジェクトを開始するためのツールcreate-nuxtが追加、unheadエンジンがv2へアップグレード、Devtoolsがv2へアップグレードされ、カスタムエディタの選択、解決済みの設定を検査するためのDiscovery.jsが追加、スキーマジェネレータが復活。
その他、モジュール解決の高速化、スマートなモジュール解決パスの導入、重複したNitroエイリアス解決の排除によるファイル処理の効率化などが行われ、パフォーマンスが改善。
コンポーネントがハイドレーションするタイミングの制御、初回ロードのパフォーマンス向上、インタラクティブになるまでの時間を早める遅延/レイジーハイドレーションのネイティブサポートが追加、ページをスキャンするファイルの微調整が可能になるなど、機能追加・改善が行われている。
