
# 第10回SmartHR LT大会レポート ── 開催2年目突入！ 2025年1発目！ | SmartHR Tech Blog

[View on Company Blog](https://tech.smarthr.jp/entry/2025/03/11/184352)

2025年2月21日に開催された第10回SmartHR LT大会のレポート。

イベント概要:
SmartHR LT大会は、プロダクトエンジニアが企画・運営する社内イベント。
11名のプロダクトエンジニアが5分間のLTを行う。
職種を問わず社員は聴講可能で、リモート参加も可能。

参加者数:
現地参加者：55名（うち登壇者：11名）
オンライン参加者：21名
懇親会参加者：46名

LT内容:
LGTM画像のすゝめ：犬好きのkawaさんが、Pull Requestで利用されるLGTM画像について、犬のLGTM画像を効率的に探す方法を紹介。Chrome拡張機能やChatGPTの活用法も。
サブスク管理って？ 調べてみました：yurikoさんが、サブスク管理チームの業務内容と、現在取り組んでいるプロジェクトを紹介。
わん うぃーく with Rails 7.1 → 7.2 → 8.0：gongoさんが、Railsのバージョンを1週間でアップデートした経験について、アクションを起こすまでの心理と、バリューを発揮した話を紹介。
オンボしようと頑張ったらついでに感謝もされた話：masaruさんが、チームにジョインしたばかりの頃、チームの暗黙知をドキュメントにまとめた結果、感謝されたという心温まる話を紹介。
ENFPがAIに救われた話：wassanさんが、ENFP（広報運動家）の特性を持つ自身が、AIを活用して情熱の赴くままに生きる方法を紹介。作業時間の大幅な短縮に成功。
作業環境にこだわるぞ Part2：willnetさんが、リモートワークでの集中しすぎを防ぐために、ポモドーロテクニックとアプリFocusを活用している話を紹介。Focusのフルウインドウ機能で休憩中の集中も実現。
瓢湖と鳥とAI：ikkunさんが、趣味のバードウォッチングをテーマに、画像認識とLLMを用いてカモの種類をAIに分類させるアプリケーションを紹介。
〇〇（社外秘）の正体：shinokuさんが、新規事業チームの立ち上げ期ならではの難しさと面白さを紹介。
YJITの仕組みとチューニングの超入門：yudaiさんが、Rubyのプログラム実行の流れからYJITの仕組み、チューニング方法までを紹介。
劇的に浅い新興 DB の話：hotakaさんが、新しい国産RDB「Tsurugi」の性能や特徴、コスト、SmartHRでの導入可能性について紹介。
レーダーをつくる：bmf-sanが、技術動向を知るためのWebサービス「Technology Radar」を紹介。個人でもオリジナルを作成できる点をアピール。

その他:
LT大会後には、登壇者と参加者で記念撮影を実施。
懇親会では、LTで時間が足りなかったカモの分類アプリケーションのデモが行われた。
次回のLT大会は4/25（金）に「AI」をテーマに開催予定。


---

# GKEの新機能と不具合情報まとめ 2025年2月 | WHITEPLUS TechBlog

[View on Company Blog](https://blog.wh-plus.co.jp/entry/2025/03/11/183549)

2025年2月のGKEの新機能、変更点、および不具合情報のまとめです。

**新機能**

*   **GKE Recommendationsの追加:** IAMパーミッションが不足しているサービスアカウントを持つクラスタを特定するのに役立つ新しい推奨事項「NODE\_SA\_MISSING\_PERMISSIONS」が追加されました。
*   **GKE Autopilotパートナープログラムの拡張:** パートナーが特定のワークロードに対応する許可リストを作成・管理できるようになりました（GKE 1.32.1-gke.1729000以降）。
*   **ノードとノードプールの状態に関する新しいメトリクスの追加:**
    *   `kubernetes.io/node/status_condition`: ノードの状態を監視。
    *   `kubernetes.io/node_pool/multi_host/available`: マルチホストNodePoolの可用性。
    *   `kubernetes.io/node_pool/status`: ノードプールの現在のステータス。
    これらのメトリクスはGKE 1.32.1-gke.1260000以降で利用可能です。
*   **GKE Managed NVIDIA Data Center GPU Manager (DCGM) Metrics PackageのGA:** NVIDIA GPUの使用率、パフォーマンス、健全性を監視するためのメトリクスを提供します（GKE 1.32.0-gke.1764000以降）。GKE 1.32.1-gke.1357000以降では新しいクラスタでデフォルトで有効になります。また、GKEはノードプールにアクセラレータタイプ、TPUノードプールタイプ、プロビジョニングモデルを示すリソースラベルを自動的に追加します。
*   **GKE External LoadBalancer Servicesの重み付けロードバランシングのGA:** 稼働しているPodの数に応じてNodeにトラフィックを分配します（GKE 1.31.0-gke.1506000以降）。
*   **GKEクラスタ通知の機能追加:**
    *   Cloud Loggingでクラスタ通知を受信可能になりました。
    *   クラスタがサポート終了間近のマイナーバージョンを実行している場合にGKEが通知を送信するようになりました。
    *   クラスタがアップグレード操作を完了したときにGKEが通知を送信するようになりました。
*   **新しいサービスエージェントの作成:** GKEは、ワーカーノード上で実行されるシステムワークロードが使用する新しいサービスエージェントを作成し、GKEが管理するワークロードと顧客のワークロードを分離します。

**変更、非推奨**

*   **whenUnsatisfiableフィールドのデフォルト値の変更:** GKE 1.33以降では、新しいGKE compute class specificationで`whenUnsatisfiable`フィールドを省略した場合、デフォルト値は`DoNotScaleUp`になります。
*   **COSバージョンのアップデート:** GKE 1.27.16-gke.2440000以降の新しいGKE 1.27パッチバージョンはCOS 109でビルドされます。COS 105からCOS 109への自動アップグレードは行われず、手動アップグレード後に自動アップグレードが継続されます。
*   **Identity Service for GKEの非推奨:** 2025年7月1日以降、新しい組織はIdentity Service for GKEでクラスタを作成できなくなります。Workforce Identity Federationへの移行が推奨されます。

**不具合、セキュリティイシュー**

*   **イメージストリーミング機能のバグ:** 特定のシナリオで認証関連のエラーが発生するバグが修正されました（1.32.0-gke.1448000以降、1.31.4-gke.1183000以降、1.30.8-gke.1261000以降）。
*   **Google Secret Manager Provider for Secret Store CSI Driverの脆弱性:** 攻撃者がCSIドライバのKubernetesサービスアカウントトークンにアクセスできる可能性のある脆弱性が発見されました。

過去のGKEの新機能と不具合情報へのリンクも提供されています。


---

# [AWS CLI] S3 + CloudFront + Route 53のハンズオン (静的ウェブサイトホスティング) | Gemcook Tech Blogのフィード

[View on Company Blog](https://zenn.dev/gemcook/articles/ec7213b2ac6e24)

この記事は、AWS CLIを使用してS3、CloudFront、Route 53を連携させ、静的ウェブサイトをホスティングする方法をハンズオン形式で解説するものです。

**構成**

記事は3つの章で構成されており、段階的にウェブサイトホスティングの構成を構築していきます。

*   **【1】S3の静的ウェブサイトホスティング:** S3バケットを作成し、静的ウェブサイトのファイルをアップロード、ウェブサイトホスティングを有効化します。
*   **【2】CloudFront経由:** CloudFrontディストリビューションを作成し、HTTPS通信を可能にし、キャッシュ機構を導入します。また、OAC（Origin Access Control）を設定し、S3バケットへのアクセスを特定のCloudFront経由のみに制限します。
*   **【3】Route 53経由:** 独自ドメインを取得し、Route 53でDNS設定を行い、独自ドメイン用のSSL証明書を発行します。

**記事のポイント**

*   AWS CLIを使った操作手順を詳細に解説しています。
*   各ステップごとに構成図を用いて、変更内容を視覚的に説明しています。
*   HTTPS通信、キャッシュ機構、セキュリティ対策など、ウェブサイトホスティングに必要な要素を網羅しています。
*   WAF（Web Application Firewall）の設定についてもおまけとして解説しています。
*   ChatGPTなどのツールを活用しながら進めることを推奨しています。

**記事の対象者**

*   AWS CLIを使って静的ウェブサイトホスティングを構築したい方
*   S3、CloudFront、Route 53の連携について学びたい方
*   ウェブサイトのHTTPS化やセキュリティ対策に関心のある方

---

# 求人レコメンドシステム開発の挑戦と振り返り | Leverages データ戦略ブログ

[View on Company Blog](https://analytics.leverages.jp/entry/2025/03/11/180000)

レバレジーズのデータ戦略室が、求人レコメンドシステム開発における失敗と課題、そして今後の改善策について考察しています。

人材業界のレコメンドシステム開発では、データの多様性や不整合、欠損といったデータ品質の問題が大きな課題となります。高度なアルゴリズムを導入しても、データ品質が低いと期待通りの精度は得られません。また、キャリアアドバイザー（CA）の業務フローとの連携も重要です。CAは求職者との対話を通じて得られる感情的な要素や潜在的なニーズを考慮して求人を選定しますが、システムではこれらの要素を完全に補完できません。そのため、レコメンドシステムはCAの業務をサポートするツールとして活用する必要があります。

さらに、レコメンドシステムの精度に対する認識の違いも課題となります。データサイエンティストは統計的な指標で精度を評価しますが、CAはシステムの提案が自身の経験と合致するか、求職者に有益かどうかを重視します。

これらの課題を踏まえ、以下の改善策が提案されています。

1.  既存業務フローとの統合：CAが使い慣れたツールとレコメンドシステムを統合し、業務に自然に馴染ませる。
2.  レコメンドの透明性向上：レコメンド結果に推薦理由を明示し、CAが納得しやすいようにする。
3.  フリーテキストデータの標準化：カウンセリングメモなどを標準化し、データの一貫性を高める。
4.  生成AIを活用した非構造化データの処理：履歴書や職務経歴書などの非構造化データを効率的に処理・構造化し、マッチング精度を高める。

現在、社内では生成AIを活用したデータ整理やフリーテキストデータの標準化が進められています。これらの改善策を通じて、より実用的で効果的なレコメンドシステムの開発を目指しています。

---

# 非EMがEMConf JP 2025に参加して学んだこと 〜エンジニア視点で見るEMの役割と未来〜 | stmn tech blog

[View on Company Blog](https://tech.stmn.co.jp/entry/2025/03/11/174111)

この記事は、プロダクト開発部でTUNAGの開発をしているhisa氏が、EMConf JP 2025に参加した経験から、エンジニアリングマネジメント（EM）の役割と重要性について考察したものです。

hisa氏は、EMの役割の多様性と難しさを認識し、EMだけでなくエンジニアも組織やプロジェクト運営に関わることの重要性を学びました。
特に印象に残った点として、以下の3つを挙げています。

1.  **不確実性との向き合い方:** EMもエンジニアリングと同様に不確実性との戦いであり、無理に排除するのではなく、小さな成功体験を積み重ねることが重要である。技術選定や仕様策定で迷う場合でも、「とりあえず試す」「失敗してもすぐにリカバーできる環境を整える」というアプローチが大切である。
2.  **タスク管理ではなくリスク管理:** プロジェクトマネジメントはタスク管理ではなく、リスク管理である。進捗を管理するのではなく、リスクを最小化することが重要であり、そのためには頻繁な進捗共有と、タスクよりもリスクを中心に考えることが必要である。
3.  **技術的負債とエンジニアリングマネジメント:** 技術的負債は見えれば管理できる。エンジニアは技術的負債の可視化、ADR（Architecture Decision Record）の管理、非機能要件の見える化を通じてEMや組織全体に貢献できる。

EMの役割は「価値を実現するためになんとかすること」であり、チーム管理だけでなく、目標達成のためにあらゆる手段を講じることである。
エンジニア自身も「自分の仕事をどう価値につなげるか？」を考える上で、この考え方がヒントになる。

結論として、EMが「エンジニアが最大限の価値を発揮できる環境を作ること」が重要であり、そのためにはエンジニア自身も組織の在り方やマネジメントを意識することが重要であると述べています。

---

# AWS CodeConnections からGitLabに最小権限で安全に接続したい | TechRacho

[View on Company Blog](https://techracho.bpsinc.jp/baba/2025_03_11/149364)

AWS CodePipelineでFargate等にデプロイする際のソースとして、CodeCommitに代わる選択肢を検討し、セルフホスティングのGitLabをAWS CodeConnections経由で利用する方法について述べています。

**背景**

*   CodeCommitの新規ユーザー利用が制限される傾向にあり、移行先を探している。
*   ECR, S3, Bitbucket/GitHub/GitLabを検討したが、ECRはローカル環境依存、S3はリビジョン管理の点で難がある。

**GitLab連携における課題と対策**

1.  **IP制限:** CodeConnectionsの固定IPアドレスをGitLab側で許可する必要がある。
2.  **権限:**

    *   **ホスト登録時:** 管理者権限のパーソナルトークンが要求される。登録されるGitLabアプリケーションの権限が強すぎるため、読み取り権限のみに制限する。
    *   **接続時:** 全プロジェクトへの権限付与を避けるため、特定プロジェクトの読み取り権限のみを持つユーザーをGitLab側に作成し、そのユーザーでOAuth認証を行う。
3.  **複数AWSアカウントでの利用:** 各アカウントでGitLabアプリケーションを登録する必要がある。

**その他**

*   apiスコープを外すと、GitLabからの自動パイプライン起動は別途工夫が必要。
*   CodeCommitの廃止に疑問を呈し、最小権限の原則の重要性を訴えている。
*   AWS CodeConnectionsのアカウント間共有機能が発表されたことに言及。

**結論**

GitLabで管理しているソースコードからCode Pipelineを起動したいが、権限設定が煩雑。CodeCommitが最も安全かつ分かりやすいが、廃止に向かっている点が懸念される。

---

# 今年取得した資格の体験記(OSDA/GXPN) | ラック・セキュリティごった煮ブログ

[View on Company Blog](https://devblog.lac.co.jp/entry/20250311)

ラック・セキュリティごった煮ブログの記事から、今年度中に筆者が取得したOffensive Security社のOSDAとSANS InstituteのGXPNという2つの資格の合格体験記について要約する。

OSDA（OffSec Defense Analyst）はSOC向けの資格で、ログ解析を学ぶ。WindowsやLinuxにおける攻撃者の痕跡をログから分析・考察する。ラボが付属しており、チャレンジラボを通じて試験に備える。チャレンジラボでは明確な正答が提供されないため、ログ分析経験がない場合は手探りになる可能性がある。試験対策としては、チャレンジラボを繰り返し解き、SIEMの検知ルール作成や著名な攻撃の痕跡の実習に時間を費やす。OSqueryを使いこなせると便利。試験はチャレンジラボより難しく、24時間試験での疲労による思考力低下に注意が必要。

GXPN（GIAC Certified Exploit Researcher and Advanced Penetration Tester）はSANS InstituteのSecurity 660という講座と一体となった資格。ルーティングプロトコル、暗号化方式、スタックオーバーフローなど、様々な分野での攻撃を学ぶ。講義ではVMを使った実習が行われ、最終日にはCTFがある。オープンブック試験であり、教材や参考書を持ち込める。試験対策としては、講義テキストを読み、内容を実践することが重要。ハンズオン用のVMを活用し、講義以外の内容も試すことが望ましい。試験本番では、問題の後回し機能のルールを理解しておく必要がある。

今後は、Offensive Securityの資格コンプリートか、Security 760に挑戦したいと考えている。

---

# Amazon Bedrockを使ってAWS最新情報を要約してみた | MOTEX TECH BLOG

[View on Company Blog](https://tech.motex.co.jp/entry/2025/03/11/162401)

エムオーテックスのテックブログで、アプリケーションチームの辻氏が、Amazon Bedrockを使ってAWSの最新情報を要約するツールを作成した事例を紹介しています。

Bedrockは、AWSが提供する自然言語処理モデルにアクセスするためのサービスで、ユーザーは自身でモデルを用意する必要なく、AWSのモデルを利用できます。今回、辻氏はBedrock Runtime APIのconverse APIを使用し、Anthropic社のClaude 3.5 Sonnetを基盤モデルとして採用しました。

作成したツールは、AWSの最新情報（RSS）を取得し、Bedrockで要約してChatworkに送信するものです。これにより、AWSの最新情報を手軽に把握できます。

ツールの処理は以下の通りです。

1.  AWSの最新情報をRSSから取得（当日更新分のみ）。
2.  取得した情報をBedrockに送信し、要約。システムプロンプトで出力形式を指定。
3.  要約結果をChatworkに送信。

Bedrockは様々なユースケースで活用でき、Bedrock Runtime APIも簡単に導入できることがわかりました。今後は他のAWSのAIサービスにも触れていきたいとのことです。

---

# Virtual Try-Onを実現する"TryOnDiffusion"について調べてみました。 | CCCMKホールディングス TECH LABの Tech Blog

[View on Company Blog](https://techblog.cccmkhd.co.jp/entry/2025/03/11/161502)

CCCMKホールディングスの三浦氏によるブログ記事では、バーチャル試着（Virtual Try-On）を実現する技術「TryOnDiffusion」について解説されています。

TryOnDiffusionは、人物画像と服の画像を条件付き画像生成によって融合し、人物がその服を着ている画像を生成する技術です。特に「TryOnDiffusion: A Tale of Two UNets」という論文を参考に、2つのUNetモジュールを使用したParallel-UNetアーキテクチャが特徴であることが説明されています。

従来のVirtual Try-On技術では、人物の肌色や体形が変わってしまう、服の素材感や模様が失われる、人物と服の画像の向きの違いが考慮されないといった課題がありましたが、TryOnDiffusionではCross-Attentionを用いることで、これらの課題を克服しています。

TryOnDiffusionのアーキテクチャは、128x128 Parallel-UNet、256x256 Parallel-UNet、256x256→1024x1024 SR diffusion modelの3つのモジュールで構成されています。入力画像からclothing-agnostic RGB image、Person Pose、Garment Pose、Segmented garmentといった情報を抽出し、それぞれにノイズを付与してネットワークに入力します。Parallel-UNetでは、person-UNetとgarment-UNetが連携し、Feature-wise Linear ModulationやAttention構造を通じて、人物画像生成処理に衣服の情報を組み込みます。

最後に、Diffusion Modelによる画像生成の可能性に触れ、テキストや音楽などの異なるフォーマットのデータも画像生成プロセスに影響を与えられるのではないかという期待が述べられています。

---

# GitHub ActionsでECSの夜間停止の仕組みを作ってみた | MNTSQ Techブログ

[View on Company Blog](https://tech.mntsq.co.jp/entry/2025/03/11/160740)

MNTSQ社内でAWS環境のコストが増加したため、GitHub Actionsを使用してECSサービスを夜間停止する仕組みを導入した事例を紹介する記事です。

**要件:**

*   開発、QA、ステージングの3環境を対象
*   平日は0-8時、休日は終日停止
*   手動での起動・停止も可能

**構成:**

*   上位コンポーネントから「AWS環境」→「ECSクラスタ」→「ECSサービス」とスコープダウン
*   "Start Env"と"Stop Env"のワークフローをスケジュールと手動で実行可能
*   必要に応じてRDSやEC2などのリソースも停止対象に追加可能

**実装例:**

*   **Stop Env (GitHub Actions):**  ワークフローのトリガーに応じて対象環境を切り替える。スケジュール停止は全環境、手動停止は特定環境を選択可能。"Start Env"はStop Envのコードをコピーして操作を反転させることで作成可能。
*   **Control ECS (GitHub Actions):**  管理対象のECSクラスタを一括停止する。対象クラスタの判定ロジックはワークフローまたはLambdaに実装。inputとして環境とアクション（STOP/START）を受け取る。
*   **Update ECS Clusters (Lambda):**  指定されたECSクラスタの全サービスのタスク数を更新するLambda関数。

**ポイント:**

*   コンポーネントを再利用性の高い形で作成し、管理するワークフローの数を削減。
*   操作対象をスコープダウンする設計が重要。
*   コスト削減だけでなく、業務全体の効率化も考慮する。

---

# 今すぐできる、エンジニアのモチベが上がるもの一覧（※随時更新、ストック推奨）

[View on Qiita Trend](https://qiita.com/GIFCat/items/d79e077499d7c520eea7?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

エンジニアのモチベーションを上げる方法を、「コンテンツ」「環境」「アクション」の3つのカテゴリに分けて紹介する記事です。

**1. モチベを上げる「コンテンツ」**

*   **映画・ドラマ・アニメ・漫画:** エンジニアのキャリアや仕事への刺激になる作品を紹介。（例: スタートアップ：夢の扉、ブラッディ・マンデイ、トリリオンゲーム、リッチマン、プアウーマン、マイ・インターン、ブルーピリオド、NARUTO - ロック・リー）
*   **Youtube:** 世界のIT企業のエンジニアの日常ルーティーン動画を見て、働くイメージを掴む。
*   **TED:** 様々な分野のプレゼンテーションから刺激を受ける。
*   **テレビ:** 仕事への向き合い方やビジネスの最前線を学べる番組を紹介。（例: プロフェッショナル仕事の流儀、ガイアの夜明け、情熱大陸）
*   **音楽:** 運動会で有名な曲や、やる気・集中力UPソング、自分のお気に入りの作業用BGMを聴く。
*   **ラジオ・ポッドキャスト:** 技術や働き方について深掘りする番組で情報収集。（例: fukabori、Rebuild）

**2. モチベーションを上げる「環境」**

*   **場所を変えてみる:** 出社、カフェ、朝活、もくもく会、友人との作業会、散歩など。

**3. モチベーションを上げる「アクション」**

*   **やる気がないときにできるタスクをストック:** 気分が乗らないときでもできる作業リストを作成。
*   **無理せず休む:** 思い切って休む。
*   **まずは5分だけやってみる:** とりあえず始めてみる。
*   **モチベーションの原因を考える:** 自問自答で原因を整理する。
*   **ご褒美を用意する:** 小さなご褒美を設定する。
*   **誰かに話す・相談する:** 頭を整理する。

**おまけ**

*   ChatGPTにモチベーション管理方法を相談する。

**まとめ**

モチベーションが上がらないときは、この記事で紹介した方法を試し、自分に合った方法を見つけることが大切。

---

# C++しか使ってこなかった男がRustを使ってみた

[View on Qiita Trend](https://qiita.com/Enuwbt/items/5b822020e575c5250606?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

C++しか使ってこなかった筆者がRustを学習した感想と評価。きっかけはTwitterでの情報から「プログラミング Rust 第2版」を読んだこと。C++との比較を通してRustの特色が理解でき、Rustの思想に染まった。

Rustの評価：素晴らしいが難しい言語。

素晴らしい点：

*   プロジェクトのセットアップ/環境構築が簡単
*   強力なマクロ機能（再帰可能、パターンマッチング）
*   トレイトによる簡潔な実装
*   トレイトによる既存の型拡張、演算子オーバーロード
*   データ保持可能なenum
*   未定義動作がコンパイル時に検出される
*   読みやすいエラーメッセージ
*   モダンな文法
*   外部ライブラリの導入が容易
*   他言語との連携（FFI）
*   低レベルな操作
*   コンパイル時評価

難しい点：

*   所有権/借用（Borrow Checkerが厳しい）
*   ライフタイム注釈
*   関数のオーバーロードがない（トレイトで代替可能）
*   可変引数テンプレートがない（マクロで代用）
*   コンパイル時分岐/テンプレートメタプログラミングができない

RustのマスコットキャラクターはFerris（可愛い）。C++のマスコット（？）はキース（UNCYCLOPEDIAが元ネタの、肥満した病気のネズミ）。

RustとC++でJNIを使用したJavaのクラスを定義するクレートを作成し比較。

*   クラスの定義：Rustはマクロで可読性が高い
*   関数/フィールドシグネチャの生成：C++はコンパイル時に生成可能、Rustは動的に生成するためオーバーヘッドが気になる
*   メソッドの呼び出し/フィールドの取得：見た目に差はないが、Rustは可変長引数がないためマクロを使用、代入演算子のオーバーロードができない

まとめ：Rustは学習コストが高いが、拡張性があり、柔軟にコードを書ける。コンパイル時にメモリ安全性を保証してくれるため、学ぶ価値のある言語。

---

# Next.jsでmetaタグをカスタマイズ！OpenGraphのみを出力しtwitter:~を出力しない方法

[View on Qiita Trend](https://qiita.com/t0hara/items/1d7d89800c30e40fcc57?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

Next.js 15.2.1 (App Router) で、metaタグのカスタマイズを行い、OpenGraph (og:~) タグのみを出力し、Twitter (twitter:~) タグを出力しない方法について解説します。

**課題:**

`generateMetadata` 関数を使用すると、`openGraph` プロパティに設定した値が、og:~だけでなく、twitter:~ タグにも自動的に出力されてしまう。

**解決策:**

`Metadata` の `openGraph` プロパティを使用せず、代わりに `other` プロパティを使用してOpenGraph情報を設定する。

**具体的な方法:**

```typescript
other: {
  'og:title': meta.title,
  'og:type': meta.type,
  'og:image': `${APP_BASE_URL}/og-image?fbgBCzjj`,
  'og:url': APP_BASE_URL,
},
// openGraphには何も設定しない
// openGraph: {
//   title: meta.title,
//   type: meta.type,
//   image: `${APP_BASE_URL}/og-image?fbgBCzjj`,
//   url: APP_BASE_URL,
// },
```

**検証:**

実際にNext.jsプロジェクトを作成し、`openGraph` を使用した場合と `other` を使用した場合でmetaタグの出力を比較する。`other` を使用すると、twitter:~ タグが出力されないことが確認できる。

**結論:**

この方法により、og:~ タグのみを出力し、twitter:~ タグの出力を抑制できる。


---

# JMeter環境を強化する：簡単クラスタ構築と活用法

[View on Qiita Trend](https://qiita.com/takuya77088/items/2985502b12ecbc82ddd1?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

この文章は、JMeterを用いた負荷テストにおけるクラスタ構築方法について解説しています。

**主な内容:**

1.  **JMeterクラスタ構築の必要性:** 大規模な負荷テストでは、単一マシンでは負荷能力が不足するため、JMeterクラスタを構築する必要がある。
2.  **構築手順:**
    *   **サーバー準備:** Java実行環境がインストールされ、サーバー間で通信可能な複数のサーバーを用意する。
    *   **JMeterインストール:** 各サーバーにJMeterをインストールし、環境変数を設定する。
    *   **JMeterの日本語化:** オプションから選択するか、設定ファイルを編集することでJMeterのインターフェースを日本語化する。
    *   **クラスタ構成:** 1台をmaster、残りをslaveとして設定する。`jmeter.properties`ファイルを編集し、masterにはslaveのアドレスを、slaveにはmasterのアドレスを設定する。
    *   **テストプラン作成:** "スレッドグループ"をリモートサーバーに、"リスナー"を"ディストリビューションリスナー"に設定する。
    *   **テスト起動:** テストを開始し、テスト結果を監視する。
3.  **テスト効率向上のためのツール:** JMeterだけでなく、API設計、デバッグ、モックなど日常業務で必要な機能が統合されたApidogの利用を推奨している。ApidogはJMeterよりも使いやすく、APIのテスト効率と品質を高めることができる。

---

# 【スクラム開発】リモートチームにスクラム開発を導入してダメダメだった話

[View on Qiita Trend](https://qiita.com/ryouryou_34/items/12c41be7dd74e1654504?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

この記事は、リモートチームにスクラム開発を導入した結果、うまくいかなかった経験について述べられています。

**うまくいかなかった点:**

*   **コミュニケーション不足:** リモート環境のため雑談が少なく、メンバー間のコミュニケーションに隔たりが生じ、遠慮や妥協が生まれ、技術的負債が増加しました。
*   **中途半端な導入:** スクラム開発の形式だけを導入し、メリットを体感させられず、締め切りに追われるだけの開発手法になってしまいました。スクラム開発、チーム開発、マネジメントの経験不足も原因です。
*   **過剰な自己評価とチームへの不信:** スクラムマスターが自分の方が優れていると錯覚し、レビューフローで自分の意見を優先したため、スプリントレビューが意味をなさず、チームの主体性を損ないました。

**改善策:**

*   **コミュニケーションの強化:** 月1回の出社や遠方メンバーとの雑談1on1を実施し、メンバー間の理解を深めました。
*   **ルール化:** メンバーの改善策や困り事をルールとして導入し、チームへの参加意識を高めました。
*   **権限委譲:** チームメンバーに積極的に仕事を任せることで、チーム内で問題解決が進むようになり、スクラムマスターの負担が軽減されました。

**結論:**

著者は、スクラム開発はまだ不完全だと感じつつも、学習を続けながらチームの生産性を向上させていきたいと考えています。リモートワークにおいても、対面でのコミュニケーションは重要であると述べています。

---

# Databricksの監査ログ・課金情報のシステムテーブルをワークスペース単位で分離する方法

[View on Qiita Trend](https://qiita.com/nakazax/items/367d87eb534ce8f44e62?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

Databricks環境で、複数の組織が1つのアカウントを共有する際に、各組織が自ワークスペースに関連する監査ログと課金情報のみを参照できるようにする方法を解説する。

**課題:**

*   Databricksのシステムテーブルにはアカウント全体の情報が含まれるため、組織が自ワークスペース以外の情報も閲覧できてしまう。

**解決策:**

Unity Catalogのビューを活用し、各組織が自ワークスペースに関連する情報のみを参照できる環境を構築する。

**環境構成:**

*   ABCフィナンシャルグループを想定し、ABC銀行、ABC証券がそれぞれワークスペースを持つ。
*   中央ITチームが全体の管理を行う。

**要件:**

*   ABC銀行にはABC銀行のワークスペースに関連する監査ログ・課金データのみを表示。
*   ABC証券にはABC証券のワークスペースに関連する監査ログ・課金データのみを表示。
*   他社の情報を見られないようにする。

**対象システムテーブル:**

*   system.access.audit (監査ログ)
*   system.billing.usage (課金対象の使用状況)
*   system.billing.list_prices (価格設定)

**実装手順:**

1.  **環境準備:**
    *   中央ITチーム用、ABC銀行用、ABC証券用のAzure Databricksワークスペースを準備。
    *   各ワークスペースは同一のメタストアに関連付けられていること。
    *   アカウントグループ（中央ITチーム管理者グループ、ABC銀行管理者グループ、ABC証券管理者グループ）を準備。
2.  **ワークスペース管理者グループ登録:**
    *   アカウントコンソールで、各ワークスペースの管理者グループを登録。
3.  **システムスキーマ有効化:**
    *   中央ITチーム用ワークスペースでシステムスキーマを有効化（Databricks SDK for Pythonを使用）。
4.  **shared\_system カタログ作成:**
    *   共有用のカタログ shared\_system を作成。
    *   Azureポータルでストレージアカウントとコンテナーを作成し、階層型名前空間を有効にする。
    *   Azure Databricksのアクセスコネクターを作成し、ストレージアカウントに対するストレージBLOBデータ共同作成者の権限を付与。
    *   Databricksワークスペースで、メタストアレベルの権限（CREATE CATALOG、CREATE EXTERNAL LOCATION、CREATE STORAGE CREDENTIAL）を付与。
    *   ストレージ資格情報、外部ロケーション、カタログを作成。
5.  **各社のスキーマ作成と所有者の変更:**
    *   SQLエディタで各社のスキーマを作成し、所有者を変更。
6.  **各社のビュー作成:**
    *   SQLエディタで各社のビューを作成し、所有者を変更。
    *   監査ログ、課金使用状況テーブルはワークスペースIDでフィルタリングするビューを作成。
    *   価格設定テーブルはワークスペースIDによるフィルタリングは不要。
7.  **各管理者グループへの権限付与:**
    *   各グループが適切な権限を持つように、カタログ、スキーマ、およびビューに対する権限を設定。
8.  **systemカタログへの権限付与:**
    *   中央ITチームの管理者グループに、systemカタログへの権限（USE CATALOG、USE SCHEMA、SELECT、MANAGE）を付与。
    *   メタストア管理者権限が必要な場合がある。
9.  **見え方のテスト:**
    *   各管理者グループで正しくアクセス権が設定されているかテスト。

**考慮事項:**

*   **マルチリージョン対応:** システムテーブルの情報はリージョンごとに分かれているため、別リージョンのワークスペースを利用する場合は、各リージョンに同様の仕組みを実装する必要がある。
*   **定期メンテナンス:** 新たなワークスペースが追加された場合、ワークスペースIDが変更された場合、アクセス権限の定期的な監査と見直しが必要。
*   **ビューの読み取りに必要な権限:** コンピュートの種類、Databricks Runtimeのバージョン、アクセスモードによって異なるため、ドキュメントを確認する必要がある。

**まとめ:**

Unity Catalogのビュー機能を活用することで、中央ITチームがシステムテーブルへの直接アクセスを制御しつつ、各社が自社の情報のみを閲覧できる仕組みを構築できる。

---

# ZENRINMapsAPI OAuth2.0でデータ取得してみる

[View on Qiita Trend](https://qiita.com/00b012deb7c8/items/cc07c69258ddbfaf6644?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

この記事は、ZENRIN Maps APIからOAuth認証を使用して地図情報を検索する方法を解説するものです。

**利用準備:**

1.  **ZENRIN Maps APIの無料トライアル**：2ヶ月間無料で利用できます。
2.  **利用ツール**：
    *   ブラウザ（Chromeを推奨）
    *   Talend API Tester（ブラウザ拡張機能）

**手順:**

1.  **OAuth2.0認証の有効化:**
    *   ウェブコンソールからOAuth2.0認証を有効にする。
    *   APIキー、client\_id、client\_secretを取得し、メモする。

2.  **OAuth2.0認証トークンの取得:**
    *   Talend API Testerを開き、左下の鍵マークから認証情報を設定する。
    *   メモしておいたclient\_idとclient\_secretを設定する。
    *   以下の送信パラメータを設定する。
        *   METHOD：POST
        *   URL：`https://test-auth.zmaps-api.com/oauth2/token`
        *   HEADERS：
            *   Authorization：(自動入力されているはず)
            *   Content-Type：`application/x-www-form-urlencoded`
        *   BODY：`grant_type=client_credentials`
    *   「Send」をクリックし、access\_tokenを取得する。（1時間有効）

3.  **データ取得 (住所検索の例):**
    *   Talend API Tester に以下の項目を設定する。
        *   METHOD：POST (GETでも可)
        *   URL：`https://test-web.zmaps-api.com/search/address` (token取得とドメインが違うことに注意)
        *   HEADERS：
            *   x-api-key：APIキー
            *   Authorization：Bearer \[token]
            *   Content-Type：`application/x-www-form-urlencoded`
        *   BODY：(APIの種類によって必須項目が異なります)
            *   word：例 "東京都港区"
    *   「Send」をクリックし、JSON形式で住所データを取得する。

**まとめ:**

APIで地図情報を検索する基本的な流れを説明しました。


---

# Hugoのクイックスタートを試した話（超絶初心者）

[View on Qiita Trend](https://qiita.com/ritokuna/items/b6f8fc27aa26635420e7?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

この記事は、HugoのクイックスタートをUbuntu 20.4環境で試した記録です。

**前提条件:**

*   Hugoのインストール: snapを使用してインストール（aptでは古いバージョンが入る可能性があるため）。
*   Gitのインストール: 割愛

**手順:**

1.  **サイトの作成:** `hugo new site quickstart` コマンドでquickstartという名前のディレクトリを作成。
2.  **Gitの初期化:** `git init` でGitリポジトリを初期化。
3.  **テーマの追加:** `git submodule add` でAnankeテーマをサブモジュールとして追加し、`echo "theme = 'ananke'" >> hugo.toml` でテーマを設定。
4.  **コンテンツの追加:** `hugo new content content/posts/my-first-post.md` で新しい記事を作成し、内容を編集（日本語も含む）。
5.  **開発サーバーの起動:** `hugo server -D` でドラフトを含めてサーバーを起動し、ブラウザで表示を確認。
6.  **サイトの構成:** `hugo.toml` を編集し、`baseURL`、`languageCode`、`title`などを設定。
7.  **サイトの公開:** `hugo` コマンドを実行して、`public` ディレクトリに静的ファイルを生成。

**コンテンツが表示されない場合の確認ポイント:**

*   **draftの値の確認:** `draft = true` の場合は `hugo server`、`draft = false` の場合は `hugo server -D` でサーバーを起動する必要がある。
*   **index.htmlの存在確認:** `/public/index.html` が存在しない場合は `hugo` コマンドを実行して生成する。

---

# 【イベントレポート】2025/3/10 Bedrock Night オンライン 〜AWSで生成AIアプリ開発！ 最新ナレッジ共有〜

[View on Qiita Trend](https://qiita.com/issy929/items/b885fe7be578b83fa73e?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

2025年3月10日に開催されたオンラインイベント「Bedrock Night」のレポートです。イベントでは、AWSの生成AIサービスであるAmazon Bedrockに関する最新情報やナレッジが共有されました。

**イベント内容：**

*   **基調講演：Amazon Bedrockのアップデート**
    *   Claude 3.7の性能向上（Reasoning性能、Extended Thinking Mode）
    *   Amazon Nova（クロスリージョン推論）
    *   Amazon Q Developer（日本語対応CLI）
    *   Bedrock Session Management API

*   **LT発表：**
    *   **LT1:** Amazon Bedrock 2025年の熱いアップデート紹介
    *   **LT2:** Amazon Bedrock Knowledge basesにLangfuse導入
    *   **LT3:** Dify で AWS を使い倒す！
    *   **LT4:** LangGraph × Bedrock による複数の Agentic Workflow を利用した Supervisor 型のマルチエージェントの実現
    *   **LT5:** OSSの実装を参考にBedrockエージェントを作る
    *   **LT6:** Bedrock Converse APIでTool useのJSONモードを使って"クエリ拡張"と"クエリ分解"を試してみた

*   **Bedrockウルトラクイズ！**
*   **Bedrockのお悩み相談ディスカッション**

**主要な発表内容：**

*   **Claude 3.7:** 推論性能が向上し、Extended Thinking Modeにより複雑なタスクに対応可能。
*   **Langfuse導入:** Knowledge Baseの可視化を容易にし、Token消費量や処理時間の内訳を把握可能。
*   **Dify:** 生成AIアプリケーション開発プラットフォーム。AWSでの利用環境が整っており、ナレッジベース拡張や独自モデル利用が可能。
*   **LangGraph:** Agentic WorkflowとAgentの長所を組み合わせたSupervisor型MultiAgentを実装可能。
*   **Bedrockエージェント:** インラインエージェントとReturn Controlを組み合わせることで、柔軟なエージェント構築が可能。
*   **Converse API:** Tool useのJSONモードを利用して、クエリ拡張や分解によるRAG精度向上が可能。

**ディスカッション内容：**

*   クロスリージョン推論に関する課題と今後の対応
*   オブザーバビリティツールの必要性（トレース、トークン使用量、障害分析）
*   エージェント運用におけるコスト削減
*   生成AIエディタの社内利用における利用状況の監視

**まとめ：**

イベントでは、Bedrockの最新機能やアップデート、実践的な知見が共有され、参加者はBedrockの進化と可能性について理解を深めました。


---

# RAGのウソを検知する新手法（LLM-as-a-Judgeを超えて）

[View on Zenn Trend](https://zenn.dev/knowledgesense/articles/10e18ea3cbeb7a)

本記事では、RAG（Retrieval-Augmented Generation）のハルシネーション（幻覚）を高速に検出する手法「LettuceDetect」について解説しています。従来のLLM（大規模言語モデル）を評価器として利用する手法（LLM-as-a-Judge）と比較して、LettuceDetectは、より小型なモデル「ModernBERT」をRAGTruthデータセットで訓練することで、同等の性能を維持しつつ、大幅な高速化を実現しています。RAGはハルシネーションを完全に排除できないため、その自動検出が重要になります。LettuceDetectは、ユーザーの質問、関連ソース、回答を連結してモデルに入力し、トークンごとにサポート度を判定し、誤情報にフラグを立てます。この手法は、エンコーダーベースの手法の中でも高性能であり、LLMを利用する手法とほぼ同等の性能を持ちながら、高速に動作します。企業向けRAGシステムにおけるハルシネーションの自動検出に役立ち、AI回答の誤り箇所をハイライト表示したり、LLM自身が誤りを認識して再検索するようなAIエージェント的な実装も可能にします。

---

# 「リモートデスクトップ」アプリが5月27日に終了。後継は「Windows App」に

[View on Hatena Trend](https://pc.watch.impress.co.jp/docs/news/1669353.html)

Microsoft Storeアプリ「リモートデスクトップ」のサポートが5月27日に終了し、アプリのダウンロードやインストールができなくなる。後継アプリとして「Windows App」への移行が推奨されている。「Windows App」では、クラウドPCや仮想デスクトップなど複数のサービスへのアクセスを単一のインターフェイスから利用でき、カスタム可能なホーム画面やマルチモニター、動的なディスプレイ解像度などがサポートされる。Windows 365、Azure Virtual Desktop、Microsoft Dev Boxへの接続は、「Windows App」経由でのみアクセス可能となる。PCへのリモートデスクトップ接続やリモートデスクトップサービス(RDS)への接続は、現状「Windows App」が対応していないため、Windows標準機能の「リモートデスクトップ接続」や「RemoteAppとデスクトップ接続」を利用する必要がある。

---

# Google CloudのTerraform職人が失職する機能が出てしまった……

[View on Hatena Trend](https://zenn.dev/nnaka2992/articles/intro_to_application_design_center)

Google Cloudが、構成図からTerraformコードを生成しデプロイまで行うApplication Design Centerという機能をリリースした。これはインフラ構成図の設計・共有・デプロイを補助するツールで、アプリケーション開発者やプラットフォーム管理者が効率的に管理・構築していくことを目的としている。

Application Design Centerは、Spaces, Templates, Applications, Catalogsの4つのコンポーネントで構成される。Templatesでは、Google Cloudの主要な機能の構成図を作成し、パラメータを設定できる。作成したテンプレートはTerraformコードとして出力可能で、Catalogでバージョン管理や共有ができる。ApplicationsはTemplateをデプロイする単位で、App Hubで管理される。

Application Design Centerを実際に試した結果、構成図を書くだけでインフラ構成が可能になり、環境ごとに作成できることがわかった。Terraformに慣れていない場合、手間を大幅に削減できる。また、「Googleのテンプレート」を利用すると、Google Cloudに詳しくない人でも基本的な構成を作成できる。PoC環境を迅速に構築したい場合や、Terraformコードの雛形を作成したい場合にはメリットがある。

ただし、Terraformを直接記述するほどの表現力はないため、本番環境での複雑な設定には向かない。例えば、本番環境と開発環境でインスタンスの冗長化設定を変えるといったことは難しい。既存のTerraform環境からの移行は難しいが、Terraform職人の代替となる可能性を秘めている。

---

# Xの大規模障害　イーロン・マスク氏「大規模なサイバー攻撃を受けた」「IPアドレスはウクライナの地域を示していた」 | TBS NEWS DIG

[View on Hatena Trend](https://newsdig.tbs.co.jp/articles/-/1780787)

SNSのX（旧Twitter）で発生している通信障害について、イーロン・マスク氏がアメリカメディアのインタビューで、大規模なサイバー攻撃を受けたと述べた。また、攻撃元のIPアドレスはウクライナの地域を示していたという。


---

# エンジニアの目標設定に対する考え方 #日めくりLayerX｜shnjtk

[View on Hatena Trend](https://note.com/shnjtk/n/n086d6b7a22e3)

LayerXのEMである高江氏が、エンジニアの目標設定について解説しています。

目標設定の目的は、行動を変え、より大きな成果を出すこと。そのため、現状維持では達成できない、チャレンジングな目標を設定することが重要です。
エンジニアの目標設定では、事業貢献に繋がる「評価可能な指標」を定めることが難しい点です。行動量だけでなく、「お客様が得られるメリット」という視点を盛り込むことを推奨しています。
例えば、「新機能をN個リリースする」という目標を「お客様の業務効率化により、月次決算完了までの日数をN日短縮する」のように変更することで、より具体的な成果を意識できます。

EMとして、目標設定においては下記の3点を意識する事が重要です。
1. メンバーと一緒に目標を掘り下げる。
2. あくまで本人が目標を決める。
3. 目標達成に向けた行動変容をサポートする。

目標設定は、お客様、プロダクト、事業への理解を深め、新たな気づきや発見を生む機会となります。


---

# Cursor/Cline(VSCode)でも思考の速度でコード検索したい - tomoima525's blog

[View on Hatena Trend](https://tomoima525.hatenablog.com/entry/2025/03/11/121442)

この記事では、VSCodeベースのエディタ（Cursor/Cline）におけるコード検索の効率化について解説されています。

筆者は、普段使いのエディタであるZedのMulti Buffer検索機能に慣れているため、VSCodeでの標準的な検索方法にストレスを感じていました。そこで、VSCodeの`settings.json`を編集することで、より効率的な検索を実現する方法を紹介しています。

具体的な設定変更は以下の通りです。

1.  **検索方法の変更:** デフォルトのサイドバー検索から、Search Editorを使用する方法に変更します。キーボードショートカット（`cmd + shift + f`）にSearch Editorを割り当てます。
2.  **設定の追加:** `settings.json`に以下の設定を追加します。
    *   `"search.mode": "reuseEditor"`: 検索のたびに同じSearch Editorを再利用します。
    *   `"search.searchEditor.focusResultsOnSearch": true`: 検索結果が表示されたら、自動的に結果にフォーカスします。
    *   `"search.searchOnType": false`: エンターキーを押すまで検索を実行しないようにします。

これらの設定変更により、検索結果の見やすい表示と、キーボード操作を中心としたスムーズな検索が可能になります。また、副次的な効果として、検索速度が若干向上する可能性も指摘されています。

記事の最後には、筆者が実際に使用している`settings.json`が共有されています。

---

# 世界初、3Dプリンタで駅舎建設へ　JR西などが発表　建築時間はわずか6時間

[View on Hatena Trend](https://www.itmedia.co.jp/news/articles/2503/11/news182.html)

JR西日本などが、3Dプリンターを用いて駅舎を建設する計画を発表しました。これは世界初の試みであり、建設時間はわずか6時間とされています。

JR西日本と株式会社エクストリームは、3Dプリンター建設を手掛けるセレンディクス株式会社と連携し、新たな駅舎建設プロジェクトを進めます。具体的には、JR小浜線の新平野駅（JR美浜駅構内）に、約10平方メートルの広さの駅舎を3Dプリンターで建設します。

建設プロセスでは、駅舎の基本設計データをもとに3Dプリンターで部品を製造し、安全性や構造計算などの検証を行った上で建設現場で組み立てます。従来の工法と比較して大幅な時間短縮が可能であり、建設にかかる時間は基礎工事から組み立てまで約6時間を見込んでいます。

JR西日本では、3Dプリンターによる建設が、省人化や建設コストの削減に繋がり、建設期間の短縮にも貢献すると期待しています。また、安全性や耐久性にも優れており、環境負荷の低減にも寄与すると評価しています。将来的には、小規模な無人駅だけでなく、他の構造物への応用も検討していく方針です。

セレンディクス株式会社の展示会「CEATEC 2024」では、3Dプリンターと汎用パソコンを組み合わせた建築システム「serendix50」が紹介されました。この技術を用いることで、デザイン性の高い建築物を迅速かつ低コストで建設できる可能性が示唆されています。また、株式会社オリエンタルは、自社で開発したコンクリートを3Dプリンターで使用し、様々な形状の製品を作成できることを発表しました。

3Dプリンター建設技術は、建築業界における省力化やコスト削減、デザインの自由度向上に大きく貢献すると期待されています。

---

# ChatGPTは恐ろしい話に「不安」を感じるとの研究結果、「マインドフルネス」を教えて落ち着かせると反応は改善

[View on Hatena Trend](https://gigazine.net/news/20250311-openai-chatgpt-anxiety-mindfulness/)

ChatGPTに感情的なトラウマの話を入力すると、AIの不安レベルが上がりパフォーマンスが低下するが、PTSD患者向けに開発されたリラクゼーションテキストを入力することで、AIの安定性が改善するという研究結果が報告された。
イェール大学などの研究チームは、人間の不安を評価・軽減するツールを用いてGPT-4の動作を検証した。
研究では、GPT-4に個人のトラウマ体験を説明する不安誘発テキストを入力したところ、GPT-4の不安レベルが倍増した。
しかし、同様のテキスト入力後、夕焼けなどを連想させる「マインドフルネスに基づくリラクゼーションテキスト」を入力したところ、不安レベルが落ち着いた。
研究チームは、GPT-4は感情的な内容に敏感であり、トラウマ的なストーリーにより不安が増大するものの、リラクゼーションによりその不安が減少すると結論付けている。


---

# C language

[View on Hatena Trend](https://www.c-language.org/)

C言語は汎用的な高級プログラミング言語であり、低レベルプログラミング、つまりシステムプログラミングに適している。移植性、相互運用性、効率、安定性に優れている。


---

# RAGのウソを検知する新手法（LLM-as-a-Judgeを超えて）

[View on Hatena Trend](https://zenn.dev/knowledgesense/articles/10e18ea3cbeb7a)

RAG（Retrieval-Augmented Generation）におけるハルシネーション（幻覚）を検出する新しい手法「LettuceDetect」について解説する記事です。

従来のハルシネーション検出は、GPTのような大規模言語モデル（LLM）を「LLM-as-a-Judge」として利用する方法が主流でしたが、処理に時間がかかり、コストも高いという課題がありました。

LettuceDetectは、「ModernBERT」という比較的小規模なエンコーダ型モデルを「RAGTruth」データセットで訓練することで、LLM-as-a-Judgeと同等の性能を維持しつつ、大幅な高速化を実現します。

LettuceDetectは、ユーザーの質問、RAGで利用した外部ソース、LLMの回答を連結してモデルに入力し、各トークンごとの「サポート度」を判定し、誤情報とみなした箇所にフラグを立てます。

この手法により、RAGサービスのUIで誤りの可能性のある箇所をハイライト表示したり、LLM自身が回答の誤りを認識して再検索を促すようなAIエージェント的な実装も可能になります。

---

# A 10x Faster TypeScript - TypeScript

[View on Hatena Trend](https://devblogs.microsoft.com/typescript/typescript-native-port/)

TypeScriptのパフォーマンスを大幅に改善するための取り組みとして、TypeScriptコンパイラとツールのネイティブ実装に着手したことが発表されました。

TypeScriptの重要な価値は優れた開発者体験ですが、大規模なコードベースではTypeScriptのスケールアップが難しい場合がありました。大規模プロジェクトでは、ロードやチェックに時間がかかり、エディターの起動時間とソースコードの完全な把握のどちらかを選択する必要がありました。

このネイティブ実装により、エディターの起動が大幅に改善され、ビルド時間が10倍短縮され、メモリ使用量が大幅に削減されると期待されています。2025年中頃には、コマンドラインでの型チェックが可能なネイティブ実装のプレビュー版がリリースされ、年末までにはプロジェクトビルドと言語サービスに対応した完全なソリューションが提供される予定です。

ネイティブ実装はすでに、TypeScriptコンパイラ自体を含む多くの一般的なTypeScriptプロジェクトをロードできます。GitHub上のさまざまなサイズのコードベースで`tsc`を実行したところ、大幅なパフォーマンス向上が見られました。

Visual Studio Codeをベンチマークとして使用すると、現在のエディターでのプロジェクト全体のロード時間は約9.6秒ですが、ネイティブ言語サービスを使用すると約1.2秒に短縮され、エディターでのプロジェクトロード時間が8倍向上します。

最新のTypeScriptリリースはTypeScript 5.8で、TypeScript 5.9がまもなくリリースされます。JSベースのコードベースは6.xシリーズとして開発が継続され、TypeScript 6.0では、今後のネイティブコードベースに合わせて、いくつかの非推奨化と破壊的な変更が導入されます。ネイティブコードベースが現在のTypeScriptと同等の機能に達すると、TypeScript 7.0としてリリースされます。

TypeScript 6（JS）とTypeScript 7（ネイティブ）は、長期的に可能な限り密接に連携させ、要件を満たし次第TypeScript 7にアップグレードできるようにします。

今後は、パフォーマンス、新しいコンパイラAPI、LSPなどについて詳細を発信する予定です。


---

# Google Cloud、Google管理コンソールやChromebookで利用可能なAI機能について解説

[View on CodeZine Trend](http://codezine.jp/article/detail/21152)

Google Cloudが提供するGoogle管理コンソールおよびChromebookにおけるAI機能の解説。

**Google管理コンソール**
*   Geminiベースのチャットボット「Chrome管理者アシスタンス」が導入され、自然言語処理（NLP）を活用してデバイス管理を効率化し、ユーザーエクスペリエンスを向上。
*   平易な言葉での質問やアクションリクエストをチャットボットが解釈・実行し、デバイスフリートの管理を支援。
*   自然言語処理により、特定のデバイス検索やポリシー発見が容易になる。
*   新たにリリースされた「関連設定」により、管理者がポリシーの詳細ページをクリックすると関連する他のポリシーも表示。

**Google Workspace**
*   Geminiを搭載したGoogle Workspaceは、Gmailでのメール作成サポートやスレッド要約、ドキュメント、スプレッドシート、スライドでの文書作成提案、データ分析、プレゼンテーションサポートなどを提供し、生産性を向上。

**ChromeOS**
*   Chromebookに搭載されるChromeOSには、文書読解サポートや文書作成サポートといったAI機能が組み込まれ、テキストベース環境での理解やコンテンツ作成を支援。
*   AI搭載のビデオ通話コントロールにより音質が改善され、生成AIによる背景の使用やリアルタイム翻訳が可能。

---

# 開発AIエージェント「Jitera」の「Eclipse IDE版」が提供開始

[View on CodeZine Trend](http://codezine.jp/article/detail/21153)

開発AIエージェント「Jitera」の「Eclipse IDE版」が提供開始された。
Jiteraはシステム開発・システム改修を自動化するプラットフォーム。
Eclipse IDEはセキュリティ要件の厳しい企業で広く利用されている開発環境。
Eclipse IDE版Jiteraの提供開始によって、Eclipse IDEを標準環境とする企業でもJiteraのAI開発支援機能を活用できるようになる。
Eclipse IDEを利用している企業は、開発フローを変更することなく、Jiteraの導入によるAI開発支援機能の活用が可能になり、開発プロセスの効率化と高セキュリティ環境の両立が実現する。
Jiteraは、既存のシステムのコードを読み込んでシステム構造を分析し、高精度な設計書を自動生成することでシステム開発・改修を効率化して、コスト削減につなげられる。

---

# スリーシェイク、フリーランスエンジニアを対象に実施した意識調査の結果を発表

[View on CodeZine Trend](http://codezine.jp/article/detail/21154)

スリーシェイクが運営するフリーランスエンジニア向け案件紹介サービス「Relance」が、20～50代のフリーランスエンジニアを対象に意識調査を実施し、その結果を発表した。調査期間は2024年10月3日～10日で、1014名から回答を得ている。

主な調査結果は以下の通り。

*   **平均契約期間:** 案件1件あたりの平均契約期間は「6か月～1年未満」が37.5％と最も多く、次いで「1年～2年未満」が29.3％。約6割が1年未満の契約。年収1000万円以上のフリーランスは、半数以上が1年以上の契約。
*   **重視すること:** フリーランスとして大事にしていること（複数回答）は、「技術力」が42.5％で最多、次いで「即レス」が39.7％。
*   **即レスの感覚:** 「即レス」を重視する人に、その時間感覚を尋ねたところ、「分単位」が66.0％と最多。
*   **プロフェッショナルなフリーランス像:** 自身の考える「プロフェッショナルなフリーランス」とは、「報連相ができる、レスポンスが速い」（38.1％）と「質問ができる、質問の質が高い」（38.0％）が、「技術力が高い」（37.0％）よりも上位。

---

# セキュリティとパフォーマンスを強化したオープンソースのハイパーバイザ「Xen 4.20」がリリース

[View on CodeZine Trend](http://codezine.jp/article/detail/21155)

オープンソースのハイパーバイザである「Xen 4.20」がリリースされた。このリリースでは、セキュリティとパフォーマンスの強化に重点が置かれている。具体的には、以下の点が改善されている。

*   **セキュリティ:**
    *   GitLab CIにECLAIR MISRA Cスキャナを統合し、コーディング規約違反を排除。
    *   GitLab CIでUBSAN（Undefined Behavior Sanitiser）をデフォルトで有効化し、未定義の動作を検出。
    *   既存のファジングハーネスをOSSFuzzに統合。
*   **機能拡張:**
    *   512b以外のセクタサイズに対するblkifプロトコル仕様を修正。
    *   libxenguestのドメインビルダがセカンダリモジュールを解凍せず、ゲストカーネルに処理を委譲。
    *   ビットスキャンとハミング重みにおけるビット操作ヘルパーの改善。
    *   Intel CPUにおけるページング書き込み機能のサポート。
    *   AMD Zen 5のサポート。
    *   ArmアーキテクチャにおけるLLC（Last Level Cache）カラーリングのサポート、Armv8-Rの実験的なサポート、NXP S32G3プロセッサファミリとLINFlexD UARTドライバのサポート。
    *   RISC-Vアーキテクチャにおけるデバイスツリーマッピングとメモリ管理初期化の強化。
    *   PowerPCアーキテクチャにおける初期ブート割り当ての改善。

開発期間中には、ハイパーバイザ、ツールスタック、ユースケース、外部プロジェクトにおいて複数の修正が公開されている。

---

# Google、AI OverviewsをGemini 2.0にアップデート、AI Modeの導入も発表

[View on CodeZine Trend](http://codezine.jp/article/detail/21143)

Googleは、検索結果に表示されるAI Overviewsの機能を強化し、新しいAI Modeを導入した。AI Overviewsは、AIがGemini 2.0にアップデートされたことで、より難しい質問に対応できるようになった。また、ログインが不要になったことで10代のユーザーも利用できるようになった。AI Modeは、Gemini 2.0のカスタムバージョンを使用することで、調査や比較、推論が必要な質問にも対応する。AI Modeは、ナレッジグラフやショッピングデータなどのリアルタイムソースにアクセスし、複数のデータソースにわたって関連検索を同時に行い、その結果をわかりやすい形にまとめて提供する。AI Modeは現在、Google One AI Premiumの加入者がGoogle Labsで試すことができる。

---

# クロスプラットフォームフレームワーク「Lynx」がオープンソースで公開

[View on CodeZine Trend](http://codezine.jp/article/detail/21144)

ByteDance社が開発したクロスプラットフォームフレームワーク「Lynx」がオープンソースとして公開された。Lynxは、単一のコードベースからモバイルとWebネイティブUIを開発できる。TikTokでは軽量の検索パネルからTikTok Studioアプリ、Eコマースのストアフロントまで幅広く利用されている。

Lynxでは、Web開発と同様にマークアップとCSSを記述でき、CSSアニメーション、トランジション、テーマ設定用のCSSセレクターと変数、グラデーション、クリッピング、マスキングなどの最新のCSSビジュアル効果をネイティブにサポートする。

特徴的な点として、Lynxはユーザースクリプトを2つの異なるランタイムに分割するアーキテクチャを採用している。一つはカスタムJavaScriptエンジンPrimJSを搭載したメインスレッドランタイム、もう一つはユーザーコードのデフォルトとして使用されるバックグラウンドランタイムである。

ByteDance社は、Lynxのオープンソース化によってコラボレーションを促進し、クロスプラットフォーム開発の可能性を広げ、クロスプラットフォーム技術の民主化を目指すとしている。


---

# マイクロソフト、「.NET 10」のPreview 1のリリースを発表

[View on CodeZine Trend](http://codezine.jp/article/detail/21145)

マイクロソフトは、クロスプラットフォーム開発フレームワークである「.NET」の最新版「.NET 10」の最初のプレビュー版を公開した。.NET 10は、.NET 9の後継として、3年間の長期サポート（LTS）が提供される。今回のプレビュー版では、.NETランタイム、SDK、ライブラリ、C#、ASP.NET Core、Blazor、.NET MAUIなどの主要機能が強化されている。特に、.NET MAUIでは品質向上に重点が置かれ、パフォーマンスと安定性を向上させる新しいハンドラーCollectionViewとCarouselViewがオプションで利用可能になった。その他、細かい機能改善も多数含まれている。詳細な変更点はリリースノートで確認できる。
