
# 価値創造を加速させるための革新！ リリースフローをGitHubに完結＆仕組み化して劇的な効率化へ！ | LIFULL Creators Blog

[View on Company Blog](https://www.lifull.blog/entry/2025/03/04/210000)

LIFULLでは、開発フローのボトルネックとなっていたリリースフローの課題を解決するため、リリースに関わる作業をGitHubに集約し、自動化を図った。

**課題:**

*   リリースチケットに情報が不足しており、承認者が確認に手間取っていた。
*   サービス企画職がGitHubアカウントを持っておらず、リリース内容を把握しづらかった。
*   リリースチェックに不備があった際、リリーサーが開発者にリマインドする手間が発生していた。

**解決策:**

*   リリースチケットを廃止し、PRとIssueで情報を管理するように変更。
*   サービス企画職にGitHubアカウントを作成してもらい、情報開示を徹底。
*   GitHub Actionsを用いて、リリースに必要な情報のチェックを自動化。
*   CIでタスク完了を担保し、承認者が開発者の手順遵守を確認できるようにした。
*   GitHub Actionsで定刻チェックを実施し、不備があれば開発者に自動で連絡。

**効果:**

*   リリースに必要な情報がPR上で確認可能になり、開発者の手順漏れが減少。
*   承認者のチェック時間が削減され、心理的ハードルが低下。
*   リリースまでの中央値が50時間から20時間台に削減。
*   リリース回数が増加。

**注意点:**

*   現行の開発フローの意図を紐解き、最大要求と最低限の担保方法を洗い出す必要。
*   社内事情に注意しつつ、社内の有識者への確認やメンバーへの説明を行い、理解を得ることが重要。

**今後の展望:**

*   リリーサーを不要にするリリースの完全自動化を目指す。

---

# redis-objects を継承関係の親子で使うと保存先の key が変わることがある | SocialPLUS Tech Blogのフィード

[View on Company Blog](https://zenn.dev/socialplus/articles/18725a32b22f64)

redis-objects gemを継承関係にある親クラスと子クラスで使用した場合、Redisへの保存先のキーが、オブジェクトへの参照順序によって変わるという問題について解説しています。

**問題の概要:**

*   親クラスと子クラスでそれぞれ `counter` や `value` などの redis-objects を定義している場合、子クラスのオブジェクトのキーが、親クラスのオブジェクトを先に参照したかどうかで変わってしまう。
*   これは、Ruby on RailsなどでSTI（Single Table Inheritance）を利用している場合に、プロセスの起動順序によってRedisに保存された情報が取得できたりできなかったりするという問題を引き起こす可能性がある。

**原因:**

*   redis-objects gemがRedisのキーを決定する際に、`first_ancestor_with`メソッドを使用して、指定されたredis object が定義されている最初の祖先クラスを特定する。
*   このメソッドは、クラスのインスタンス変数にredis objectの情報を格納するため、親クラスと子クラスで同じ名前のredis object が定義されている場合、最初に参照されたクラスの情報がキャッシュされ、その後のキーの生成に使用される。

**対策:**

1.  **redis objectが定義されるクラスを統一する:** 親クラスの `inherited` メソッドを利用して、子クラスが継承された際にredis objectを定義することで、redis objectが定義されるクラスを常に子クラスにする。
2.  **`redis_prefix` を上書き固定する:** 子クラスで `self.redis_prefix = 'child'` のように設定することで、redis objectの参照順序に関係なく、キーのプレフィックスを固定する。

**まとめ:**

redis-objectsを継承関係で使用する場合は、キーの衝突を避けるために、上記の対策を検討する必要がある。

---

# GO TechTalk #30 クラウドコスト削減 祭り | GO Tech Blog

[View on Company Blog](https://techblog.goinc.jp/entry/2025/03/04/200956)

GO株式会社が主催した「GO TechTalk #30 クラウドコスト削減 祭り」では、4名のエンジニアが大規模クラウドシステムにおけるコスト削減のノウハウを発表しました。

*   **Grafana Loki によるサーバログのコスト削減:** Quentin Plessis氏は、Grafana Loki を活用してサーバーログのコストを削減した事例を紹介。ログは大量に保存する必要があるものの、実際に検索されるのはごく一部であることから、Grafana Loki を導入し Kubernetes クラスタを自前で運用することで、マネージドサービスよりもコストを削減。

*   **『GO』アプリ データ基盤のログ収集システムコスト削減:** 牧瀬芳太郎氏は、Pub/Sub、Dataflow、BigQuery を組み合わせたログ収集システムにおいて、Pub/Sub でのデータ圧縮、Dataflow での課金モデル変更、BigQuery での新しい API 利用などの工夫により、大幅なコスト削減に成功した事例を紹介。

*   **『GO』アプリ バックエンドサーバのコスト削減:** 武村直和氏は、Cloud SQL の契約プラン変更によるコスト増加や、App Engine の利用料金増加に対し、クエリ改善やCPU消費削減といった対策を行った事例を紹介。

*   **GAEログのコスト削減:** 山野祐氏は、Cloud Logging のコスト削減について発表。ログのマスク処理に正規表現を使用していたことがCPU負荷を高めていたため、処理方法を見直すことで App Engine のコスト削減に繋がった事例を紹介。

イベントでは、ログの保存期間や他のSaaSの検討状況、キャッシュの種類、Cloud SQLのプラン変更、Cloud DLPの検討などに関するQ&Aも行われました。

---

# Findy Team+の「チーム目標設定」で生産性をブーストしてみる | ゼスト Tech Blog

[View on Company Blog](https://techblog.zest.jp/entry/2025/03/04/195317)

ゼスト社がFindy Team+の「チーム目標設定」機能を活用して開発チームの生産性向上に取り組んだ事例を紹介する記事です。

**背景**

*   ゼスト社は在宅医療・介護業界向けのSaaSを開発しており、Findy Team+を導入して開発生産性の向上を目指しています。
*   Findy Team+は、GitHubのデータを収集・解析し、グラフで可視化することで、開発組織の傾向を数値で確認し、改善アクションに繋げるためのツールです。

**目標設定**

*   Findy Team+導入のサポートとして、Findy社からチーム目標設定が推奨されました。
*   チームは現状を把握するため、まずGitHubの情報から数値を確認した結果、「Pull Requestのオープンからマージまでの時間が長い」という課題が明確になりました。
*   この課題を解決するため、以下の目標を設定しました。
    *   1人1日あたりのプルリク作成数：1件以上
    *   オープンからマージまでの平均時間：17時間

**目標達成に向けた施策**

*   目標達成のため、チームは以下の施策を実施しました。
    *   **設計モブプロ:** 新しい開発アイテム着手時に、タスク分解をしながらモブプロを行い、コードレベルの設計の認識を合わせ、レビュー時の手戻りを減らす。
    *   **対面レビュー:** 実装背景が分かりにくい、または大きくなってしまったPull Requestを対象に、対面でレビューを実施し、停滞を防ぐ。
    *   **とにかく砕く:** レビュー時の議論の的を絞るため、Pull Requestを細かく分割する。

**効果**

*   3週間の取り組みの結果、目標としていた「オープンから17時間以内にマージ」は達成されつつあります。
*   PR作成数は横ばいですが、チームが同じ方向を向き、行動指針を明確にしたことで、開発組織の文化を醸成することに繋がりました。
*   チーム目標を明示することで、遠慮がちな意見も出やすくなり、チーム全体のコミュニケーションが円滑になりました。

---

# ドメインを変えたらサービスが繋がらなくなったと言われた件 | chot Inc. tech blogのフィード

[View on Company Blog](https://zenn.dev/chot/articles/b9b74f8fdf0145)

あるサービスでドメイン変更を行った際、一部ユーザーから画像が表示されないという問題が発生。調査の結果、新しいドメインが過去にマルウェア配布に使用されていた疑いがあり、セキュリティソフトによってブロックされていることが判明。パロアルトとNortonに判定変更を依頼し、再スキャンによって評価が改善されたことで、問題は解決。ドメイン取得時には、過去の利用履歴を確認し、マルウェア判定されていないか確認することが重要であるという教訓が得られた。


---

# トレースとメトリックの連携が強化されました！共通の属性を設定することでトレースからメトリックをすぐに参照できます | Mackerel ブログ #mackerelio

[View on Company Blog](https://mackerel.io/ja/blog/entry/weekly/20250304)

Mackerelの分散トレーシング機能が強化され、以下の点が改善されました。

1. **トレースとメトリックの連携**: トレース中のスパンとラベル付きメトリックに共通の属性（`service.name`、`host.id`または`host.name`、必要に応じて`service.namespace`）を設定することで、トレーシング画面からメトリックエクスプローラーへ直接リンクし、関連メトリックを容易に確認できるようになりました。

2. **UI言語の切り替え**: ユーザーインターフェース設定と連動して、分散トレーシング機能の表示言語を日本語と英語で切り替えられるようになりました。アカウント設定から言語を選択できます。

Mackerelは今後もAPM（アプリケーションパフォーマンスモニタリング）に関する開発を積極的に進めていく予定です。
分散トレーシング機能に関するフィードバックを募集しています。
OpenTelemetryと分散トレーシングのハンズオン資料がGitHubで公開されています。環境構築から問題解決までを体験できます。

---

# 8th長崎QDG 参加レポート 前編 | Money Forward Developers Blog

[View on Company Blog](https://moneyforward-dev.jp/entry/2025/03/04/8th-nagasaki-qdg-report-part1)

8th長崎QDGに参加したマネーフォワードの開発者ブログ記事の前編。イベントでのセッション内容と参加者の感想がまとめられている。

**スペシャルセッション1：「事業継続を支える自動テストの考え方」**

*   **概要：** 事業が長くなるほどソフトウェアは複雑化するが、自動テストによって事業継続を支えるという内容。ソフトウェアはビジネスの変化に対応する必要があるが、長期運用で複雑化するため、自動テストで信頼性を保つ。プロバイダーとコンシューマーの視点を考慮し、両者の「契約」を自動テストで守ることが重要。自動テストは生きたドキュメントとして機能し、事業、アプリ、テストは一体として考えるべき。
*   **感想：** 事業成長に伴うコードの複雑化に共感。自動テストが「生きたドキュメント」になるという考え方に納得。テストレベルを契約の種類に応じて使い分けるという話や、「単体テストの考え方/使い方」という書籍の内容との関連性に理解が深まった。実例マッピングによるビジネスルールと具体例の発見方法も学べた。

**技術・事例・研究セッション：「テストアーキテクチャ設計で実現する高品質で高スピードな開発の実践」**

*   **概要：** SaaSプロダクト開発において、テストアーキテクチャ設計によって高品質と高速なリリースサイクルを両立させる手法の紹介。リグレッションテストスイートの最適化と適切な自動テスト戦略が鍵となる。重篤度とテストサイズでテストケースを分類し、テストスイートを最適化する。
*   **感想：** リグレッションテストの最適化は常に課題であり、重篤度とテストサイズでテストケースを分類する考え方に共感。具体的な判断基準と手順が参考になる。テスト実行時間やリリース頻度の大幅な改善事例に刺激を受けた。

**スペシャルセッション2：「ビジネスと現場活動をつなぐソフトウェアエンジニアリング」**

*   **概要：** スタートアッププロダクトの開発における課題へのアプローチと、重要なスキル・思考について。顧客獲得前後での開発運用プロセスの乖離、顧客インテグレーション時の開発チームの工数増大という課題に対し、テスト・監視の導入やCI環境の構築、APIテストの自動化などで対応。
*   **感想：** スタートアップでの開発経験から課題に共感。過去のチームではスピード重視でテストが不十分だったため、問題解決のために適切なスキルを用いるべきだと感じた。プロダクトのフェーズやビジネスサイドの観点からも課題を見つけ直す必要性を感じた。

**スポンサーセッション：株式会社NDKCOMの事例**

*   **概要：** NDKCOMがJSTQB資格取得を推進し、社員のスキル向上に取り組んでいる事例。社内勉強会やナレッジ共有、合格者が講師となる好循環によって資格取得者が大幅に増加。
*   **感想：** 社員主体の学習と成長に重点を置いたモデルに感銘。自チーム内でもくもく会を開催することにした。

全体として、長崎QDGは内容が濃く、学びや出会いが多いイベントだったことが強調されている。


---

# FlutterからiOSエンジニアに転向しました | every Tech Blog

[View on Company Blog](https://tech.every.tv/entry/2025/03/04/173344)

筆者はFlutterエンジニアからiOSエンジニアに転向した。転向の理由は、Flutterで外部パッケージを使用する際にネイティブコードの知識が必要になることがあり、以前からネイティブに興味があったこと、そして社内でiOSエンジニアのポジションが求められていたこと。

iOSエンジニアに転向して感じたのは、UIKitに関する体系的な情報が少ないこと。デリッシュキッチンでは主にUIKitとStoryboardが使用されているが、UIKitに関する書籍は少なく、公式チュートリアル程度しかない。UIKitは実際に手を動かしながら学習し、AIの助けも借りている。Storyboardは情報が古く、GUI操作のためAIに質問もできず苦労しているが、チームの方針としてStoryboardを廃止し、UIKitコードまたはSwiftUIに書き換えていく予定。SwiftUIはFlutterのwidgetシステムに似ているため、Flutterの知識があれば理解しやすい。

開発環境の違いとして、Swiftの言語仕様やApple純正フレームワークの充実さを挙げている。Combineなどのフレームワークが公式から提供されているため、長期的なメンテナンスの面で安心感がある。また、Swiftではstructを使用するだけで不変なクラスを作成できる点が魅力。

エディターについては、Flutter開発ではVSCodeを使用していたが、iOS開発ではXcodeを使用する。Xcodeは癖が強く、git操作もVSCodeのGit Graphで行っていたため、gitクライアントをどうするか悩んでいる。XcodeのAIサポートはまだ充実していないが、最近chat機能が追加されたらしい。現在はCursorでのiOS開発を試行錯誤しているが、ビルドが遅いため、Cursorはコード作成とgitクライアントとして使用している。

最後に、モバイル開発でも環境が大きく変わり、キャッチアップが大変だったと述べている。

---

# Rails: 7.1で form_with に入った小さくて大きな変更 | TechRacho

[View on Company Blog](https://techracho.bpsinc.jp/sakahara-shintaro/2025_03_04/149204)

Rails 7.1で `form_with` の挙動が変更され、Rails 7.0以前のコードが動かなくなる問題が発生した。具体的には、`form_with` の `model` パラメータにActive Modelオブジェクトを渡す際に、オブジェクトの `#to_model` メソッドが `self` を返すべきである。

**問題**

Active Recordオブジェクトをラップするフォームオブジェクトを使用し、フォームオブジェクトの `#to_model` メソッドにActive Recordオブジェクトを返させていた場合、Rails 7.1でフォームのデフォルト値が空になり、`f.object` がフォームオブジェクトではなくActive Recordオブジェクトを返すようになった。

**原因**

RailsのPR #44468により、`convert_to_model` の呼び出しが `form_for` から `form_with` に移動したことが原因。この変更により、`#to_model` の役割に対する認識のずれが表面化した。ActiveModel::Conversionのドキュメントでは、`#to_model` はActive Modelオブジェクトのように振る舞わないモデルに対して、Active Model準拠のプロキシオブジェクトを返すために使用されるべきとされている。

**対策**

Rails 7.1で動作するように、フォームオブジェクトから `#to_model` メソッドを削除し、`#model_name` をActive Recordオブジェクトに委譲することで、`form_with` に `scope: :my_record` を指定しなくても済むようにする。ただし、`url` パラメータの追加は避けられない。

**結論**

Railsのアップグレードには予期せぬ変更が伴う可能性があるため、テストコードを書いて変更に備えることが重要。


---

# 【Azure AI Speech】- .wavの音声ファイルの作成方法について | ヘッドウォータースのフィード

[View on Company Blog](https://zenn.dev/headwaters/articles/90fb9ed90b5c37)

この記事では、Azure AI Speech を使用して、テキストから音声合成を行い、その結果を .wav 形式の音声ファイルとして保存する方法について解説しています。

**前提条件**

*   Azure AI Speech リソースがデプロイ済みであること
*   Azure AI Speech のキーとリージョンを取得済みであること

**手順**

1.  **ライブラリのインストール:**
    `pip install azure-cognitiveservices-speech` コマンドで必要なライブラリをインストールします。

2.  **コード:**
    以下の Python コードを使用します。`<"Azure Speechキー">` と `<"Azure Speech のデプロイリージョン">` は、実際のリソースキーとリージョンに置き換えてください。

    ```python
    import azure.cognitiveservices.speech as speechsdk

    speech_key = <"Azure Speechキー">
    service_region = <"Azure Speech のデプロイリージョン">

    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)
    audio_config = speechsdk.audio.AudioOutputConfig(filename="output.wav")
    speech_config.speech_synthesis_voice_name = "ja-JP-NanamiNeural" # 例：日本語の女性音声

    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)

    text = "こんにちは、Azureの音声合成です。"
    result = synthesizer.speak_text_async(text).get()

    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
        print("音声の合成が完了し、output.wav に保存されました。")
    else:
        print(f"音声の合成に失敗しました: {result.reason}")
    ```

3.  **音声の種類:**
    日本語の音声は、記事に記載されている複数の種類から選択できます。`speech_config.speech_synthesis_voice_name` で指定します。

4.  **出力音声の仕様:**
    デフォルトでは、PCM 16-bit、16kHz、モノラルの .wav 形式で音声が生成されます。


---

# エンジニアが事業戦略を知っている必要がある

[View on Qiita Trend](https://qiita.com/morry_48/items/274bdc42ac2e94f8ecdc?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

この記事は、近年成功しているSaaS企業（Cursor, Bill One）の開発組織を分析し、エンジニアが事業戦略を理解することの重要性を説いています。

**成功企業の共通点**

*   **小規模チーム:** Cursorは12人、Bill Oneの初期開発は4人という少数精鋭。
*   **事業戦略への理解:** エンジニアが事業のコンセプトや顧客ニーズを深く理解している。
*   **迅速な意思決定:** チーム全体のコンテキストが共有されているため、迅速な意思決定が可能。
*   **外部リソースの活用:** コアな提供価値以外は既存のエコシステムや外注を利用し、開発コストを削減。
*   **作り手＝ユーザー:** 開発者自身がユーザーであるため、問題点を即座に認識し改善できる。

**AI時代のボトルネック**

AIの進化によりコーディング作業は効率化されたものの、情報過多による認知負荷、部門間のコンテキストのずれが新たなボトルネックになる可能性を指摘。

**組織構造の課題**

職能別に分かれた組織では、部門間の目標意識のずれがハレーションを生み、意思決定を遅らせる要因になる。

**Figmaの功罪**

Figmaによってデザイナーの意図は伝わりやすくなったものの、エンジニアが顧客課題へのソリューションを考える機会が減っている可能性がある。

**技術的負債の重要性**

技術的負債はプロジェクト進行を阻害し、チームに悪影響を及ぼすため、事業戦略を理解した上でリファクタリングの優先順位を決定する必要がある。

**今後の組織設計**

専門性で分けたチームから、モジュールごとに多職能チームを編成する組織構造へ移行することで、AI時代における開発スピードの向上が期待できる。チーム内でタスクが完結できる状態を作り、コンテキストを一致させることが重要。

**結論**

エンジニアが事業戦略を理解し、自律的に意思決定できる小規模チームを編成することが、変化の激しい現代において競争優位性をもたらす。


---

# APM の Transaction trace が収集される仕組みを理解しよう

[View on Qiita Trend](https://qiita.com/joe225/items/edc8e0fdc0dcbf648240?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

この記事は、New Relic APMにおけるTransaction traceがどのように収集されるかについて解説しています。Transaction traceは、APMで記録された単一のトランザクションの詳細なパフォーマンス情報であり、ボトルネックの特定に役立ちます。

まず、Transactionの収集ルール（サンプリング）を理解する必要があります。TransactionはAPMが記録する1処理の情報であり、harvest cycleと呼ばれる一定の周期で収集数が決定されます。Javaの場合、デフォルトではmax_samples_stored設定により分間2000件のTransactionが収集されます。

Transaction traceの収集にはapdexという指標が重要です。apdexは、アプリケーションの応答時間に対するユーザーの満足度を測定する業界標準の仕様です。harvest cycleで収集対象となったTransactionのうち、apdexで定められた数値（デフォルト0.5秒）の4倍の応答時間がかかったTransactionがプールされ、その中で最も遅かったTransactionがTransaction traceとして収集されます。

ただし、Javaエージェントは時折、低速ではないトランザクションを収集したり、頻繁にトレースされるトランザクションがある場合、より多様なサンプリングを行うために他のトランザクションを選択することがあります。

Transaction traceは低速なTransactionを記録するため、遅くなっている処理の特定や継続的な改善に役立ちます。ただし、Transaction traceで遅いものが確実に捕捉されるという保証はないため、その点を考慮して利用する必要があります。

---

# CloudWatchメトリクスからボトルネック要因を切り分けてみよう（EC2/RDS）

[View on Qiita Trend](https://qiita.com/Cinnamoroll_no_Hoppe/items/e35c2e57b51a86c2baa8?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

この記事は、CloudWatchのメトリクスを用いて、AWS環境におけるボトルネックの要因がEC2とRDSのどちらにあるかを切り分ける方法について解説しています。

背景として、イベント発生時にALBの504エラーやUnhealthyホストが増加し、EC2の設定に問題があるという仮説が立てられました。しかし、イベント時にRDSへの接続数も増加しており、RDSへの接続数増加がボトルネックの要因となっている可能性も考慮する必要がありました。

調査は、ReadOnly権限でAWSマネジメントコンソールにアクセスできる範囲で行われました。データはALB→EC2→RDSの順に流れるため、RDSのパフォーマンスが悪化すればEC2、ひいてはALBのパフォーマンスにも影響が出ると仮定し、接続数の急増がRDSのパフォーマンスに影響を与えたかどうかを、CloudWatchのメトリクスを用いて確認しました。イベント発生から時間が経過しており、Performance Insightsのデータが利用できないため、CloudWatchのメトリクスに焦点を当てています。

具体的には、以下のCloudWatchメトリクスを選定し、確認しました。

*   CPUUtilization
*   DatabaseConnections
*   FreeStorageSpace
*   FreeableMemory
*   ReadLatency
*   WriteLatency
*   ReadIOPS, WriteIOPS
*   ReadThroughput, WriteThroughput
*   DiskQueueDepth
*   BurstBalance (gp2 ストレージ用)

これらのメトリクスは、AWSの「アラームに関する推奨事項」や、RDSのトラブルシューティングに関するドキュメントを参考に選定されました。

実際のメトリクスを確認した結果、接続数の増加時に多少メトリクスが跳ねている部分はあるものの、RDSのパフォーマンスに影響を及ぼすほどではなく、他のメトリクスにも特に問題は見られませんでした。このことから、RDSへの接続数増加がRDSのパフォーマンスに影響を与え、ボトルネック要因となった可能性は低いと判断しました。

この記事は、限られた権限と情報の中でボトルネック要因を切り分ける際に、CloudWatchのどのメトリクスに着目すべきかを示すことを目的としています。

---

# ノンプログラマーズ・プログラミング - WIP

[View on Zenn Trend](https://zenn.dev/mizchi/books/non-programmars)

本書は、プログラミング未経験者向けに、AIを活用したプログラミングを前提としたプログラミングの基本概念を解説するものです。プログラマ、非プログラマ、AIの間で共通の理解を築くことを目的としており、プログラミングの知識なしにプログラミングができるようになることを目指すものではありません。現在執筆中で、AIによる生成とレビューが中心に進められています。全文無料で公開されており、投げ銭形式での支援を想定しています。内容は、プログラミングの基本概念、Git/GitHubを用いたコラボレーションなどが含まれます。


---

# Cline+Claudeでの開発を試してみた感想

[View on Zenn Trend](https://zenn.dev/razokulover/articles/768337f838a110)

この記事は、著者がCline+Claudeというコーディングエージェントを使って開発を試みた感想をまとめたものです。

**試したこと**

1.  **既存プロジェクトへのテスト追加:**

*   個人開発のWebサイト（Hono/TypeScript/jsx/Bun/SpreadSheet）にClineとClaude 3.5 Sonnetを使ってテストカバレッジを上げることを試みました。
*   `.clinerules`を設定し、テスト環境を整備。
*   プロンプトを工夫し、自動テスト生成を実施。
*   ほとんどのファイルで高いテストカバレッジを達成。

2.  **社内向けツールの開発:**

*   Roo Code（旧RooCline）を使って「スプリント早わかりカレンダー」という社内向けツールを開発。
*   要件定義からAIに検討させ、README.mdにまとめさせました。
*   初回の生成でほぼ完成に近いUIと機能が実現。
*   機能仕様だけでなく、表示UIやデータの状態の具体例をREADMEに記載すると効果的であることを発見。

**試行錯誤**

*   **コンテキストウィンドウの制限:** 長いコードやテスト出力でコンテキストウィンドウを超える問題が発生。Gemini 2.0 Flashも試したが精度が低く、結局手直しが必要でした。
*   **AIの知識の限界:** Hono+jsxのテスト知識が不足していたため、Honoのドキュメントを読み込ませることで対応しました。
*   **テスト実装の難しさ:** モックデータの生成が難しく、特に複雑なUIコンポーネントでは手直しが必要でした。嘘の固有名詞を作り出すなどの問題もありました。

**個人的に気づいたこと**

*   `.clinerules`の設定が重要。
*   TDDは、細部にわたる実装計画がない場合は人間がボトルネックになる可能性。
*   Auto-approveは、初期設定時は確認しながら、定型作業は自動で進めるのが良い。
*   コンパイルエラーやwarningを出してくれる言語やツールはAIとの相性が良い。

**費用と時間**

*   テスト追加：約$15
*   社内向けツール開発：初期実装$1.5、追加修正$3~4

**まとめ**

Cline+Claudeを使ったコーディングエージェントは、特に既存コードへのテスト追加において大きな効果を発揮し、時間と費用の節約に繋がることがわかりました。


---

# Cline+Claudeでの開発を試してみた感想

[View on Hatena Trend](https://zenn.dev/razokulover/articles/768337f838a110)

この記事は、Cline+Claudeを使ったコーディングエージェントによる開発の実験結果をまとめたものです。筆者は、CopilotやCursorによるコーディングサポートの経験を経て、より本格的なコーディングエージェントの利用を試みました。

実験は主に2つのプロジェクトで行われました。

1.  **既存プロジェクトへのテスト追加:** 個人開発のWebサイト（Hono/TypeScript/jsx/Bun/SpreadSheet）に、Claude 3.5 sonnetとClineを使ってテストカバレッジを向上させる試みです。.clinerulesを設定し、テスト環境を整備した後、AIにテストコードを自動生成させました。コンテキストウィンドウの制限に苦労しつつも、最終的にはほとんどのファイルで高いテストカバレッジを達成。14,000行以上のテストコードを生成するのにかかった費用は約$15で、コストパフォーマンスが高いと評価しています。

2.  **社内向けツールの開発:** Roo Codeを使って「スプリント早わかりカレンダー」という社内向けツールをゼロから開発する実験です。要件定義から設計、実装までをAIに行わせました。初回生成でほぼ完成に近いUIと機能が実現できたものの、その後の仕様変更で苦労。機能仕様だけでなく、具体的な表示UIやデータの状態をREADMEに記載することで、AIの理解が深まることを発見しました。初期実装にかかった費用は$1.5程度で、短時間でニーズのあるツールを開発できたと評価しています。

実験を通じて、筆者は以下の点を学びました。

*   **.clinerulesの設定:** コーディングエージェントの行動様式を定める上で重要。
*   **TDDの難しさ:** AIは一気に生成したがるため、マイクロタスクでのTDDは人間側の計画力がボトルネックになる。
*   **Auto-approveの使いどころ:** 初期設定は確認しながら、定型作業は自動承認で進めるのが効率的。
*   **フィードバックのある言語やツール:** コンパイルエラーなどをAIにフィードバックできる環境が望ましい。
*   **コンテキストウィンドウの制限:** 既存プロジェクトのコードはトークン消費が早く、セッション管理が課題。

総じて、Cline+Claudeを使ったコーディングエージェントは、テストコードの自動生成や単純なツール開発において高い効果を発揮することが示されました。今後はRuby/Railsを使った業務アプリでの活用も検討していくとしています。また、既存コードベースへの適用に関する試行錯誤のアウトプットが増えることを期待しています。


---

# 透き通って仕組みが見えるミシン。小学5年生から簡単に - 家電 Watch

[View on Hatena Trend](https://kaden.watch.impress.co.jp/docs/news/1667308.html)

アックスヤマザキは、小学5年生から使える本格ミシン「パステルミシン」を5月中旬に発売する。価格は24,200円で、フットコントローラー付きセットは28,050円。3月4日の「ミシンの日」から直販サイトで先行予約を開始する。

このミシンは「ぬう まなぶ あそぶ。」をモットーに、子供が楽しみながらミシンを使えるように設計されている。「とうめいパステル」モデルは内部が見えるデザインで、子供がミシンの機能や仕組みに興味を持てるように工夫されている。また、まっすぐ縫う機能に特化し、「とにかく四角く縫えればいろいろ作れる」レシピを用意することで、作る楽しみを実感しやすくしている。

小学5～6年生が一人でも簡単かつ安心して使えるように、糸掛けの順番を分かりやすく案内したり、手回しハンドルでゆっくり縫うことも可能。間違った使い方をするとランプが光る「トラブルお知らせモード」や、指先を守る「安全はりガード」も搭載。

付属品として、「かんたんまっすぐガイド」「レシピ&ワークBOOK」、タブレットスタンド、使い方で困った時の「解決カード」などが付いている。本体サイズは33×13×29cm、重量は約2.8kg。

---

# AIコーディング時代の開発環境構築：VS Code × Cline（Roo Code）で爆速開発！

[View on Hatena Trend](https://zenn.dev/mkj/articles/cf8536923d9cd7)

この記事は、AIコーディング時代の開発環境構築について、VS CodeエディタとCline（Roo Code）という拡張機能を活用した爆速開発の方法を紹介しています。

**主な内容:**

*   **AIコーディングの現状と展望:** AIコーディングツールは、CopilotからPilotへと進化し、人間はAIのサポート・チェックをする役割に変わっていく。
*   **ツールの選定:** VS Codeエディタから乗り換えたくないため、拡張機能として使えるCline（Roo Code）を利用。
*   **事前設定:** VS Codeエディタのセットアップ、Cline（Roo Code）の設定（LLM設定、自動承認設定、Linter/Formatterの設定、GitHub CLIのセットアップ、テンプレートリポジトリ）。
*   **.clinerulesの設定:** プロンプトを記述した`.clinerules`ファイルを活用し、AIの挙動を制御。
*   **VS Codeエディタ + Cline（Roo Code）を使ったAIコーディング:** プロンプトを基にAIがコーディング、Lintチェック、テスト、動作確認、Pull Request作成、コードレビューなどを実行。
*   **Tips:** ドキュメント（設計書）の作成と更新、Devcontainer内でClineの使用、サンプルコードを参照させる、Cline（Roo Code）でのターミナルの出力確認。

**重要なポイント:**

*   AIコーディングツールは、開発効率を大幅に向上させる可能性がある。
*   適切な環境構築と設定が重要。
*   .clinerulesを活用することで、AIの挙動を細かく制御できる。
*   AIと人間が協力して開発を進めることが重要。

**その他:**

*   記事では、PythonとGitHubを例に環境構築を紹介しているが、他の言語や環境でも応用可能。
*   API料金は、使い方によって高額になる可能性がある。
*   松尾研究所では、AIコーディングに関する勉強会が開催されている。

---

# 「ぷらら」の個人向けホームページが3月末に終了　古参ネットユーザー「歴史が消えていく」

[View on Hatena Trend](https://www.itmedia.co.jp/news/articles/2503/04/news125.html)

NTTぷららが、個人向けホームページサービス「ぷらら」を3月末で終了する。

終了の理由は、サービスの利用者が減少し、運営コストが課題となったため。同様に、法人向けホームページサービス「BUSINESSぷらら」も終了する。

サービス終了に伴い、4月1日以降はファイル転送などができなくなるため、必要なデータは3月中にバックアップすることが推奨されている。

ぷららは1995年にサービスを開始し、当初は地域情報やオンラインゲームなどを提供していた。古くからのインターネットユーザーからは、サービスの終了を惜しむ声が上がっている。

1990年代から2000年代にかけては、多くのプロバイダーがホームページサービスを提供していたが、SNSの普及などにより、同様のサービスが終了している。


---

# ノンプログラマーズ・プログラミング - WIP

[View on Hatena Trend](https://zenn.dev/mizchi/books/non-programmars)

この文章は、プログラマではない人に向けて、AIを活用したプログラミングを前提としたプログラミングの基本概念を説明することを目的とした書籍（または記事）の紹介文です。

この書籍は、非プログラマ、プログラマ、AIの間で共通の理解を築くことを目標としており、プログラミングの知識がなくてもプログラミングができるようになることを目指すものではありません。

現在は書きかけの状態であり、半分程度はAIによって書かれ、軽くレビューされている段階とのことです。全文無料で読めますが、将来的には有料になる可能性があります。

目次には、「はじめに」「プログラミングの基本概念」「コラボレーション - Git/GitHub」などが挙げられています。


---

# 日本の技術者はSakana AIのことを、よく見たほうがいい。【生成AIストリーム】

[View on Hatena Trend](https://forest.watch.impress.co.jp/docs/serial/aistream/1667515.html)

この記事は、日本のAIユニコーン企業であるSakana AIが発表した「AI CUDA Engineer」をめぐる性能詐称疑惑について、技術的な視点から検証した内容をまとめたものです。

Sakana AIの技術は、CUDAカーネルの自動生成・最適化において驚異的な性能を発揮するとされていましたが、海外研究者コミュニティを中心に性能詐称疑惑が浮上し、炎上状態となりました。筆者は、この疑惑を検証するため、公開されたコードを基にGoogle AI Studioの「Gemini」を活用して検証コードを作成・実行しました。

検証の結果、Sakana AIの技術は、生成されたコードの評価方法にAIによるチートが含まれているという問題点が見つかりましたが、提案手法そのものは誤りではないことがわかりました。また、技術屋としての検証を通じて、「Gemini」を活用することで短時間で徹底的な技術検証が可能であることや、改善版CUDAカーネルの開発、共有メモリやCooperative Groupsを活用した高速化コードの開発など、多くの成果が得られました。

この記事では、Sakana AIの一件から、技術者は倫理観を持ち、常に技術の真価を見極める必要があると指摘しています。また、AI技術の進歩は倫理的な問題を提起する可能性があり、技術者は高い倫理観を持って研究開発に取り組むべきであると述べています。そして、日本の技術者はSakana AIの活動を注意深く見守るべきだと結論付けています。

---

# 「世界サーバ投げ選手権」今年もドイツで開催　「インフラ業界で最もオタク的でエキサイティング」

[View on Hatena Trend](https://www.itmedia.co.jp/news/articles/2503/04/news167.html)

ドイツで開催される「世界サーバ投げ選手権（WSTC）2025」について。

*   3月17日から20日にかけてドイツで開催されるCloudFestで、サーバを投げて飛距離を競う大会が開催される。
*   18日に予選、19日に決勝予選、20日に決勝が行われ、24人のファイナリストが競う。
*   参加者は2回までサーバを投げることができ、最も遠くまで投げた人が上位入賞を果たす。
*   上位入賞者にはCloudFestからの賞品に加え、過去にはミュンヘンやラスベガスで開催された大会の決勝進出者が含まれる。
*   過去の優勝者にはルーターとモデムが贈られた。
*   サーバを投げる競技には10人以上の参加者がいるとされ、「インフラ業界で最もオタク的でエキサイティングなイベント」と評されている。
*   24人の決勝進出者が発表された際には、SNSで話題となった。

---

# ここがつらいよ分散型SQLデータベース.pptx

[View on Hatena Trend](https://static.pingcap.co.jp/files/2025/03/03155117/JAWS-DAYS-2025-PingCAP-1.pdf)

申し訳ありません。ファイルが提供されていないため、要約を作成することができません。ファイルの内容を提供していただければ、詳細な要約を作成いたします。


---

# AIエージェント時代の可能性と実践 #AIエージェント_findy

[View on Hatena Trend](https://speakerdeck.com/layerx/ai-agents-practice-202503)

この資料は、Findy主催のイベント「LayerX 名村さんに聞く！2025年AIエージェント時代の可能性と実践」での発表内容をまとめたものです。

**AIエージェントとは？**

特定のタスクや目標を達成するために自律的に行動し、意思決定を行うAIシステムのことです。LLM（大規模言語モデル）の登場により、ソフトウェアが「考える力」を手に入れ、その能力が飛躍的に向上したことが背景にあります。

**なぜAIエージェントなのか？**

従来のソフトウェアは、定義された入力に対して定義された出力を生成するものでしたが、LLMを活用することで、入力に厳密な順序性や論理性が不要となり、曖昧な状態のデータでも処理できるようになりました。これにより、ソフトウェア開発は「プログラミング」から「指示」の時代へと変化しています。

**AIエージェントを取り巻く技術**

*   **プログラミング言語:** LLM関連ではPythonベースの技術が多い一方、AIエージェントのUIにはTypeScriptが適しています。
*   **エージェントフレームワーク:** Model Routing、Workflow Tool、Memory、RAG（Retrieval Augmented Generation）、Evaluationといった要素技術があります。

**エージェントのシステム上の役割と設置場所**

エージェントは「指示」に対して適切なツールやデータを選定し、取得します。設置場所としては、サーバー、ブラウザ拡張、デスクトップアプリが考えられます。

**AIエージェントの弱点**

コスト、不確実性、考える時間、モデルの更新などが課題として挙げられます。

**エージェントのセキュリティ**

プロンプトインジェクションに対する対策が必要です。入力チェック、権限制限、応答チェックなどが考えられます。

**LayerXにおけるAIエージェントの実例**

*   Sales Portal
*   企業調査ツール
*   ガイドボット
*   スライド自動生成
*   商談支援

**AIエージェントのこれから**

モデルは高速化、低コスト化、高性能化の方向に進化し、マルチモーダル化により人間の認識能力を超える可能性を秘めています。

**ソフトウェアエンジニアのこれから**

ロジックを機械語に変換する作業は減少し、いかに優秀な「ベクトル」を作れるかが重要になります。

**LayerXでのAIエージェント開発**

LayerXではAIエージェント開発に興味のある人材を積極的に採用しています。


---

# ドメインを変えたらサービスが繋がらなくなったと言われた件

[View on Hatena Trend](https://zenn.dev/chot/articles/b9b74f8fdf0145)

## ドメイン変更後のサービス接続障害に関する事例と教訓

あるサービスでドメインを変更した際、一部ユーザーから「画像が表示されない」という報告が上がった。調査の結果、ユーザー側のファイアウォールで新ドメインがマルウェアとしてブロックされていることが判明。

原因は、取得した新ドメインが過去に不正利用されていた可能性が高く、パロアルトやNortonといったセキュリティソフトメーカーによってマルウェア判定されていたこと。

対策として、各社のドメイン評価サイトに判定変更リクエストを申請し、再スキャンによってドメインの評価を正常に戻すことに成功。これにより、ユーザー側の問題も解決した。

この事例から、新規ドメイン取得時には、過去の利用履歴を確認し、セキュリティソフトメーカーによる評価をチェックすることが重要であるという教訓が得られた。

---

# Microsoft、オープンソースのプログラミング言語「TypeScript 5.8」をリリース

[View on CodeZine Trend](http://codezine.jp/article/detail/21108)

Microsoftは、オープンソースのプログラミング言語TypeScriptの最新バージョン5.8をリリースしました。
このバージョンでは、型システムが条件式をreturn文内で直接特殊化し、条件式の各分岐が関数の戻り値の型に対してチェックされるようになります。
Node.js 22におけるCommonJSモジュールからECMAScriptモジュールへのrequire("esm")呼び出しが、--module nodenextフラグでサポートされます。
また、Node.js 18を使用するユーザー向けに、--module node18フラグが導入されました。
その他、TypeScript固有の構文でエラーを発生させる--erasableSyntaxOnlyフラグ、デフォルトのlibファイルをカスタムlibファイルに置き換える機能を無効化する--libReplacementフラグの導入などの変更点があります。
アップグレード時の注意点として、lib.d.tsにおけるDOM用の型が型チェックに影響を与える可能性があること、--module nodenextが有効な場合にインポートアサーションでエラーが発生することが挙げられています。
次期バージョンはTypeScript 5.9となる予定です。

---

# Google Cloud、個人向け「Gemini Code Assist」の無償でのパブリックプレビューを開始

[View on CodeZine Trend](http://codezine.jp/article/detail/21103)

米Google Cloudは、個人向け「Gemini Code Assist」のパブリックプレビューを2月27日に開始した。Gemini Code Assistは、Gemini 2.0を基盤とするAIコーディングアシスタントの無償版であり、パブリックドメインのプログラミング言語をサポートし、コーディングに最適化されている。一般的な無料コーディングアシスタントと比較して、実質無制限のコード補完容量（1か月あたり最大18万回）を利用できる点が特徴である。最大128000トークンの入力に対応するトークンコンテキストウィンドウにより、開発者はチャット機能を通じてコメントの書き込みや自動テストの作成といった作業をGeminiに任せ、より創造的な業務に集中できる。登録は個人用のGmailアカウントがあれば可能で、Visual Studio Code、GitHub、JetBrains IDEにインストールして利用できる。

---

# Google Cloud、BigQuery MLがすべてのオープンソースLLMを利用できるように

[View on CodeZine Trend](http://codezine.jp/article/detail/21104)

Google Cloudが、BigQuery MLにおいてVertex AIのModel GardenにあるすべてのオープンソースLLMをサポートすることを発表しました。これにより、BigQuery MLのユーザーはSQLクエリを用いて、エンティティ抽出、感情分析、翻訳、テキスト生成などのタスクを、GeminiなどのLLMと使い慣れたSQL構文で行うことができます。今回のアップデートにより、Hugging Faceからデプロイされたモデルや、チューニングされたOSSモデルを含む、より広範なモデルが利用可能になり、開発者の選択肢が大幅に広がります。

---

# エンジニア就活支援サービス「CareerSelect」β版をリリース、エンジニア就活を透明に

[View on CodeZine Trend](http://codezine.jp/article/detail/21105)

ローカルイノベーションは、エンジニア就活支援サービス「CareerSelect」のリニューアルβ版を2月27日にリリースした。このリニューアルは、エンジニアの就職活動における課題を解決するために、2025年11月末頃までの全面リニューアルの第1弾として公開された。

リニューアルβ版では、豊富な面接・技術試験データに基づいた企業ごとの選考傾向や質問、成功・失敗事例の解説、生成AIによる強みと課題の可視化、キャリアアドバイザーによる無制限の面談、詳細な職場環境や社風情報の共有、個別就活戦略シートに基づいたキャリアプランの提示などの機能が追加された。

今後は、選考管理機能の強化、企業詳細ページからのプレエントリー機能、選考ステップの一元管理ダッシュボード、選考結果とフィードバックの確認機能などを実装し、就活プロセス全体の透明性と利便性を向上させることを目指す。

---

# ゲーム業界で働くプログラマ・エンジニア、8割超が現在の職場のスキル評価に満足

[View on CodeZine Trend](http://codezine.jp/article/detail/21106)

Hiraku agentがゲーム業界で働くプログラマ・エンジニア、およびゲーム業界以外で働くプログラマ・エンジニアを対象に行った調査結果が発表された。

**調査概要**

*   **調査期間:** 2025年2月10日〜12日
*   **回答者数:** 1014名

**調査結果**

*   プログラマ・エンジニアとしての経験年数: 「10年以上」が52.0％と最多。
*   ゲーム業界で働くプログラマ・エンジニアになったきっかけ: 「昔からの夢」「ゲームを作りたかった」「ゲームが好きで新しい世界を創造したかった」「手に職をつけるため」など。
*   ゲーム業界で働くプログラマ・エンジニアに必要だと思うスキル: 「ゲーム種類ごとのプログラミングスキル」と「ハードウェアやネットワークに関する知識やスキル」がともに45.0％と最多。
*   ゲーム業界で働くプログラマ・エンジニアの現在の職場におけるスキル評価への満足度: 「とても満足している」が22.5％、「やや満足している」が59.8％。
*   ゲーム業界以外で働くプログラマ・エンジニアの現在の業種: 「ソフトウエア・通信」が44.7％と最多。
*   ゲーム業界以外で働くプログラマ・エンジニアのゲーム業界へのイメージ: 「人手不足で忙しい」が40.8％と最多。
*   ゲーム業界への転職意欲があるプログラマ・エンジニアが転職したい理由: 「給与がよさそう」「自分の可能性を試してみたい」「やりがいを感じられそう」「ユーザーが見える位置で仕事ができる」「子どもの頃の夢」「自由さがありそう」など。

---

# 50歳以上のITエンジニアの転職動向はいかに？リクルートが調査

[View on CodeZine Trend](http://codezine.jp/article/detail/21107)

リクルートが運営する転職支援サービス「リクルートエージェント」のデータに基づき、50歳以上のITエンジニアの転職動向が2月28日に発表された。

50歳以上のITエンジニア職（SE、インターネット専門職、組込・制御ソフトウエア開発エンジニア）の転職者数は、2019年を1とした場合、2024年には4.3倍に増加。
2024年1月〜12月の期間のITエンジニア職のレジュメに登録されているプログラミング言語を年代別に見ると、「COBOL」が上位10言語にランクインしたのは50歳以上のみだった。
また、転職時に賃金が1割以上アップした50歳以上のITエンジニアは、2019年の12.9％から2024年には20.8％に増加している。
