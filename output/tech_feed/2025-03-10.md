
# 【きのこカンファレンス2025】ランチスポンサーとして協賛！ブース展示 &amp;amp;登壇全文公開！ | CARTA TECH BLOG

[View on Company Blog](https://techblog.cartaholdings.co.jp/entry/kinoko-conf-2025-report)

CARTA HOLDINGSが「きのこカンファレンス2025」にランチスポンサーとして協賛し、ブース出展とスタッフエンジニア@brtriver氏による登壇を行った。

ブースでは「エンジニアとしての成長と人生の転機をシェアする」をテーマに、来場者のエンジニアに人生の好調・不調の時期をシールで、大切にしていることや今後のトライを付箋で示してもらい、キャリアについて対話を行った。年代によって悩みの質が異なり、若手は仕事に慣れるまでの苦労、30代はマネジメントへの移行、30-40代は病気や親の死別などが転機となるケースが多かった。

ランチセッションでの@brtriver氏の登壇では、「後悔しない選択を毎日行う / No Day, But Today」という信念に基づき、日々の小さな変化が将来を大きく変えるという考えが語られた。
@brtriver氏は自身の20代での病気、30代での難易度MAXのプロジェクト、40代での子育てと父親の介護といった経験から得た学びを共有し、講演内容の全文が公開されている。

カンファレンスを通じて、多くのエンジニアと貴重な対話の機会を得て、各年代の課題や転機についての理解を深めた。CARTA HOLDINGSは今後もテクノロジーに関わる人々を支援し、得られた知識をコミュニティに還元していく。


---

# systemd timer にちゃんと向き合ってみる | サーバーワークスエンジニアブログ

[View on Company Blog](https://blog.serverworks.co.jp/about-systemd-timer)

Amazon Linux 2023でデフォルトとなったsystemd timerについて、その設定方法や深掘りした内容をまとめたブログ記事です。

**systemd timerとは**
systemdはLinux OS用のシステムおよびサービスマネージャであり、ユニットファイルという設定ファイルでシステム管理を行います。.timer拡張子を持つユニットファイルでタイマーを定義し、設定された時間になると同じ名前の.serviceユニットファイルを起動する仕組みです。cronジョブに似たスケジュール機能を提供します。

**systemd timerを使う理由**
Amazon Linux 2023ではcronが標準インストールされなくなったため、systemd timerへの移行が推奨されています。

**設定方法**
1.  実行したいジョブを.serviceファイルとして作成する。
2.  .serviceファイルと同じ名前で、拡張子を.timerとしたファイルを作成する。
3.  .timerファイルにタイマーの設定を記述する。

**動作確認**
`systemctl list-timers`コマンドでタイマー設定の一覧を確認できます。

**タイマーの種類**
*   **Real-time timer (リアルタイムタイマー)**: カレンダー形式で日時を指定する。OnCalendarオプションを使用。
*   **Monotonic timers (単調タイマー)**: OS内部のイベントを起点とする。OnBootSecなどのオプションを使用。
*   **Transient timers (過渡タイマー)**: 現在のセッションのみ有効なタイマー。`systemd-run`コマンドで実行。

**OnCalendarオプションの記法チェック**
`systemd-analyze calendar`コマンドでOnCalendarオプションの記法チェックと実行日時の確認ができます。

**その他**
*   cronと異なり、スケジュール実行後のメール送信機能は標準では提供されないため、別途実装が必要です。
*   .timerユニットファイルを更新した場合は、`systemctl daemon-reload`を実行する必要があります。

**まとめ**
systemd timerはcronに比べて設定ファイルの準備が少し手間ですが、タイマーの一覧表示やカレンダー形式の評価機能があり、設定ミスが起こりにくいと感じられます。Amazon Linux 2023への移行を機に、systemd timerの導入を検討してみてはいかがでしょうか。

---

# 生成AIに外部APIの結果出力をお願いしたら驚くほど簡単だった話 | SODA Engineering Blogのフィード

[View on Company Blog](https://zenn.dev/team_soda/articles/15e8562b194ac3)

SODAのクオリティエンジニアであるokauchi氏が、生成AIとGAS（Google Apps Script）を組み合わせて、E2Eテスト自動化ツールのテスト実行結果収集を効率化した体験談を紹介。

従来、APIのスクリプト作成に手間を感じていたが、生成AIにAPI Docを読ませることで、APIのエンドポイントやパラメータ、レスポンス形式を自動解析し、GASで実装するためのスクリプトを提案してもらうことに成功。

生成されたスクリプトは修正が必要だったものの、生成AIが修正のヒントを提供し、数回のやり取りでほぼ完璧なスクリプトが完成。手動で収集していた情報が数秒で完了するようになった。

この体験から、生成AIはプログラミング初心者でも強力な味方となり、API Docの読解やスクリプトの基礎部分をサポートしてくれると実感。生成AIの進化も早く、以前は役に立たなかったスクリプトもバージョンアップで簡単に対応できるようになった。

この内容を社内勉強会で発表したところ、開発エンジニアから実用的な内容だと評価された。SODAではエンジニアの採用活動を積極的に行っており、詳細については記事内のリンクを参照。


---

# Amazon ECRの拡張スキャンを始める前に知っておきたい設定ポイント2つ | ENECHANGE Developer Blog

[View on Company Blog](https://tech.enechange.co.jp/entry/2025/03/09/145926)

ENECHANGEがAmazon ECRの拡張スキャンを導入した際に重要となる設定ポイントとして、以下の2点が挙げられています。

1. **Amazon ECRから有効化する:** Amazon Inspectorから直接有効化すると、EC2やLambdaのスキャンも有効になり、不要なリソースまでスキャンしてしまう可能性があります。また、全てのリポジトリが連続スキャンの対象となり、意図せず利用料金が高騰する可能性があります。そのため、ECRのスキャン設定から拡張スキャンを有効化し、最初はリポジトリを絞ってプッシュ時の脆弱性検出から試すことを推奨します。

2. **通知をカスタマイズする:** 拡張スキャンで検出された脆弱性の通知をAmazon EventBridge経由でSlackに通知する際、デフォルトの通知内容ではイメージタグや脆弱性情報が含まれておらず、実用的ではありません。EventBridgeの入力トランスフォーマーを使用して通知内容をカスタマイズし、Inspectorの検出結果ARN、イメージタグ、検出された脆弱性などの情報を含めることで、対応がしやすくなります。また、同じイメージの検出結果がスレッドにまとまるようにスレッドIDを調整すると、さらに見やすくなります。

これらの設定を行うことで、ENECHANGEではクリティカルな脆弱性への対応をスムーズに行えるようになり、セキュリティ強化に繋がったとのことです。

---

# あなたの組織は迎え入れの準備はできていますか？〜「オンボーディングガイドブック」をリリースしました～

[View on Qiita Trend](https://qiita.com/viva_tweet_x/items/c0bfd00074301b667b1b?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

記事は、新卒研修や新メンバーのオンボーディングを円滑に進めるためのガイドブック「オンボーディングハンドブック」のリリースを紹介しています。

**概要:**

*   **オンボーディングハンドブックとは:** 新メンバーが組織にスムーズに適応し、能力を発揮できるよう、会社の文化や基礎知識、キャリアプランのノウハウをまとめたTIPS集（約50種）。
*   **特徴:** オンラインホワイトボードツール「Miro」で作成されており、コピー＆ペーストが容易。利用用途やシーンに応じて検索しやすく、コミュニティとして意見を反映できる。
*   **対象者:** 新入社員や新メンバーを受け入れる立場の人（先輩社員、人事担当者、研修講師など）。
*   **アクセス方法:** Miroのボードにアクセスし、操作説明に従って利用。誰でも編集可能で、情報の追加・更新が可能。
*   **構成:** 大分類（マインドセット、研修、オンボーディングなど）、中分類、関連するTIPSで構成。
*   **使い方:**
    *   **眺める:** 研修やオンボーディング設計の参考に。
    *   **検索する:** 必要なTIPSをキーワードで検索。
    *   **説明に使う:** TIPSの概要を他の人に伝える。
    *   **TIPSの拡張:**
        *   好きなTIPSに投票。
        *   みんなのメモを書き込む。
        *   自分でTIPSを書き足す。
*   **利用のお願い:** リンクの共有、QiitaやX(Twitter)での共有、誤字脱字の指摘。
*   **謝辞:** 企画編集者、構成アドバイザー、意見提供者、スクラムフェス福岡の参加者への感謝。

---

# 初めてAWS Community Builderに選ばれたので何をしたか振り返ってみる【外部登壇なしでも！】

[View on Qiita Trend](https://qiita.com/issy929/items/4b8aacd261d1a6fabc75?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

この記事は、筆者がAWS Community Builderに選出された経験を振り返り、これから目指す人への参考になるように書かれたものです。

**AWS Community Builders Programとは**

AWS Community Builders Programは、AWSの知識共有やコミュニティへの貢献に熱心な技術者を支援するプログラムです。選ばれると、AWSに関する技術リソースや教育、ネットワーキングの機会が提供されます。応募資格は18歳以上であれば誰でもあり、選出範囲はグローバルです。

**申請方法**

申請は、ウェイティングリストに登録し、申請受付開始時に送られてくるメールからWebフォームに記入して行います。申請は英語で行う必要があり、AWSの経験やコミュニティへの貢献に関する具体的な記述が求められます。

**選考のポイント**

具体的な審査条件は公開されていませんが、ブログ投稿、ビデオ、オープンソースへの貢献、プレゼンテーションなど、他のAWS技術者を支援する技術コンテンツの証拠と精度が重視されます。オンラインでの知識共有も考慮されます。

**筆者の実績**

筆者は、AWS Community Builderになるという明確な目標を立てていたわけではありませんが、以下の活動を継続していました。

*   Zennでの記事発信（社内勉強会向けのAWSサービス解説記事など）
*   GitHubでのコード公開（AWS CDKを使ったインフラ構築コードなど）

**申請時に気を付けたこと**

申請フォームの記述では、以下の点を心がけました。

*   経歴と活動内容の具体化
*   実例説明の明確化
*   数字を含めること（投稿数、閲覧数、参加人数など）

**審査結果**

審査結果はメールで通知されます。

**最後に**

外部登壇実績や書籍執筆などの目立った実績がなくても、AWSが好きで、熱意をもって活動を継続することが重要です。目標を立て、小さな一歩からでも知識や経験をコミュニティに還元していくことが大切です。

---

# microCMS+Next.js+Vercel+お名前.comで独自ドメインのブログを作る

[View on Qiita Trend](https://qiita.com/rf_p/items/608fe8d9463dc37eb42e?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

この記事は、microCMS、Next.js、Vercel、お名前.com を使用して、独自ドメインのブログを構築する手順を解説しています。

まず、microCMS のテンプレートを利用してブログのフロントエンドを簡単に作成し、ローカル環境で立ち上げます。次に、microCMS の管理画面からコンテンツを登録し、ブログ記事が正しく表示されるか確認します。

その後、Vercel にデプロイして本番環境を構築し、ブログのタイトル、コピーライト、投稿日のフォーマットなどのテキスト情報を調整します。

最後に、お名前.com で独自ドメインを取得し、Vercel に設定することで、独自ドメインでのブログ公開を実現します。デザイン調整や機能追加は必要に応じて行うことが推奨されています。

---

# 線形漸化式を満たす数列の線形代数

[View on Qiita Trend](https://qiita.com/ryuhe1/items/1ee6d40302874c40c702?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

この記事は、線形漸化式を満たす数列の線形代数的な側面、特に母関数だけでは理解しにくい点について解説しています。具体的には、母関数の分母が冪乗の形をしている場合や、線形漸化的な数列の冪乗和からなる数列の効率的な計算方法に焦点を当てています。

記事の内容は以下の通りです。

1.  **線形漸化式**: 線形漸化式を満たす数列の定義、特性多項式、および数列の母関数との関係について説明しています。また、線形漸化式を満たす数列がなす線形空間の基底の選び方について、特性多項式の根を利用した具体的な構成方法を示しています。

2.  **短い線形漸化式と関連する長い線形漸化式**:
    *   **特性多項式が Γ(x)^m の場合**: 元の特性多項式の根が重根となる場合に、線形空間の基底がどのように変化するかを述べています。
    *   **線形漸化的数列の m 乗和**: 数列の m 乗和が満たす線形漸化式について、特性多項式の根の組み合わせから新しい特性多項式を構成する方法を示しています。
    *   **線形漸化的数列のアダマール積**: 2つの線形漸化的数列のアダマール積が満たす線形漸化式について、それぞれの特性多項式の結合積として新しい特性多項式を定義しています。

3.  **具体例**: Yukicoder の問題を例に、具体的な数列に対して、上記の理論をどのように適用して効率的な計算を行うかを説明しています。

4.  **おまけ：結合積の計算**: 結合積の特性多項式を効率的に計算するためのアルゴリズムについて解説しています。

全体として、この記事は線形漸化式を満たす数列に関する線形代数的な構造を深く理解し、効率的な計算方法を開発するための洞察を提供しています。


---

# そのGitHub Copilotの機能、Preview版じゃない？

[View on Qiita Trend](https://qiita.com/cazamir0/items/ae71c3bce51fd5a3fa8d?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items)

GitHub CopilotのPreview版機能を利用する際の注意点について解説されています。

GitHub Copilotは、低価格で高機能なコード生成AIであり、Preview版として新機能が頻繁に提供されています。しかし、Preview版の機能を使用すると、収集されたデータがGitHub Copilotの学習に使用される可能性があります。

Preview版の利用規約では、ユーザーの使用状況に関する情報が収集され、GitHubに送信されることが明記されています。これらの情報はサービスの提供・改善に使用されることがあります。Business版では、オプトアウト設定が有効でなくても学習に使用されないとされていますが、Preview版の機能を使用する場合は、この規約が優先されます。

Preview版の機能は、GitHub Copilotの設定画面で「Preview」と表示されているものや、GitHubのブログ記事で「public preview」と記載されているもので確認できます。これらの機能は、「Editor preview features」を無効化することで使用しないようにできます。

GitHub CopilotのPreview版を使用するとデータが学習される可能性があるため注意が必要ですが、Preview版を使用しないとエディタとしての利便性が低下する可能性があります。個人開発でデータが学習されることを許容できる場合は、無理に無効化する必要はないと述べられています。


---

# Postman を使ったシナリオ付き負荷試験

[View on Zenn Trend](https://zenn.dev/kameoncloud/articles/c3b6f6a2ac3445)

この記事は、Postman を使ってシナリオに基づいた負荷試験を行う方法を紹介しています。

**Postmanの負荷試験機能**

*   Postmanのデスクトップアプリには負荷試験機能が搭載されている。
*   コレクションを実行することで、APIを連続的に呼び出すことができる。
*   Performanceタブでは、スパイクテストなどのシナリオをGUIで設定可能。
*   無償で利用できる点がメリット。
*   ただし、APIコールのソースIPアドレスが同一であるため、WAFの設定によっては通信が遮断される可能性がある。

**Postman Flows を活用したシナリオテスト**

*   Postman Flows を使うことで、API呼び出しの条件分岐やスクリプトの挿入など、より複雑なシナリオを作成可能。
*   Flowsで作成したフローはWebhookとして公開し、コレクションから呼び出すことで実行できる。
*   FlowsはPostmanクラウド上で実行されるため、APIコールのIPアドレスはコレクション実行時とは異なる。
*   IPアドレスは固定であり、定期的な変更はできない。

---

# MCPサーバーを作るMCPサーバーを作った

[View on Zenn Trend](https://zenn.dev/tesla/articles/c66bda76c4a523)

この記事は、MCP (Message Communication Protocol) サーバーを手動で作成する手間を省くためのツール「MCPサーバーを作ってくれるMCPサーバー」の紹介です。

**概要:**

*   MCPサーバーの作成を自動化し、プロトタイプ作成や既存MCPサーバーの調整を容易にするツール。
*   現状TypeScriptに対応しており、今後Pythonにも対応予定。
*   Docker環境での動作を推奨。
*   簡単な指示（例: 「typescriptで文字を逆順にするmcpサーバーを作って」）でMCPサーバーを生成可能。
*   文字の逆順、GitHub連携など、具体的なMCPサーバーの例を紹介。

**機能:**

*   MCPサーバーの作成、削除、実行が可能。
*   リポジトリ: [https://github.com/tesla0225/mcp-create](https://github.com/tesla0225/mcp-create)

**使い方:**

1.  Dockerイメージをビルド。
2.  MCP設定ファイルに設定を追加。
3.  指示を記述して実行。

**今後の課題:**

*   コードの部分更新
*   Pythonでの実行対応
*   Sequential Thinkingの実装

**その他:**

*   MCPのプロトタイピングを高速化できる。
*   バグ報告や要望はGitHubのissueまたはTwitterで受け付け。
*   MCPに対する考え方: [https://zenn.dev/tesla/articles/3d1ba14614f320](https://zenn.dev/tesla/articles/3d1ba14614f320)
*   依存関係install込み版のPull Request: [https://github.com/tesla0225/mcp-create/pull/4](https://github.com/tesla0225/mcp-create/pull/4)

---

# 中国でDeepSeek狂奏曲　VRAM96GB（？）の改造4090カードや各種製品が高速で大量登場 (1/2)

[View on Hatena Trend](https://ascii.jp/elem/000/004/255/4255977/)

中国発の軽量LLM「DeepSeek」が話題となり、DeepSeek R1ソリューションが中国国内で急速に普及している。病院や行政機関での導入が進み、医療の効率化や市民対応の迅速化に貢献している。

DeepSeek R1のローカル運用にはGeForce RTX 4090D搭載システムが約143万円で必要だが、A100/H100搭載システムと比較して大幅に安価である。RTX 4090Dは中国向けに性能が抑えられたバージョンだが、無印RTX 4090も市場に流通している。

深圳の電子街「華強北」では、標準の24GBメモリを増強した改造版RTX 4090も販売されている。中には96GBに増強されたものもあるという。これらの改造版は排熱が課題となるため、冷却機能が強化されている。

DeepSeek R1の安定動作をサポートするテクニカルサポート付きのショップブランドPCも販売されている。また、レノボやファーウェイなどの企業からDeepSeekを組み込んだサーバー型ハードウェア「大模型（LLM）一体機」が発表され、医療、教育、金融などの特定業界向けにも提供されている。

---

# 10億台超のIoT機器に搭載の「ESP32」に悪用可能なバックドア発見

[View on Hatena Trend](https://www.itmedia.co.jp/news/articles/2503/09/news075.html)

Tarlogic Securityは、10億台以上のIoT機器に搭載されている「ESP32」に悪用可能なバックドアを発見したと発表しました。

ESP32は、Wi-FiとBluetoothの機能を備えた低価格なMCUであり、多くのスマートホームデバイス、産業用機器、教育用機器などに使用されています。Espressif Systemsによると、2023年には全世界で10億個以上のESP32が出荷されたとのことです。

Tarlogic Securityが発見したバックドアは、ファームウェアが適切に保護されていない場合に悪用される可能性があります。このバックドアが悪用されると、機密情報の漏えい、デバイスの制御、マルウェアのインストール、IoTデバイスで処理されるデータの改ざんなどが可能になる可能性があります。

Tarlogic Securityは、このバックドアを特定するために、Bluetoothプロトコルアナライザ「BSAM」とBluetooth USBドングルを使用しました。

また、ファームウェアのアップデートを最新の状態に保つことや、信頼できるソースからのみファームウェアをダウンロードすることなどを推奨しています。

---

# Postman を使ったシナリオ付き負荷試験

[View on Hatena Trend](https://zenn.dev/kameoncloud/articles/c3b6f6a2ac3445)

この記事は、Postman を使ってシナリオ付きの負荷試験を行う方法を紹介しています。

**Postman での負荷試験の基本的な方法:**

1.  **テスト用APIの準備:** `requestcatcher` などのツールを使って、テスト用のAPIを2つ作成します（例: `stresstest` と `success`）。
2.  **コレクションの作成:** Postmanで2つのコレクションを作成し、同じフォルダに格納します。`stresstest` API を呼び出すコレクションと、`success` API を呼び出すコレクションを作成します。
3.  **コレクションの実行:** フォルダを選択し、実行回数や遅延時間（Delay）を設定して負荷試験を実行します。PostmanのGUIでスパイクテストなどのシナリオを設定することも可能です。

**Postman Flows を使ったシナリオテスト:**

*   複数のAPI呼び出しをシナリオに沿って実行したい場合は、Postman Flows を使用します。
*   例えば、最初のAPIコールが成功した場合のみ次のAPIがコールされるように条件分岐を設定したり、途中でスクリプトを挿入して文字列操作や乱数生成などを行うことができます。
*   作成したFlowのWebhookをコレクションから呼び出すことで、シナリオに沿った負荷試験が可能です。

**注意点:**

*   Postman デスクトップアプリから実行する場合、APIコールのソースIPアドレスは同じになるため、WAFなどで通信が遮断される可能性があります。
*   FlowはPostmanクラウド上で実行されるため、IPアドレスはデスクトップアプリからの実行時とは異なりますが、単一のIPアドレスからリクエストが出されます。

**まとめ:**

Postman は、JMeter や Locust などの専門的なツールを使わなくても、比較的簡単に負荷試験を行うことができる便利なツールです。特に、Postman Flows を活用することで、より複雑なシナリオに沿ったテストを行うことができます。無償で利用できる範囲で非常に有用ですが、IPアドレス制限などの注意点も考慮する必要があります。

---

# 生成AIにdraw.ioのAWS構成図を作図させてみた | DevelopersIO

[View on Hatena Trend](https://dev.classmethod.jp/articles/aws-drawio-genai/)

この記事は、生成AIを活用してdraw.io形式でAWS構成図を自動生成する方法を紹介しています。

**要約:**

*   **IaCからの構成図生成:** CDK、CloudFormation、TerraformなどのIaCコードから、直接draw.io形式のAWS構成図を生成できることを実証。
*   **推奨モデル:** 特にClaude 3.5 Sonnet以上のモデルが、AWSアイコンの認識精度や構成の理解度において優れている。
*   **アイコン認識の課題:** Anthropic以外のモデルでは、AWSアイコンの認識が弱い傾向がある。
*   **構成図の品質:** 生成された構成図は、マルチAZ構成、ALB、EC2、RDSなどのリソース、セキュリティグループの関係性などを適切に表現。ただし、アイコンが古い場合がある。
*   **レイアウトの柔軟性:** 事前にdraw.ioのテンプレートを用意することで、好みのレイアウト（横配置/縦配置）で構成図を作成可能。
*   **テンプレートの利用:** テンプレートを利用することで、生成AIが適切な位置にリソースを配置しやすくなり、最新のAWSアイコンを利用する可能性が高まる。
*   **プロジェクト全体を考慮した構成図:** Cursorの`@codebase`やGitHub Copilotの`@workspace`などのツールを使用することで、プロジェクト全体を理解した構成図を生成可能。利用できない場合は、複数のファイルを1つにまとめるアプローチも有効。
*   **今後の展望:** 生成AIの進化により、さらに高品質な構成図の自動生成が期待される。

---

# TypeScript 製の AI エージェントフレームワーク Mastra

[View on Hatena Trend](https://azukiazusa.dev/blog/typescript-ai-agent-framework-mastra/)

Mastraは、Gatsbyの開発チームが開発したTypeScript製のAIエージェントフレームワークです。Mastraサーバーを起動することで、REST APIを通じてエージェントと対話できます。

**Mastraの主な機能:**

*   **エージェント:** 複雑なタスクを実行するAIエージェントの定義
    *   様々なAIプロバイダの切り替え
    *   過去のコンテキスト保持
    *   ツールによる外部情報取得
*   **ワークフロー:** グラフベースのステートマシンによる複雑なLLM操作
*   **RAG:** 大量のドキュメントを読み込ませ、ベクトルデータベースに保存し、質問応答時に参照
*   **開発環境:** REST API, OpenAPI, インタラクティブなプレイグラウンド
*   **評価:** エージェントの回答をスコアリング
*   **オブザーバビリティ:** ログ・トレース機能
*   **Next.jsとの統合

**Mastraを使ったAIエージェントの構築:**

1.  **プロジェクトの作成:** `npx create-mastra@latest`コマンドでプロジェクトを作成。APIキー（OpenAI, Anthropic, Geminiなど）が必要。Ollamaを使ってローカルLLMも可能。
2.  **ディレクトリ構造:** `src/mastra`ディレクトリがコアとなる。
    *   `src/mastra/index.ts`: エントリーポイント。Mastraクラスの初期化とエージェントの登録。
    *   `src/mastra/agents/index.ts`: Agentクラスでエージェントを定義。プロンプト、モデル、ツールを指定。VercelのAI SDKでモデルを指定。
    *   `src/mastra/tools/index.ts`: ツールを定義。createTool関数を使用し、ツールの説明、入力/出力スキーマ、実行関数を指定。JSONスキーマで構造化された出力を実現。

**Mastraサーバーの実行:**

*   `npm run dev`でサーバーを起動。REST API、Swagger UI、Playgroundが利用可能になる。
*   `curl`コマンドでAPIにリクエストを送信 (`http://localhost:4111/api/agents/{agentId}/generate`)

**AIエージェントの評価:**

*   `@mastra/evals`パッケージを使用。
*   Agentクラスの`evals`プロパティに評価メトリックを追加（例: ToxicityMetricで有害コンテンツの評価）。
*   Vitestなどのテストフレームワークでテストを自動化し、CI/CDパイプラインに組み込む。
*   OpenTelemetryでトレースを収集し、Grafanaなどで可視化。

**まとめ:**

Mastraは、TypeScriptでAIエージェントを構築、評価、監視するための包括的なフレームワークであり、REST API、Swagger UI、Playgroundを提供し、様々なLLMプロバイダをサポートします。

---

# iPhoneではうちのネコチャンで文字とかを隠すスタンプが作れるらしい→GIFで動くやつも作れて「大変キャワ」

[View on Hatena Trend](https://togetter.com/li/2522875)

iPhoneで、飼い猫の写真を使ってメッセージの文字を隠すスタンプが簡単に作成できるという情報がSNSで話題になっている。iPhoneの切り抜き機能を利用し、写真から猫の画像をステッカーとして保存、メッセージアプリなどでスタンプのように使用できる。この機能を使えば、静止画だけでなくGIFアニメーションのスタンプも作成可能。同様の機能はGalaxyにも搭載されている。ユーザーからは、愛猫や愛犬のスタンプを自作して楽しむ様子が多数投稿されている。


---

# AIによるコーディングアシスタント、コーディングエージェント、アプリケーション自動生成サービスまとめ（2025年3月版）

[View on Hatena Trend](https://www.publickey1.jp/blog/25/ai20253_1.html)

2025年3月版として、AIを活用したコーディング支援サービスを「コーディングアシスタント」「コーディングエージェント」「アプリケーション自動生成」の3つに分類し、各カテゴリーのツールを紹介する。

**コーディングアシスタント** は、プログラマーが記述するコードの補完や提案を行うことで、生産性向上を支援する。代表的なツールとしてGitHub Copilotがあり、コードの自動補完、自然言語によるコメントからのコード生成、コードの説明などの機能を提供する。多くのツールがVisual Studio Codeなどのコードエディタに統合されており、既存プロジェクト内のコードを把握した上で、より正確なコード生成や提案を行うようになっている。

**コーディングエージェント** は、自然言語で設定されたタスクに基づき、AIが主体的にコーディングを行うサービス。実装計画の作成、テストコードの作成、コマンドライン操作、デバッグなどの機能を備える。GitHub Copilot Agent Modeのようにコーディングアシスタントと統合されているものと、Devinのように単独のツールとして提供されているものがある。

**アプリケーション自動生成** サービスは、自然言語によるプロンプトで指示を出すことで、AIが自律的に実装計画、コーディング、デバッグを行い、アプリケーションを生成する。v0 by Vercelのように、プロンプト入力画面がシンプルで、ユーザーに開発プロセスを意識させずに迅速にアプリケーションをプレビュー表示するのが特徴。比較的シンプルなロジックを持つWebアプリケーションやWebサイトの生成を想定しているものが多い。

---

# 「kubeshark」でKubernetesのトラフィックをリアルタイムに可視化する

[View on Hatena Trend](https://thinkit.co.jp/article/37988)

この記事は、Kubernetesのトラフィックをリアルタイムに可視化するツール「kubeshark」について解説しています。

**kubesharkとは**

WiresharkをKubernetes向けにカスタマイズしたツールで、Pod、Node、Cluster間のトラフィックをキャプチャし、可視化します。REST、GraphQL、gRPCなど多様なプロトコルをサポートし、インシデントの迅速な解決に役立ちます。ノード数4台以下のクラスターであれば無料で利用できます。

**基本的な使い方**

CLIまたはHelmでインストールできます。CLIの場合、`kubeshark tap`コマンドでトラフィックキャプチャを開始し、ブラウザでダッシュボードにアクセスします。ダッシュボードでは、API CALLSとSERVICE MAPの2つのセクションでトラフィックを分析できます。KFL（Kubeshark Filtering Language）を使って表示をフィルタリングすることも可能です。

**キャプチャフィルター**

リソース消費を抑えるために、キャプチャフィルターを利用して特定のトラフィックのみをキャプチャできます。PodやNamespaceを指定してトラフィックを絞り込むことが可能です。

**pcapファイルの取得**

特定のトラフィックまたはすべてのトラフィックをpcapファイルとして取得できます。TLS通信は復号された状態で出力されます。

**トラフィックの保存とオフライン分析**

kubeshark上でトラフィックを保存・管理し、スケジュールに基づいて記録できます。保存されたトラフィックはKFLでフィルタリングして表示できます。AWS S3やGoogle Cloud Storageなどのオブジェクトストレージにアップロードして長期保存も可能です。

**まとめ**

kubesharkはKubernetes環境でのトラフィック分析に役立ち、トラブルシューティングやパフォーマンス解析を効率化します。特に小規模なクラスターやテスト環境での運用に適しており、Kubernetesコンテキストを含む詳細な情報を収集できます。

---

# Twitterで古いツイートを検索・探す簡単な方法！古い順に並べ替えは不可？ ｜ LINEアプリの使い方・疑問解決マニュアル（LINE活用ガイド）

[View on Hatena Trend](https://line-line-line.com/twitter/twitter-tweet-search/)

この記事では、Twitter（X）で過去のツイートを検索する方法について解説しています。

**公式アプリでの検索**

*   公式アプリではツイートを古い順に並べ替える機能は現状ありません。
*   検索コマンドを使用すると、アカウントと日付を指定してツイートを検索できます。
    *   コマンド例: `from:ユーザーID until:YYYY-MM-DD`

**twilog を利用した検索**

*   twilog は、過去のツイートを検索・閲覧できる外部サービスです。
*   他人のアカウントの場合、表示できるのは100ツイートまでですが、自分のアカウントと連携することで最大3200ツイートまで閲覧できます。
*   twilog では、キーワード検索に加えて、ツイートを古い順に並べ替えることが可能です。

**twilog で古い順に並べ替える方法**

1.  twilog のサイトにアクセスし、Twitter ID を入力。
2.  ツイート一覧が表示されたら、画面中央の「ツイートの並び順」から「古→新」を選択。

**まとめ**

Twitter の検索機能では見つけにくい過去のツイートも、twilog を利用することで効率的に検索できます。特に、ツイートを古い順に並べ替える機能は、特定の時期のツイートを探す際に便利です。

---

# GitHub - nao1215/sqluv: simple terminal UI for DBMS & local CSV/TSV/LTSV

[View on Hatena Trend](https://github.com/nao1215/sqluv)

sqluvは、複数のDBMSとローカルのCSV/TSV/LTSVファイルに対応したシンプルなテキストユーザーインターフェースを提供するツールです。SQLクエリを実行して、接続されたDBMSまたはローカルファイルを操作できます。

**インストール方法:**

*   `go install` コマンドを使用
*   Homebrewを使用

**対応OS・DBMS・Goバージョン:**

*   Windows
*   macOS
*   Linux
*   MySQL
*   PostgreSQL
*   SQLite3
*   SQL Server
*   go1.24 以降

**使用方法:**

1.  **DBMSへの接続:** ファイルパスを指定せずにコマンドを実行すると、接続情報を入力する画面が表示されます。接続に成功すると、設定ファイルに保存され、次回からリストから選択できます。
2.  **SQLクエリ履歴:** 実行したクエリは `~/.config/sqluv/history.db` に保存され、履歴ボタンから参照できます。
3.  **ファイルからの読み込み:** コマンド実行時にファイルパスを指定すると、TUI起動前にファイルが読み込まれます。

**注意点:**

*   sqluvは開発中のため、本番環境でのUPDATEやDELETEは推奨されません。
*   現在はSQLクエリごとにトランザクションが開始・コミットされるため、予期せぬタイミングでコミットされる可能性があります。

**その他:**

*   キーバインディングあり
*   貢献を歓迎 (CONTRIBUTING.md参照)
*   バグ報告や機能リクエストはGitHub Issueで受け付け

sqluvは、nao1215/sqlyから派生したツールで、sqlyよりもユーザーフレンドリーなSQL記述環境を目指しています。
